---
title: "HydroBOT: an integrated toolkit for assessment of hydrology-dependent outcomes"
author: 
 - name: Galen Holt
   orcid: 0000-0002-7455-9275
   corresponding: true
   email: galen@deakin.edu.au
   affiliation:
    - ref: 1
 - name: Georgia Dwyer
   orcid: 0000-0002-3579-3819
   corresponding: false
   affiliations:
     - ref: 1
 - name: David Robertson
   orcid: 0000-0003-4230-8006
   corresponding: false
   affiliations:
     - ref: 2
 - name: Martin Job
   orcid: 
   corresponding: false
   affiliations:
     - ref: 3
 - name: Rebecca E Lester
   orcid: 0000-0003-2682-6495
   corresponding: false
   affiliations:
     - ref: 1

affiliations:
  - id: 1
    name: Deakin University
    department: Centre for Regional and Rural Futures
    address: Locked Bag 20000
    city: Waurn Ponds
    state: Victoria
    country: Australia
    postal-code: 3220
    
  - id: 2
    name: CSIRO
    address: Research Way
    city: Clayton
    state: Victoria
    country: Australia
    postal-code: 3168
        
  - id: 3
    name: Murray-Darling Basin Authority
    address: Allara Street
    city: Canberra
    state: ACT
    country: Australia
    postal-code: 2601

categories:
# keywords: 
 - Murray-Darling Basin
 - Holistic modeling
 - Management modeling
 - Climate change
 - Climate adaptation
 
date: last-modified

filters:
  - multibib
  
# see https://github.com/Mellich/pandoc-multibib#readme and https://www.andrewheiss.com/blog/2023/12/11/separate-bibliographies-quarto/index.html
  
bibliography_main: references.bib
bibliography_supp: references.bib
# csl: apa.csl # alphabetical by author in the cites??
csl: freshwater-biology.csl # basically good, but includes 3 authors

number-sections: true

echo: false

crossref:
  custom:
    - kind: float
      key: suppfig
      latex-env: suppfig
      reference-prefix: Figure S
      space-before-numbering: false
    - kind: float
      key: supptbl
      latex-env: supptbl
      reference-prefix: Table S
      space-before-numbering: false
      caption-location: top

format:
  docx:
    toc: false
    prefer-html: true
    # 7 and 5 are html defaults and look better, but 6.3 is 16cm and so full-page width in word and usually submissions
    # Though 19 is Elsevier full page. And the pdfs will be what matters anyway.
    # Setting these still ends up with figs scaled 64% for some reason
    fig-width: 7.5 # 7
    fig-height: 5.4 # 5
    fig-dpi: 300
    reference-doc: default_word_template.docx
  html:
    embed-resources: true
    toc: true
    comments:
      hypothesis: true
  preprint-typst:
    # bibliographystyle: apa
    suppress-bibliography: false # true is default, but then no bib
    fig-width: 7.5 # 7
    fig-height: 5.4 # 5
  preprint-docx:
    # bibliographystyle: apa
    suppress-bibliography: false
    toc: false
    prefer-html: true
    fig-width: 7.5 # 7
    fig-height: 5.4 # 5
    fig-dpi: 300
---

```{r}
options(knitr.kable.NA = '')

```

```{r}
#| eval: false

# This should not be run, except to make a simple quarto
galenR::make_simpleyml(rstudioapi::documentPath())
```

```{r}
#| label: packages
#| include: false

library(HydroBOT) 
library(dplyr)
library(sf)
library(flextable)
library(ggplot2)
library(patchwork)
```

```{r}
set_flextable_defaults(font.family = 'Calibri',
                       font.size = 10,
                       table.layout = 'autofit')
```

```{r}
#| label: directories
#| include: false

# This depends on the same scenarios as the demo website, so give it the path to that. This will likely be user-specific. Everything else is relative.

#demo_webdir <- file.path('../HydroBOT_website')
demo_webdir <- file.path('~', '../Deakin University/QAEL - WERP in house - WERP/Toolkit/Writing/Demonstration paper')

# Why is the execute-dir not working?
# Outer directory 
project_dir = file.path(demo_webdir, 'demo_scenarios')  # '..', 

# Hydrographs
hydro_dir = file.path(project_dir, 'hydrographs')  

# EWR outputs
ewr_results <- file.path(project_dir, 'module_output', 'EWR')  

# outputs of aggregator
agg_results <- file.path(project_dir, 'aggregator_output', 'sdl_target') 
agg_results_min_timing <- file.path(project_dir, 'aggregator_output', 'min_timing') 
agg_results_median <- file.path(project_dir, 'aggregator_output', 'median') 


# outputs of aggregator
agg_results_gauge <- file.path(project_dir, 'aggregator_output', 'gauge_target') 

```

```{r}
#| label: data-subsets
#| include: false

gauges_to_plot <- c('412002', '419001')#, '422028', '421001')

scenarios_to_plot <- c("climatedown2adapt0", 
                       "climatedown2adapt250",
                      "climatedown2adapt6500",
                      "climatebaseadapt0",
                      "climatebaseadapt250", 
                      "climatebaseadapt6500",
                      "climateup2adapt0",
                      "climateup2adapt250",
                      "climateup2adapt6500")

radar_scenarios <- c("climatedown2adapt0", 
                      "climatebaseadapt0",
                      "climateup2adapt0")
```

```{r}
#| label: scenario-info
#| include: false

scenarios <- yaml::read_yaml(file.path(hydro_dir,                                     
                                       'scenario_metadata.yml'))

scenarios <- scenarios |>  
  tibble::as_tibble() |> 
  dplyr::rename('scenario' = "scenario_name")

# Add Georgia's scenario codes
scenarios <- scenarios |> 
  arrange(flow_addition, flow_multiplier) |> 
  group_by(flow_addition) |>
  mutate(climate_code = LETTERS[1:n()]) |>
  ungroup() |> 
  group_by(flow_multiplier) |> 
  mutate(adapt_code = 1:n()) |> 
  ungroup()

# set a sceneorder
sceneorder <- forcats::fct_reorder(scenarios$scenario,
                                   (scenarios$flow_multiplier +
                                      scenarios$flow_addition/100000))

# But we usually use the codes, so we need to order them too.
rename_sceneorder <- scenarios  |> 
  mutate(scenario = ifelse(scenario == 'MAX', 'MAX', 
                           paste0(climate_code, adapt_code))) |> 
  pull(scenario) |> 
  forcats::fct_reorder((scenarios$flow_multiplier +
                          scenarios$flow_addition/100000))
```

```{r}
#| label: data-import
#| include: false

# Now that the data is in, deal with the extra junk associated with unique scenario names, hence the str_remove_all

#Hydrographs- just read in the ones we use
scenehydros <- read_hydro(hydro_dir, 
                          scenariofilter = stringr::str_c(scenarios_to_plot), 
                          long = TRUE, format = 'csv') |> 
  mutate(scenario = stringr::str_remove_all(scenario, '.*0_')) |> 
  left_join(scenarios, by = 'scenario') |>
  rename(gauge_flow = gauge)|>
  tidyr::separate(gauge_flow, into = c("gauge", NA), sep = "_", remove = FALSE)

# The PUs overlap SDL units, and so we need to clip the others that get added
clipsdl <- function(x) {
  if ('SWSDLName' %in% names(x)) {
    x <- dplyr::filter(x, 
                       SWSDLName %in% 
                         c("Lachlan", "Namoi", "Macquarie-Castlereagh"))
  }
  
  return(x)
}

#Agg data (1.2 GB)
agged_data <- readRDS(file.path(agg_results, 'achievement_aggregated.rds')) |>
  purrr::map(\(x) mutate(x, 
                         scenario = stringr::str_remove_all(scenario, '.*0_'))) |> 
  purrr::map(\(x) left_join(x, scenarios, by = 'scenario')) |> 
  purrr::map(clipsdl)

agged_data_min_timing <- readRDS(file.path(agg_results_min_timing, 'achievement_aggregated.rds')) |>
  purrr::map(\(x) mutate(x, 
                         scenario = stringr::str_remove_all(scenario, '.*0_'))) |> 
  purrr::map(\(x) left_join(x, scenarios, by = 'scenario')) |> 
  purrr::map(clipsdl)

agged_data_median <- readRDS(file.path(agg_results_median, 'achievement_aggregated.rds')) |>
  purrr::map(\(x) mutate(x, 
                         scenario = stringr::str_remove_all(scenario, '.*0_'))) |> 
  purrr::map(\(x) left_join(x, scenarios, by = 'scenario')) |> 
  purrr::map(clipsdl)

# gauge-only for the network so we don't mix in space
agged_data_gauge <- readRDS(file.path(agg_results_gauge, 'achievement_aggregated.rds')) |>
  purrr::map(\(x) mutate(x, 
                         scenario = stringr::str_remove_all(scenario, '.*0_'))) |> 
  purrr::map(\(x) left_join(x, scenarios, by = 'scenario')) |> 
  purrr::map(clipsdl)


```

```{r}
#| label: flow-differences


# To get a single dimension for the scenarios, we can use the overall difference in flow. It's crude, but likely the only thing that works when we have an addition over part of the year and a multiplicative change. Those are fundamentally different, so we'll do our best

# This is baselining the *inputs*- the amount of flow. And so we have to do it here, not in plot_outcomes where we use it, since that baselines the *outputs* (EWR achievement)
dif_flow <- baseline_compare(scenehydros, compare_col = 'scenario',                                             base_lev = "climatebaseadapt0",
                             values_col = 'flow',                               
                             comp_fun = c("difference"),
                             group_cols = c('Date', 'gauge')) |> 
  group_by(scenario) |> 
  summarise(scenario_difference = mean(difference_flow)*0.001)

scenarios <- left_join(scenarios, dif_flow, by = 'scenario')

```

```{r}
#| label: palettes
#| include: false

# Qualitative
SDL_pal <- make_pal(unique(agged_data$sdl_units$SWSDLName), 
                    palette = "ltc::trio4")
                    # palette = "impressionist.colors::la_recolte_des_foins_eragny")

gauge_pal <- make_pal(unique(gauges_to_plot),                       
                      palette = 'ggsci::nrc_npg')

adapt_pal <- make_pal(as.character(unique(scenarios$adapt_code)),
                      palette = 'nationalparkcolors::Redwoods')

# descriptive networks
net_pal <- list(NodeType = 'nationalparkcolors::MtRainier')

# these have to use quantitative even though they're not, or we run out of colors.
env_pals <- list(EB = 'grDevices::Grays',
  EF = 'grDevices::Purp',
                NF = 'grDevices::Mint',
                NV = 'grDevices::Burg',
                OS = 'grDevices::Blues 2',
                WB = 'grDevices::Peach')

# easier printing if they have the class
make_colors <- function(x){
  class(x) <- 'colors'
  return(x)
  }

# use the first level of each of those to make a named pal. I wish there were an easier way
envgroup_pal <- purrr::imap_chr(env_pals,
                                \(x,y) make_pal(levels = y, palette = x)) 


Target_pal <- stats::setNames(envgroup_pal, 
            c(NA, 'Priority ecosystem function', 'Native fish', 'Native vegetation', 'Other species', 'Waterbirds')) |> 
  make_colors()

# Quantitative- sequential achievement
achieve_pal <- 'grDevices::Blue-Yellow'

# quantitative- diverging achievement (e.g. relative to baseline)
compare_pal <- 'scico::bam'

# We don't end up using scene_pal, I don't think. 
# Since there are two dimensions, maybe use faded colors? Should be able to bring that function over.
# But do that later
scene_pal <- make_pal(unique(scenehydros$scenario),                       
                      palette = "viridis::mako", #'ggsci::nrc_npg', 
                      refvals = 'base', refcols = 'black')


climate_code_pal <- stats::setNames(scene_pal[c(1, 4, 7)],
                                    unique(scenehydros$climate_code))

sceneTarget_pal <- stats::setNames(c(envgroup_pal, climate_code_pal), 
            c(NA, "Ecosystem function", 'Native fish', 'Native vegetation', 'Other species', 'Waterbirds', names(climate_code_pal))) |> 
  make_colors()

#Target Palette
sceneTarget2_pal <-  stats::setNames(c("#5F9776", "#5F9776", "#5F9776", "#5F9776", "#5F9776", "#4873B8", "#B7A447", "#FDC010", "#f47f51", "#2e3d5a", "#bf3729"), 
            c("Native fish", "Native vegetation", "Waterbirds", "Other species", "Priority ecosystem function", "End of system flows", "Water allocation", "Agricultural benefits", "Social benefits", "I", "E")) |> 
  make_colors()

sceneTarget2_pal
```

```{r}
#| label: move figs
#| include: false
file.copy(file.path(demo_webdir, 'images', 'GraphicalAbstract_small.png'), 
          file.path('images', 'graphical_abstract.png'),
          overwrite = TRUE)

file.copy(file.path(demo_webdir, 'images', 'GraphicalAbstract_small.eps'), 
          file.path('images', 'graphical_abstract.eps'),
          overwrite = TRUE)

file.copy(file.path(demo_webdir, 'images', 'Conceptual_fig_demopaper.png'), 
          file.path('images', 'Figure_1.png'),
          overwrite = TRUE)

file.copy(file.path(demo_webdir, 'images', 'Conceptual_fig_demopaper.eps'), 
          file.path('images', 'Figure_1.eps'),
          overwrite = TRUE)

file.copy(file.path(demo_webdir, 'images', 'Aggregations_General.png'), 
          file.path('images', 'Figure_2.png'),
          overwrite = TRUE)

file.copy(file.path(demo_webdir, 'images', 'Aggregations_General.eps'), 
          file.path('images', 'Figure_2.eps'),
          overwrite = TRUE)

file.copy(file.path(demo_webdir, 'images', 'aggregation_choices.png'), 
          file.path('images', 'aggregation_choices.png'),
          overwrite = TRUE)

file.copy(file.path(demo_webdir, 'images', 'aggregation_choices.pdf'), 
          file.path('images', 'aggregation_choices.pdf'),
          overwrite = TRUE)

file.copy(file.path(demo_webdir, 'images', 'aggregation_examples.png'), 
          file.path('images', 'aggregation_examples.png'),
          overwrite = TRUE)

file.copy(file.path(demo_webdir, 'images', 'aggregation_examples.pdf'), 
          file.path('images', 'aggregation_examples.pdf'),
          overwrite = TRUE)

file.copy(file.path(demo_webdir, 'images', 'architecture.png'), 
          file.path('images', 'architecture.png'),
          overwrite = TRUE)
file.copy(file.path(demo_webdir, 'images', 'architecture.eps'), 
          file.path('images', 'architecture.eps'),
          overwrite = TRUE)

file.copy(file.path(demo_webdir, 'images', 'aggNetworkdown_rel_illus.png'), 
          file.path('images', 'causal_rel_down.png'),
          overwrite = TRUE)

file.copy(file.path(demo_webdir, 'images', 'aggNetworkdown_rel_illus.pdf'), 
          file.path('images', 'causal_rel_down.pdf'),
          overwrite = TRUE)

file.copy(file.path(demo_webdir, 'images', 'aggNetworkup_rel_illus.png'), 
          file.path('images', 'causal_rel_up.png'),
          overwrite = TRUE)

file.copy(file.path(demo_webdir, 'images', 'aggNetworkup_rel_illus.pdf'), 
          file.path('images', 'causal_rel_up.pdf'),
          overwrite = TRUE)

file.copy(file.path(demo_webdir, 'images', 'aggNetworkdown_illus.png'), 
          file.path('images', 'causal_down.png'),
          overwrite = TRUE)

file.copy(file.path(demo_webdir, 'images', 'aggNetworkdown_illus.pdf'), 
          file.path('images', 'causal_down.pdf'),
          overwrite = TRUE)

file.copy(file.path(demo_webdir, 'images', 'aggNetworkbase_illus.png'), 
          file.path('images', 'causal_base.png'),
          overwrite = TRUE)

file.copy(file.path(demo_webdir, 'images', 'aggNetworkbase_illus.pdf'), 
          file.path('images', 'causal_base.pdf'),
          overwrite = TRUE)

file.copy(file.path(demo_webdir, 'images', 'aggNetworkup_illus.png'), 
          file.path('images', 'causal_up.png'),
          overwrite = TRUE)

file.copy(file.path(demo_webdir, 'images', 'aggNetworkup_illus.pdf'), 
          file.path('images', 'causal_up.pdf'),
          overwrite = TRUE)

file.copy(file.path(demo_webdir, 'images', 'aggNetworkCombined.png'), 
          file.path('images', 'causal_combined.png'),
          overwrite = TRUE)

file.copy(file.path(demo_webdir, 'images', 'aggNetworkCombined.pdf'), 
          file.path('images', 'causal_combined.pdf'),
          overwrite = TRUE)

file.copy(file.path(demo_webdir, 'images', 'aggNetworkRelativeCombined.png'), 
          file.path('images', 'causal_rel_combined.png'),
          overwrite = TRUE)

file.copy(file.path(demo_webdir, 'images', 'aggNetworkRelativeCombined.pdf'), 
          file.path('images', 'causal_rel_combined.pdf'),
          overwrite = TRUE)

file.copy(file.path(demo_webdir, 'images', 'network_structure_illus.png'), 
          file.path('images', 'all_causal.png'),
          overwrite = TRUE)



file.copy(file.path(demo_webdir, 'images', 'network_structure_illus.pdf'), 
          file.path('images', 'all_causal.pdf'),
          overwrite = TRUE)
# This is a placeholder to move conceptual figs, since it HATES spaces in names of the raw {fig} divs

```

# Highlights {.unnumbered}

-   The HydroBOT toolkit provides new management modeling capability for data and model integration, demonstrated for the Murray-Darling Basin.

-   HydroBOT synthesizes and assesses outcomes across disparate target values.

-   Scaling and synthesis of outcomes in space, time, and groups of values unlocks improved interpretation and decision making.

-   Scenario comparison, particularly impacts of climate and management adaptation, are primary uses.

-   HydroBOT emphasizes automation, transparency, and error detection for consistent repeatable analyses.

# Graphical abstract {.unnumbered}

![](images/graphical_abstract.png){#graphab width="16cm"}

# Abstract {.unnumbered}

Water management rarely focuses only on water; instead, management targets values across many water-dependent responses. To assess past performance and plan future actions, water managers need to understand how changes to hydrology (over which they typically have most control) affect water-dependent values. Models relating values to hydrology can be difficult to integrate into management processes; they are often developed for other uses and target subsets of values. We describe and demonstrate HydroBOT (Hydrology-dependent Basin Outcomes Toolkit), a modeling toolkit co-designed with the primary federal water management agency in the Murray-Darling Basin, Australia. HydroBOT can integrate disparate response models and scale and synthesize those results across space, time, and groups of values. Outputs target water management needs and can be tailored to a range of questions, from local, short-term evaluation to basin-scale climate assessment. HydroBOT provides new capacity to move beyond hydrology to assess outcomes across diverse target values.

# Key words {.unnumbered}

1\) Environmental flows; 2) Water management; 3) Hydrology; 4) Integrated management; 5) R package; 6) Synthesis

# Software availability {.unnumbered}

Software name: HydroBOT (Hydrology-dependent Basin Outcomes Toolkit). Developer: QAEL (Quantitative Aquatic Ecosystem Laboratory) led by Galen Holt. First year available: 2023. Program language: R, Python. Program size: 16 MB. Operation system: Linux, macOS, Windows. Availability: https://github.com/galenholt/HydroBOT License: MIT. Documentation: https://mdbauth.github.io/HydroBOT_website/

# Introduction

Water management in large river systems typically targets a wide range of desired values [@brown2009; @holling2001; @jones2016]. For example, in the Murray-Darling Basin (MDB), Australia, the objective of water management is to maintain a healthy working river that supports productive and resilient water-dependent industries, healthy and resilient ecosystems, and communities with access to sufficient and reliable water supplies [@murray-darlingbasinauthority2011]. These values, defined here as any social, economic, environmental or cultural asset or function of significance, importance, worth, or use, are not unique to Australia; water is managed to protect a diverse range of values worldwide [e.g. @kaye-blake2014; @stern2019; @ziolkowska2016; @connor2015]. That these values are the target of water management implies that each value depends on water in some way but, in many cases, dependencies are not well defined and so management targets water volumes and flow characteristics under the assumption dependent values will follow [e.g. @arthington2018; @mentzafou2023].

Water managers typically have a limited range of potential actions (levers) at their disposal. While the particular levers vary across jurisdictions, those that directly affect hydrology dominate [e.g. flow releases from dams or inundation of wetlands, @murray-darlingbasinauthority2011; @holt2024]. When non-hydrologic levers are available, such as water trading rules in the Murray-Darling Basin, their impact is still often assessed by how they alter hydrologic conditions – that is, their impact on the spatio-temporal patterns of flow in the system [e.g. @nswdpiemacq2020; @delwp2022]. Hydrologic modeling is often better-integrated with management workflows than models of other values [e.g. @king2000; @tharme2003; @shenton2012]. In part, this is due to the availability of large-scale physically-based numerical models that provide robust ability to simulate flows as they arise from natural drivers, such as rainfall, and describe infrastructure impacts including dams and diversions [e.g. @yang2017].

Though these models tend to have high precision, describe complex spatio-temporal physical relationships, and produce detailed outputs of state variables across time and space, they target relatively few primary outcome variables, e.g. streamflow, runoff, or snowpack [e.g. @regan2019; @cosgrove2024; @welsh2013]. In contrast, models of ecological or economic responses are often less detailed but must model a wide range of outcomes, including any number of species, ecosystem metabolism, or economic output from various sectors [e.g. @robson2014; @frota2021; @harrison2023]. The impact of given management actions (e.g. dam releases) on hydrology is well understood and captured by the hydrograph, allowing accurate targeting of particular aspects of the flow regime by management actions [e.g. @singer2007; @loire2021]. While these proximate models of system state and the impact of management actions are invaluable, they do not provide the necessary information to directly assess the status of the range of flow-dependent values.

Assessing values as they respond to flow and management actions requires models of these relationships. Such models exist, though their quality and extent vary widely, ranging from unstated mental models to highly-detailed population dynamics or economic models [@lester2019; @holt2024]. Quantitative computational models are often written in various languages by subject-matter experts, focus on one or a limited suite of target values, and return disparate outputs depending on their particular goals and approaches [@ryder2010]. These models are often designed with the aim of studying the dynamics of highly specific variables [e.g. fish population responses to anthropogenic change, @scheuerell2021], not to produce the most useful analysis for management questions or to capture the breadth of target values. Moreover, such targeted models typically cannot individually provide information about larger-scale values; for example, single-species models are insufficient to assess the condition of all fish or the whole ecosystem [e.g. @olden2014; @gawne2018].

Integrating distinct quantitative models into a holistic modeling approach is necessary to assess management-relevant outcomes of disparate, typically broad-scale, values under different hydrologic conditions and management actions. This integration gives each response model utility beyond its original purpose and identifies where new work is needed, such as where response models are limited or non-existent [@holt2024]. The creation of an integrated toolkit provides the opportunity for robust decision-making [@harrison2023], the ability to prioritize water planning across a range of values, and to identify conditions that achieve disproportionately large (or small) impacts, as well as the explicit consideration of synergies and trade-offs among different values.

Exemplifying these issues, the Murray-Darling Basin is centrally important to the economic, cultural, social and environmental wellbeing of Australia. Within the MDB, 70% of water is utilized for agricultural purposes [@hart2021]. Agriculture and tourism in the MDB contribute nearly 2% to Australian gross domestic product [@hart2021]. The MDB is home to 2.2 million people, including more than 50 Aboriginal Nations, and contains approximately 500,000 mapped water-dependent habitats [@hart2021; @brooks2021; @murray-darlingbasinauthority2023]. While balancing this range of values is difficult in any highly-utilized basin, the Murray-Darling is unusually dry and variable compared to other systems of similar importance [@bond2021].

Contemporary management of the MDB arises from the Commonwealth [@commonwealthofaustralia2007], which established the Murray-Darling Basin Authority (MDBA) with requirements to develop and implement a Basin Plan governing water resource management [@hart2021; @murray-darlingbasinauthority2011]. The MDBA has obligations to manage water to maintain a "healthy working river" [@murray-darlingbasinauthority2011]. The state of the MDB is required to be assessed annually, with a major review of, and updates to, the Basin Plan made at legislated intervals [e.g. 15 years between development and first review, @hart2021]. The MDBA does not itself deliver water; instead states within the basin have primary responsibility for water delivery and integrated catchment management, with the MDBA providing coordination and an overarching policy framework [@hart2021; @murray-darlingbasinauthority2019]. Other stakeholders (e.g. the Commonwealth Environmental Water Holder) have additional responsibilities for water management and coordination in the MDB.

The MDBA and other water managers in the Murray-Darling Basin have an increasing focus on assessing system response to climate change and management actions including climate adaptations that may be taken by the MDBA itself or other stakeholders in the MDB [@neave2015]. Taken together, the need for collaborative management across jurisdictions to deliver legislated requirements and manage into the future for a healthy working basin require a holistic modeling approach. Such an approach should integrate across values and be adaptable to these various management needs while also simplifying repeated, ongoing use. These needs are not unique to the MDBA; other water management groups, researchers and stakeholders have similar complex and competing needs [@campbell2016].

The MDBA has access to robust hydrologic models describing flows in the system and responses to current management practices and these models are under continual use, development, and improvement [e.g. @yang2017]. Despite the need for ongoing assessment and forward planning across a range of values, models of the responses to hydrologic conditions are patchy, only represent some values, and have been developed and used in a more *ad hoc* approach rather than integrated with each other or the hydrologic models [@olden2014; @gawne2018; @holt2024]. In this paper, we describe an integrated modeling 'toolkit', hereafter referred to as *HydroBOT* (Hydrology-dependent Basin Outcomes Toolkit), to integrate these disparate models and assess the response of a wide range of water-dependent values. Decision making for water management in a complex basin such as the Murray-Darling requires multiple lines of evidence and balancing competing values and sources of information. HydroBOT brings a more consistent and rigorous capacity to include the responses of water-dependent values into that comprehensive assessment.

HydroBOT greatly improves the capacity of the relevant manager (here, demonstrated for the MDBA) to assess outcomes across a range of values, provides the structure to adapt and include additional values as additional component models become available, and addresses a number of issues with current assessment practices and modeling approaches. By providing a single consistent interface to a range of response models, we avoid the need to manually run models separately and we abstract their different interfaces, languages, and idiosyncrasies. Moreover, the design is highly modular, built to allow the integration of new response models with limited additional updates to HydroBOT itself. Continuing with this consistency, HydroBOT provides a standard set of synthesis approaches and functions that target management-relevant analysis and interpretation of outcomes from these disparate models with a common approach and design language. This synthesis step provides the user much flexibility to target analyses and outputs to the relevant target values and management questions within a common framework. Because the need for assessing outcomes is nearly universal in water management and not limited to a particular scenario or project [@medema2008], HydroBOT is designed with strong scenario-comparison capabilities but is agnostic to what those scenarios represent. For a similar reason, the standardized synthesis and outputs are highly flexible, allowing the user to choose and tailor the most relevant outputs for different management needs.

In practice, modeling is almost never a one-off analysis of a single scenario. Instead, a wide range of scenarios are typically analysed and compared, and those scenarios may be updated even within a single project [@harrison2023]. Across multiple projects, the same modeling tools might be used to address vastly different questions, e.g. assessing response to potential future climate at continental scale *vs.* historical conditions at a small set of locations [@holt2024]. The onward analysis of those scenarios is also rarely static, needing to be updated as new questions are asked or preliminary results are tailored more closely to the questions. As is common with large data analysis workflows or software, repeated small changes often introduce errors especially in complex scripts [@wilson2014]. It is not unusual for a single project to include hundreds or thousands of repeated analyses over scenarios or sets of analysis options. HydroBOT provides facilities for automating these processes and documenting the code, critical for efficiency and reproducibility. Most importantly, HydroBOT shifts much of the complex data manipulation to tested software, while limiting user input to a small number of arguments related only to scenario configuration and analysis choices. This approach not only improves the ability to understand specific runs and reproducibility, but also dramatically reduces the incidence of inadvertent errors that arise from making small adjustments to large, complex scripts [@marwick2018].

One common issue with modeling in general, and particularly integrated models spanning several tools, is that such tools can become a black box where the relationships modeled are opaque. This can yield mistrust by the public and other stakeholders influenced by the model, but also mistrust and misunderstanding by users and developers of the model [@ascough2008]. To avoid these issues, HydroBOT has been continuously co-designed with the relevant management agency, the MDBA, with emphasis on public code, reproducibility, self-documentation and production of outputs that describe the model itself in addition to its results (e.g. causal relationships).

To demonstrate HydroBOT, we develop a set of example scenarios capturing some qualitative aspects of one intended use: the assessment and comparison of outcomes under different climate scenarios and different management adaptations to those changes. These scenarios represent changes to the system due to processes over which managers have no control (i.e. a changing climate), and management actions which would typically be targeted interventions. These scenarios are not intended to represent real climate change or proposed management actions; instead we use this demonstration to illustrate the problem space and show how HydroBOT can aid in assessing potential system change and prioritising management actions to mitigate impacts.

# HydroBOT description

HydroBOT provides a flexible architecture with distinct components that can be run separately (in a modular fashion) or together to assess how various scenarios, such as climate change or management options, affect multiple sets of values spanning many scales and disciplines. This modularity enhances the iterative nature of decision making for water planning and policy and allows tuning for a particular set of management questions (@fig-tktomgmt). Scenarios are typically represented by their effect on the hydrograph, though other inputs could be included if relevant (e.g. time series of variables such as temperature). HydroBOT then synthesizes a wide range of outputs from individual response models into results that directly compare scenarios and are digestible and useful for management decision making (@fig-tktomgmt). A co-design process including scientists, software developers, and managers was developed to ensure HydroBOT achieved its goal of producing scientifically robust results that are also management-relevant.

![Conceptualisation of HydroBOT architecture (blue arrows) and links to management decision making (yellow arrows). Scenarios, represented by hydrographs, reflect observed flows or modeled scenarios (produced via hydrological modeling outside HydroBOT). These hydrographs are fed in a consistent way to various response models via the HydroBOT Controller. These response models could assess response of any values of interest, here illustrated as a range of value types across environmental and human dimensions. Additional inputs of spatial data and causal networks provide grouping information for scaling via the HydroBOT Aggregator. The HydroBOT Comparer synthesizes the results into management-relevant outputs that aid decision making. This decision making process is also supported by feedback from stakeholders, other expert advice and the social and political landscape. Water planning and policy decisions can then guide the development of scenarios to assess potential management options which, in turn, can be assessed with HydroBOT.](images/Figure_1.png){#fig-tktomgmt}

## Architecture

Taken holistically, the HydroBOT architecture comprises three primary processing and control components (Controller, Aggregator, Comparer), three components that integrate models and data from elsewhere (Response models, Spatial data, and Causal networks), and the links between them (@fig-tktomgmt). The processing flow through HydroBOT is represented by the boxes along the top of @fig-tktomgmt, and in more detail in the Supplement (@suppfig-architecture). Input data (hydrographs) are ingested by the Controller, which packages and runs Response Models. Results from the Response Models are then processed by the Aggregator, and the analysis and final outputs are prepared by the Comparer. HydroBOT provides coordination of analyses through this workflow, as well as the algorithms within each component, providing needed functionality that can be tuned by the user with parameters for a particular analysis.

HydroBOT provides the tools and capacity to integrate disparate response models, which may be developed elsewhere, typically by subject-matter experts or for other purposes. Thus, the Response models component is depicted as being defined externally to HydroBOT (@fig-tktomgmt; @suppfig-architecture), and new response models require development to integrate them into compatible, modular HydroBOT components. Once integrated, HydroBOT can run those response models directly. Causal networks and Spatial units are also typically sourced elsewhere and sit outside the data flow. These components provide groupings and relational information necessary for the Aggregator and Comparer. Causal networks define the (sometimes) complex inter-relationships defined in the response models and subsequent impacts on larger-scale values, while Spatial units define relevant spatial scales. As such, they are typically chosen and sourced based on the response models used and desired spatial scales and locations of analysis.

The HydroBOT architecture emphasizes modularity. Outputs can be saved at each step in the processing flow, allowing users to run HydroBOT as a whole or re-run only needed components to update analysis. For example, if a user wished to change how they aggregate the results of the modules, they could re-run the aggregation step and the subsequent comparison step to match without re-running earlier steps. This ability to adjust intermediate steps allows rapid iteration of results to address a given management question, or adaptation of pre-existing results to new questions. Modularity also allows rapid, iterative development of HydroBOT itself. Any HydroBOT component can be updated, e.g. new aggregation functionality added, without affecting others. Obtaining new results utilising new capacity simply requires parameterising that capacity for a given analysis and re-running HydroBOT from that point forward.

Each step in HydroBOT is parameterized for a given analysis with arguments to a set of relevant functions, giving the user wide latitude to tailor an analysis to the input data, target values, and question at hand. As each stage of HydroBOT runs, it produces metadata files including the full set of parameters for that stage and all preceding stages. These files can be used as parameter files for subsequent runs to support reproducibility.

Here we describe the specific implementation of each component of HydroBOT (@fig-tktomgmt), with additional detail in Supplement. Each component of HydroBOT is distinct, allowing modular changes to be made without altering the function of other components.

### HydroBOT Controller {#sec-controller}

The HydroBOT Controller is the interface between the externally generated input data (i.e. scenarios), the chosen response model, and other external and internal HydroBOT components (SI @suppfig-architecture). This component initiates the downstream processing steps according to user-defined settings for a particular run. It includes arguments for locating the input data and the response model(s) to use, along with any necessary parameters for those models. The Controller can also control later components, allowing the full HydroBOT workflow to be run at once. These include defining aggregation steps as discussed in @sec-aggregator and analysis of the results with the Comparer (@sec-comparer). The Controller determines whether and where outputs are returned at each step. Having control over the full workflow enables large batched runs using parameter files (yaml) to specify the control arguments. This core functionality of the Controller is delivered via simple functions that apply to the input data for each scenario and can be parallelized over scenarios. The Controller can be accessed by the user by using Quarto notebooks to work interactively, R scripts, via the command line, or with yaml parameter files, depending on the use case.

### Response models {#sec-modules}

The impacts of climate and management options on social, cultural, environmental, or economic values are estimated based on causal relationships between drivers (e.g. hydrology) and responses (e.g. the state of values). The response models may exist in many different forms, ranging from binary achievement of hydrologic indicators to fully quantitative responses. To be included in HydroBOT, the minimal requirements are that they can be scripted, and return meaningful output values that can be tagged either internally or in post-processing with scenario information, though only the second is a requirement for their data to be used in later steps of HydroBOT processing (see @sec-aggregator).

These tools are expected to be sourced from existing or in-development models developed by subject-matter experts and, as such, will be written in different languages and will target different outcomes. HydroBOT then provides a unified interface and ongoing analysis and modeling of the response model results. HydroBOT seeks to avoid changing the response models themselves, but instead wraps them with lightweight input and output management to fit into the workflow. Specifically, to incorporate a new model, HydroBOT includes a wrapper function that passes necessary data locations, as well as any necessary arguments from the user to that model. At present, HydroBOT expects the user to provide input data in a format readable by the response model. Any data cleaning or formatting necessary to meet the response model requirements should be a preprocessing step. This allows HydroBOT to pass only paths to clean data, rather than the data itself, to the response models. HydroBOT then includes cleanup functions that save or return the outputs in formats usable by onward processing in HydroBOT. These formats are quite flexible, requiring only a data frame (or csv file) with output values and columns reflecting the spatial, temporal, and value dimension of those outputs and often a column indicating the scenario. Once these wrappers are in place, HydroBOT can directly run the incorporated response models within its own workflow.

Each response model has a distinct set of outputs, reflecting the captured responses and the structure of the model. When run within HydroBOT, these outputs are cleaned and processed into standard, expected formats for further processing, and metadata are saved. This enables HydroBOT to provide a consistent, unified home for disparate response models. The outputs can be saved to disk or retained in-memory for interactive use, depending on the user's needs. The outcomes of the response models are then processed by the Aggregator to provide outcomes at scales relevant for management decision making (in time, space or value dimensions; @fig-aggregation-dims). In some cases, e.g. proprietary software, HydroBOT may not itself run the response models, though this is less ideal. In that situation, the outputs of those models would need to be cleaned by the user, and the HydroBOT workflow could begin at the Aggregator step.

### Causal networks {#sec-causal_networks}

Causal networks describe the topology of dependence among many drivers and outcomes [@peeters2022; @martínez2019]. These networks provide useful graphical representation of the relationships between nodes (state variables) and links between them (dependencies). Beyond graphical representation, they can also extend the ability to assess a range of values beyond the response models themselves. Each link represents the existence of a relationship, and so defining those relationships mathematically allows causal networks to translate from initial inputs (e.g. rainfall, flows, or management actions) through to all values of interest (nodes). Thus, such networks are ideal for systems with multiple interacting relationships [@peeters2022; @martínez2019].

The specifications of the mathematical relationships underlying each link can be highly variable, depending on the state of the best available science or expert opinion. Some may be highly-detailed models, including both hydrologic models linking rainfall to flows or the response models themselves linking that hydrology to proximate response model outputs. Other links might be specified with simpler ecological models, simple averages, or even leaving the mathematical expression unspecified where relationships are hypothesized to exist but no information is available about the nature of the relationship.

Many response models capture only proximate responses, e.g. whether flow requirements were met. In these cases, causal networks describing the hypothesized links to target management values allows HydroBOT to model those management values. The network allows moving from those proximate outcomes to other relevant values by specifying the mathematical form of the links from the response model outputs to other nodes. This is not specific to HydroBOT; any quantitative assessment of those relevant values needs specified relationships from the outcomes of detailed response models to dependent target outcomes. The availability and detail of causal networks is variable, but use is increasing for assessing ecological risk from stressors [e.g. @vonderohe2014; @martínez2019], social responses to hydrology [e.g. @frota2021] and hydrology itself [e.g. @pang2024]. In cases where a causal network is not available for a particular location and response model, one can be created even if it is as simple as a conceptual diagram. Assessing the quality of knowledge around each link provides a powerful assessment of knowledge deficiencies and uncertainty in responses.

In the absence of such a network or a response model for the target values, HydroBOT can still analyse values at the scale returned by the response model. This analysis is likely beneficial; response model outputs are developed to be useful for some purposes and these can be assessed with HydroBOT. Where causal networks are available, even conceptually, they can be used to investigate outcomes at multiple value levels. The models implicit in the causal links can then be updated as more information is available. Indeed, in some cases with well-defined response models that link all the way from hydrology to desired management targets, the causal networks and the response models are the same, as they describe the pathways from driver (hydrology) through to relevant values. In these situations, describing the links in an explicit causal network is not necessary for the functioning of HydroBOT, though it is recommended to provide visualisation of the causal relationships encoded in the response model.

HydroBOT provides a causal network for included response models, where available, to describe how their outputs arise from hydrology and how they relate to various levels of management-relevant outcomes. The causal networks enable: 1) visual representation of the complex inter-relationships between scenario inputs and outcomes across a range of objectives and 2) assessment of outcomes scaled along the value dimension (see @sec-aggregator). The former aids transparency, elucidating the intentions and causal relationships behind the response models and is a useful device for communication alongside other final outputs. The latter allows outcomes to be quantified for individual (or sets of) values at different levels of complexity or groupings (e.g. fish breeding, individual fish species, native fish overall, or target fish condition), or at overarching sets of values such as environmental or economic groupings. This quantification provides a powerful assessment tool and the ability to identify synergies and trade-offs across interrelated values.

### HydroBOT Aggregator {#sec-aggregator}

Response model output is typically very granular in many dimensions because the best response models operate near the scale of the processes being modeled [@levin1992; @holt2016; @gawne2018]. In many cases, those processes (e.g. fish breeding, crop planting) individually occur at small spatial and temporal scales. Note that this is the scale of the process itself, but may be repeated and connected over much larger scales. For example, fish may breed across a basin and migrate among breeding locations but each female breeds in only one location at a given time. Moreover, outcomes from response models are typically at small value scales as well, e.g. capturing portions of the life cycle of a single fish species, rather than an overall outcome for all fish, or representing planting of particular crops, rather than overall agricultural output. The consequence is that there are potentially thousands of different modeled outcomes across time, locations, and values. This plethora of outcomes must then be aggregated to extract meaning at larger scales and condense the information for digestibility in management decision making.

The HydroBOT Aggregator aggregates and scales information to resolutions useful for interpretation and planning or that capture larger-scale processes. Depending on the use, the desired resolution(s) may range from local, short-term responses of fine-grained outcomes to large spatial scales over longer time periods for high-level outcomes such as environmental condition (@fig-aggregation-dims). For example, a response model might assess a suite of hydrologic indicators at individual gauges, but outcomes may be desired for a range of ecological groups within larger management units or at the basin scale. Likewise, multiple indicators are typically required to meet objectives for proximate ecological values, such as fish breeding, of which many are required for each larger ecological value (such as native fish diversity).

The HydroBOT Aggregator provides a robust, consistent aggregation approach along three dimensions (time, space, and value), while maintaining the ability to define those aggregation steps flexibly to meet the needs of the specific analysis and details of the inputs (@fig-aggregation-dims). The Aggregator allows the user to define value columns to aggregate, as well as any necessary grouping variables indicating e.g. scenarios, time, space, or value dimensions. As such, it is quite flexible, and can accept any dataframe where that information is specified. Thus, it does not require internal changes to accept outputs from new response models. This flexibility is by design, to be able to incorporate new outputs from new response models or aggregate outputs from response models that are unable to be fully integrated. Moreover, this modularity means the Aggregator is run on the outputs of the response models, and so adjustments to the aggregation step do not necessarily require re-running response models, yielding large computational savings as aggregations are adjusted and tailored during the course of a project.

The choice of aggregation steps and aggregation functions at each step are highly flexible. The aggregator consists of a set of functions that scale along each of the three dimensions while handling dimensional idiosyncracies, such as time arithmetic, spatial awareness, and many-to-many links in the causal network. Overarching functions coordinate these dimensional scaling functions, allowing stepwise aggregation along a sequence of dimensions and scales (@fig-aggregation-dims). These coordination functions maintain awareness of all dimensions; e.g. they ensure scaling in the spatial dimension does not accidentally collapse along the value or temporal dimensions. The structure of the aggregator functions provides these safeguards and capability for sequential multidimensional scaling, while giving the user control over the sequence of those steps and the scaling functions used at each step.

![Aggregation along multiple dimensions. HydroBOT provides flexible capability to aggregate along spatial, temporal and value scales. Boxes here show example scales, which may not all be used and which can be user-defined if others are needed. Users can control the sequence of steps along these axes, with the capability to switch between axes at different steps.](images/Figure_2.png){#fig-aggregation-dims width="18cm"}

The primary arguments to the aggregation functions are lists of the sequence of aggregation steps and the function(s) to apply at each step. The choice of aggregation sequence and scaling functions will change depending on the question being asked and the nature of the processes being modeled. For example, a project focused on expected conditions might use means at most steps, while one focused on risk might use minima to capture the worst outcomes or essential species requirements. To give the user the ability to tailor these steps to different questions, each step can be along any dimension and multiple functions can be assigned at each step. The sequence of aggregation steps can interleave the dimensions, e.g. aggregate first through time to cover the period of the hydrograph, then along the value dimension to an intermediate level, then aggregate in space, then value again. For example, following @fig-aggregation-dims, the user might want to aggregate from hydrologic indicator to life-cycle values, such as fish breeding, to species at each gauge, then aggregate those species outcomes up to catchment to assess performance of each species over a larger area, followed by aggregating to values comprising ecological groups, e.g. native fish, waterbirds, native vegetation, or ecosystem function.

HydroBOT provides a standard set of MDB-relevant spatial units for aggregation but can also accept any user-supplied polygons (@fig-aggregation-dims). Aggregation along the value dimension follows the causal network, which is supplied by HydroBOT for included response models, though the user can specify other causal relationships if required. Supplied spatial units and causal networks are discussed in SI @sec-component-details with additional information about providing custom versions in the HydroBOT documentation. Whatever the spatial and causal relationships, HydroBOT provides the capacity to scale along them; it is the responsibility of the user to ensure those links and scaling functions are scientifically sound for the question at hand.

The Aggregator allows the user to choose any aggregation function at each step. These aggregation functions should be considered carefully, as they should be appropriate to the processes being scaled and the outputs needed for management decision making. For example, in some situations the user might want to know the proportion of indicators that pass across some area, or perhaps the average value of an abundance measure. In this case, a mean would be appropriate. In other situations, however, a single failure may be disproportionately important (e.g. 'no loss' requirements), or perhaps a single passing value is sufficient for an ecological process to occur (e.g. bird breeding can occur anywhere in a catchment). These might be captured with a minimum and maximum, respectively.

HydroBOT provides a standard set of functions (e.g. mean, max, min, geometric mean, and spatially-weighted mean), but the user can also specify any other aggregation function, including custom-written functions tailored to particular analyses. The choice of aggregation at each step has large influence on the outcomes, and so HydroBOT does not prescribe the 'appropriate' aggregation, instead giving that control to the user. Where aggregation choices are not clear, or to assess the impact of these choices, HydroBOT can be run with different sets of aggregation sequences, with the outcomes of each compared using the Comparer as if they were scenarios.

The Aggregator self-documents into a yaml file, and its output datasets retain the full sequence and functions alongside each value, ensuring that values are always paired with their provenance and meaning.

### HydroBOT Comparer {#sec-comparer}

The HydroBOT Comparer is designed primarily to make comparisons between scenarios, including assessment and visualization of their differences. This component also provides generalized capacity to produce plots and other outputs such as tables using a consistent approach, even when not directly comparing scenarios. While the primary use of the comparer is comparing Aggregator output, hydrographs and direct Response model output can also use this functionality.

The functions within the Comparer can be divided into two main categories, those for analysis and those for plotting. Although in some instances presenting the absolute outcome values can be useful across scenarios, explicitly calculating comparisons (e.g. the absolute or relative difference between scenarios) provides distinct advantages. Difficulty in accurately simulating a complex system means that comparisons between scenario outcomes can be more useful and accurate because any bias in assumptions applies to all outcomes and the focus moves from the total level to the change between scenarios [@holt2024]. The best method for comparing will vary depending on the quantities being compared and the intended use of the comparison, so several common default options (e.g. differences, relative change) have been developed along with the flexibility for the user to define alternatives.

The comparison functions provide the ability to choose a baseline level for comparison, which may be one of the scenarios, but also may be a reference dataset or a scalar value. For example, we might want to compare a set of outcomes for climate scenarios to a 'no change' climate scenario, to historical observations, or to a mean value. Output values are calculated relative to the defined baseline level using either default functions for the absolute or relative difference, or any other user-supplied function. These functions can be applied to any dataframe, but a major advantage of HydroBOT is including them within the plotting functions. This allows the generation of comparison plots from raw Aggregator outputs without the need for subsequent data calculations by the user and avoids potential errors that arise from repeated or forgotten data transformations in an analysis workflow.

The plotting functions in the Comparer provide a wide range of possible plots, with standardization providing consistency across plot types and through the project, ensuring values plotted are robust and interpretable. Different purposes require different sets of outputs; for instance, maps are particularly useful for visualizing geographic patterns, tables and graphs typically provide more precise ability to assess impacts on values, and timeseries plots are useful for visualizing climate trajectories.

While potential visualizations and comparisons vary widely depending on the intended use, the Comparer standardizes data cleaning and processing for each plot, as well as aesthetics and plotting approaches. Like the Aggregator, a key advantage of the Comparer is the standardisation and dimensional safety over repeated data manipulations and processing. By standardizing data cleaning within the Comparer, we avoid losing information or performing unsupported data manipulations and so ensure the quality and meaning of the outputs. For example, because the plotting function was designed to incorporate temporal, spatial, and value dimensions, it identifies and prevents accidental overplotting or misleading lumping of data across dimensions.

## Implementation

HydroBOT is available as an R package, which provides a suite of functions representing the steps in the architecture. A documentation website provides additional worked examples and a fuller exploration of capacity and use-cases. HydroBOT functionality is designed to be general, allowing users much flexibility in how they run HydroBOT for a particular set of analyses while retaining a consistent structure and outputs. Because translating from hydrologic scenarios to various responses is a general problem in water management, we expect the ways in which HydroBOT is used will be highly variable. Thus, by providing a general structure, users can target particular questions and analyses needed for a given question. Although the initial impetus for creating HydroBOT was to assess climate scenarios, its use in practice can be far more general. Any hydrograph can be assessed, and any set of scenarios represented by hydrographs can be compared, provided a response model exists.

As a result of an initial scan of available response models in the Murray-Darling Basin, HydroBOT development proceeded with a single response model (written in Python), as this was the only module that met requirements (see @sec-ewr), but with an architecture designed to allow modular integration of additional response models as they become available. The scan accentuated a critical feature of this modularity; HydroBOT is designed to incorporate and standardize models written in various languages and with a wide range of input needs and outputs. HydroBOT achieves this by wrapping those other tools so as to make their differences as hidden from the user as possible.

In the case of Python modules, HydroBOT uses the *reticulate* R package [@ushey2023] in combination with small amounts of internal Python code to call Python modules directly. The Python code internal to HydroBOT performs limited cleaning and translation to prevent passing large objects between languages while ensuring that any idiosyncrasies in module inputs and outputs are handled consistently. Python dependencies (and Python itself) are automatically installed on first use of Controller functions that call Python modules unless they already exist on the user's system. This approach provides essentially invisible Python for most users, while providing flexibility for the user to provide their own Python environment if desired. Modules in other languages are not yet available, but the key requirement is that they be available in a format that is scriptable. In that case, HydroBOT will provide small setup and cleanup functions as with the Python modules and wrapper functions to call these modules.

The modularity of HydroBOT means it can be run stepwise, with the user calling the relevant functions at each step (@suppfig-architecture). The outputs of each step can be saved or returned directly to an interactive session or both. Typically, selected outputs would be saved for reproducibility and speed unless the project is small enough to retain a comprehensive set in memory or re-run quickly in a notebook. There are also wrapper functions that allow running the HydroBOT flow from Controller through Aggregator, which are extremely useful for large runs or remote runs on batching services. One particularly useful wrapper provides the ability to run from a yaml parameter file providing function arguments. This function allows the use of a default file and a 'modified run' file, making it ideal for holding many parameters constant at a default for a particular set of analyses and only changing a subset on a per-run basis in a smaller file. It also takes command-line or R list arguments, making it a flexible solution to run HydroBOT from the command line, in scripting contexts, or notebooks including Databricks and Quarto [@allaire2022].

The metadata saved at each step in the process is a yaml file with parameters that are a superset of those needed to run HydroBOT. Thus, an identical run can be produced by running HydroBOT using an output metadata file as an input parameter file, supporting reproducibility. Additional information is included in these exported yaml files documenting versions of HydroBOT and response models, as well as capturing any available metadata pertaining to the input scenarios. Even if a run is started in the middle, such as to re-run aggregation in a different way, the metadata for that run captures the metadata for the previous steps, ensuring that outputs at every stage are tagged with full provenance information.

In practice, HydroBOT functions are primarily run in one of two ways. Interactive investigation of relatively small sets of hydrographs and small numbers of scenarios can be done in notebooks (typically Quarto) or simple R scripts. Larger investigations typically would be run on remote computers as part of batching systems, whether HPC, Azure, AWS, Databricks, or other, with the outputs at the end of the aggregation (and potentially each step) returned. Through the aggregation step, all operations can proceed in parallel over scenarios, and HydroBOT provides internal capacity for this using the *future* package [@bengtsson2021]. In some cases parallelizing over gauges is also possible, though typically not recommended due to spatial dependence in many models.

The Comparer step would usually not be run as part of this larger batching, but considered interactively for two reasons. First, the Comparer necessarily looks across scenarios, and so breaks parallelization. Conducting comparisons interactively is typically not excessively CPU- or memory-intensive provided aggregation is sufficient to yield interpretable figures. Second, the primary goal of the Comparer is to produce usable, interpretable outputs. Arriving at a set of meaningful outputs is an iterative process that rarely will be precisely known *a priori*, and so working through this step interactively is usually necessary. If, however, HydroBOT is being used for ongoing monitoring of the same analyses (e.g. a ‘dashboard’), then the first iteration could be done interactively, with subsequent uses incorporating those settings written into a script, Shiny app, or similar to auto-generate the same figures.

If the outputs of the Aggregator step (and so the inputs to the Comparer) are large enough to require high processing or memory, it is unlikely to be simplified enough to make interpretable figures. Additional aggregation steps to better target desired figures (or subsetting of the data to focus on a particular aspect) should be undertaken. If, after careful consideration, a user does need to make processing or memory-intensive figures, these issues are due to the amount of data being plotted and so will not be unique to HydroBOT. Methods used for any other situation involving plotting large amounts of data with ggplot2 should then be considered, such as remote, high performance, or cloud computing. The first step, though, should be to ask whether additional aggregation is needed.

HydroBOT was originally designed for analyses of management questions in the Murray-Darling Basin and so, along with the functions to perform the analyses, it also provides a standard set of spatial data, including the boundary of the MDB itself, river lines, gauge locations (at which hydrographs may be available), and various management units (see SI @sec-component-details). All geographic information in HydroBOT uses spatial dataframes using the *sf* R package [@pebesma2023]. Thus, any user-supplied sf objects can be used for spatial aggregations.

Some example hydrograph data are also included for testing and demonstration. HydroBOT provides a clean causal network for included modules, described in more detail in @sec-causal_networks and SI @sec-component-details. Analogous elements can be constructed for other spatial units or responses to extend functionality within or outside the Murray-Darling Basin. Supplying new causal networks only requires providing dataframes or lists of dataframes with the needed levels and their relationships.

All plotting functions in the Comparer are built on the on the *ggplot2* R package [@wickham2016]. While the argument structure is changed to provide the necessary dimensional safety, processing consistency, and simplification of some common complex data processing, most of the ggplot functionality is available. Most importantly, the plotting functions produce ggplot objects that can be further modified by the user. This approach gives the user great flexibility in tailoring plots to the visualisation needs of a particular project.

## Co-design and scoping for management relevance

To ensure HydroBOT meets management needs and is trusted by management users, a team was created at project inception consisting of primary HydroBOT developers, ecologists, hydrologic modelers, and managers. Collaboration among this team ensured decisions about HydroBOT construction reflected the needs of the end-user. As implementation proceeded, the collaboration provided a mechanism by which goals could be adjusted or the implications of decisions discussed and understood. By having this window into HydroBOT development, the managers obtained a much more granular view of how it operates, along with its capabilities and limitations. This view into HydroBOT development and reasoning was crucial to avoid the toolkit becoming a 'black box', and enhances trust, interpretability and usability of the HydroBOT outputs.

Key to the collaborative development was identification of the response models to include. These models needed to provide information about values relevant to water management decisions. Early in the development process, a wide scan was taken to identify candidate response models. This scan considered models being used or developed within the MDBA itself, other government agencies (both federal and state), and externally. A number of response models were found to be available, but many were outdated or highly manual, and their use was patchy both within and across management agencies [@holt2022]. Ultimately, only one was suitably modern and well-developed to include in HydroBOT, the Environmental Water Requirements (EWR) Tool [@murray-darlingbasinauthority2024]. Other in-development modules were identified as candidates to include during the development of HydroBOT, including economic and social models. Further, this scan identified values that are mandated management targets for which there were no available or in-development response models, highlighting areas needing future work.

## Advantages and tradeoffs

Integrating new modules and shifting workflows into a new package always comes at a cost, and using HydroBOT is no exception. Repeatedly doing the same operatations suggests that those operations should be done in a software package, not a script [@wickham2025]. This is particularly true if many of those operations are checks or data manipulations to meet certain conditions, e.g. to handle multi-dimensional aggregation or compare scenarios in multiple ways [@wilson2014], as they are here. Thus, if a response model already produces outputs that are essentially finished, or if an analysis is a one-off that is unlikely to be repeated or adjusted, HydroBOT may not be needed. However, in our experience, if a response model produces outputs that provide useful management information, the running and onward processing are likely to be desired across a range of projects, as they have been for the EWR tool discussed here.

It is not unusual for a single project to require hundreds to thousands of runs, particularly when small tweaks and changes to the analysis are considered. These adjustments are a frequent source of error, particularly when multi-dimensional aggregation is involved, with quality control rapidly becoming unwieldy or impossible [@wilson2014]. Indeed, it is just these issues, compounded across different sets of scenarios and different management questions, that led to creation of HydroBOT as an end-to-end package. Allowing HydroBOT to handle that processing in tested, documented functions while keeping the analysis script short and clear provides advantages for readability, time, consistency, and correctness. Processing scenarios in the same way, as well as internal parallelisation provides similar advantages in terms of consistency and speed.

Integrating new response models into HydroBOT requires wrapper functions that send relevant arguments to the response model, and potentially (as is the case with the EWR tool), clean up the output of those models for onward processing by the Aggregator. These wrappers should typically be lightweight, performing only simple data formatting. However, it is also possible to forego complete integration and use the Aggregator and Comparer on the outputs of such response models. This approach would lose some advantages (e.g. scripting, automated metadata, parallelisation) but can be useful if the input integration is difficult, as might be the case with proprietary models or those with only GUI (non-scriptable) interfaces. The outputs would still need to be cleaned into an appropriate format for the Aggregator, though this process is rarely more onerous than would need to happen for analysis outside HydroBOT. Because of its generality, the Aggregator simply needs dataframes with columns of output values, any required grouping variables (e.g. scenarios), and those that link the values to the relevant spatial, temporal, or value dimension. This same information would be needed by most analyses. Similarly, while a new response model is likely to need its own causal network this would be needed for any analysis that aggregated along the value dimension. Spatial units are likely to be shared across models unless HydroBOT is being used in wholly-different locations. If they are needed, that would again be true of any spatial analyses with or without HydroBOT. Both causal networks and spatial data can be passed as arguments rather than needing to be incorporated into HydroBOT itself.

HydroBOT is not the answer for all projects and there are certainly tradeoffs. Our belief and experience is that the marginal cost of its implementation, combined with the advantages HydroBOT brings in terms of safety, reproducibility, and speed, make those tradeoffs fall in favor of HydroBOT quite quickly, when compared with conducting the same analyses outside HydroBOT (e.g. with a set of bespoke scripts). This investment is particularly worthwhile for informative response models with clear management importance such as the EWR tool demonstrated here. Once HydroBOT is set up, using it for new scenarios and new questions is straightforward and robust, enabling rapid exploration of new avenues of analysis not otherwise possible.

# HydroBOT demonstration {#sec-demo}

Here, we present example results produced using HydroBOT, a set of demonstration hydrological scenarios, and the EWR tool for the response model (see @sec-ewr for a description of the EWR module and its associated causal network). These results demonstrate the flexibility and robustness of HydroBOT, which give it the capability to produce rigorous but interpretable and management-relevant results in a reproducible way. The scenarios used here are developed to illustrate HydroBOT functionality with perturbed hydrographs that do not represent real flow scenarios. The plots shown here demonstrate several of the plot types designed to illustrate some potential visualisations relevant to these scenarios. Many more visualisations are possible due to the flexibility of the plotting functions, giving users the ability to generate plots relevant to different projects and questions.

## Demonstration scenarios

Our input data consists of hypothetical flow timeseries generated from historical hydrographs at `r length(unique(agged_data$ewr_code$gauge))` gauges. These gauges fall within the Lachlan, Macquarie--Castlereagh, and Namoi Sustainable Diversion Limit (SDL) units of the Murray-Darling Basin, Australia. These SDL units have detailed Long Term Watering Plans, and so well-specified environmental water requirements and causal networks (described in @sec-ewr).

We develop a set of simple scenarios that capture two sorts of changes that may be commonly represented in management analyses. First, we consider scaled flow throughout the period of the hydrograph, representing overall increases or decreases in flow as might occur from changes in large-scale climate patterns. Second, we consider short-duration additions to flow, representing periodic pulses of change as might happen from targeted interventions. Each scenario characterizes all water in the system including natural inflows, extraction, and release of environmental water, yielding a complete hydrograph (SI @sec-scenarios shows a selected subset). These do not reflect realistic future scenarios but provide an avenue to test and illustrate the capabilities of HydroBOT.

To scale flow, we apply nine flow multipliers, ranging from 0.5 to 2.0, to the historical hydrographs (@tbl-scenarios). We refer to these as 'climate' scenarios, reflecting a common representation where entire hydrographs might shift to represent climate change. Though these scenarios are not derived from climate models and do not represent hypothesized climate change, they do fall within the range of predictions from GCMs [@devanand]. To achieve pulsed change for each of the 'climate' scenarios, four flow additions were applied including 1) no addition, 2) addition of 250 ML/d, 3) addition of 6500 ML/d, and 4) addition of 12000 ML/d (@tbl-scenarios). These additional flows were added throughout the period of September to December to target the characteristics of specific environmental water requirements, as might be done by water managers. For example, there are 202 EWRs in the three catchments used here with flow thresholds above 250 ML/d starting in September, which the smallest addition would ensure are met. We refer to these scenarios as 'climate adaptations' because management options are often available in the form of altering water availability for short time periods through mechanisms like water releases, though the options here do not represent proposed actions. These scenarios should not be interpreted as potential climate impacts or adaptations, but instead as different ways flows might change (multiplicative or additive) and different magnitudes of change. The E1 scenario is the observed historical data with no climate change or adaptation options applied, and so is a natural baseline for comparisons.

```{r}
#| label: tbl-scenarios
#| width: 4
#| tbl-cap: Demonstration scenarios are a factorial combination of 'climate' (scaled flow) and 'adaptation' (pulsed additions). 'Climate' scenarios included in this demonstration were produced by applying a flow multiplier to historical flows. 'Adaptation' options were applied to each climate scenario with additional flows added throughout the period of September to December. For ease of display in some figures, we provide alpha codes for the 'climate' changes and numeric codes for the 'adaptations'. Mostly frequently, we present the ‘A’ (0.5 x historical flow), ‘E’ (1.0 x historical flow and ‘I’ (2.0 x historical flow) scenarios, with adaptions 1 (no flow addition), 2 (addition of 250 ML/d) and 3 (addition of 6500 ML/d) in most plots, with scenario 4 only appearing in heatmaps and smoothed fits.
#| message: false

adapt_scenes <- scenarios |> 
  filter(scenario != 'MAX') |> 
  mutate(flow_addition = as.integer(flow_addition)) |> 
  select(`Adaptation code` = adapt_code,
         `Flow addition (ML/d)` = flow_addition) |>
  distinct()

climate_scenes <- scenarios |> 
  filter(scenario != 'MAX') |> 
  select(`Climate code` = climate_code,
         `Flow multiplier` = flow_multiplier) |>
  distinct()

adapt_scenes <- adapt_scenes |> 
  bind_rows(tibble(`Adaptation code` = rep(NA, nrow(climate_scenes) - 
                                             nrow(adapt_scenes)),
       `Flow addition (ML/d)` = rep(NA, nrow(climate_scenes) - 
                                      nrow(adapt_scenes))))

climate_scenes |> 
               mutate(`Flow multiplier` = signif(`Flow multiplier`, 2)) |> 
  bind_cols(adapt_scenes) |> 
  flextable()  |> 
  font(fontname = 'Calibri') |> 
  fontsize(size = 10, part = 'all') |> 
  set_table_properties(layout = "autofit", width = 1) |> 
  vline(j = 2)

```

## Environmental Water Requirements (EWR) Tool {#sec-ewr}

The EWR tool, forming the core of this demonstration, is a response model for hydrologic indicators of ecological outcomes. The EWR tool is written in Python and is used internally by the MDBA, the states of New South Wales and Queensland for water planning, and other interested stakeholders [@murray-darlingbasinauthority2024; @sheldon2024]. It models the response of hydrologic indicators established in Long Term Watering Plans (LTWPs) and Environmental Water Management Plans [e.g. @dew2020; @nswdpiemacq2020; @delwp2022; @drdmw2022].

The EWR tool holds databases of the environmental water requirements (EWRs; the indicators), characterized by the discharge, frequency, timing and duration of flows or inundation (SI @supptbl-ewrs). These indicators were developed based on hypothesized relationships to the ecological objectives of the MDB, which protect or enhance environmental assets and ecosystem functions that are valued based on ecological significance [@sheldon2024; @nswdpiemacq2020]. The EWR tool assesses hydrologic indicators, determining whether spatially explicit flow timeseries meet each EWR (indicator) at each gauge (illustrated in @fig-ewr-example). The precise definitions for each EWR differ at each gauge, due to the unique hydrology and channel morphology. For example, a small fresh for 10 days is required every year between October and April to meet indicator EWR SF1 (small fresh 1), but the discharge defined as a 'small fresh' differs between gauges. Moreover, the expected ecological outcome for achieving SF1 might vary between gauges or catchments due to different impacts of small freshes on local species or ecological processes, as defined in the LTWPs.

```{r}
#| label: fig-ewr-example
#| fig-cap: !expr glue::glue("The flow levels of various EWRs are illustrated at two example gauges ({paste0(gauges_to_plot, collapse = ' and ')}) on historical hydrographs. Water levels crossing the lines indicate that the immediate flow level requirements are met. Flow requirements for some EWRs (OB4 and OB5) are never met for these hydrographs because flows do not get high enough, and so ecological responses dependent on these overbank conditions would not be expected to occur. This does not illustrate the required frequency, duration or timing for the EWRs; some of the lines crossed by the hydrograph here would not count as achieving the EWR if the flows did not stay above the relevant EWR line long enough or did not cross it again within the defined timeframe. See SI @supptbl-ewrs.")
#| message: false

ewrs_in_pyewr <- get_ewr_table() |> 
  rename(gauge = Gauge)

NSWEWR_gauge <- filter(ewrs_in_pyewr, gauge %in% gauges_to_plot) |>
  tidyr::separate_wider_delim(cols = Code, delim = '_', 
                              names = c("Code", "Timing"),
                              too_few = 'align_start',
                              too_many = 'merge') |>
  group_by(gauge) %>%
  distinct(Code, .keep_all = TRUE) |>
  mutate(FlowThresholdMin = as.numeric(FlowThresholdMin)) |>
  arrange(FlowThresholdMin) %>%
  mutate(Date = seq(from = max(scenehydros$Date), 
                    to = min(scenehydros$Date), 
                    length.out = n())) %>%
  ungroup()

hydro_plot_EWRs <- scenehydros |>
    dplyr::filter(scenario == 'climatebaseadapt0' & gauge %in% gauges_to_plot) |>
    ggplot2::ggplot(ggplot2::aes(x = Date, y = (flow/1000) + 1)) +
    ggplot2::geom_hline(data = NSWEWR_gauge, 
                        mapping = aes(yintercept = (FlowThresholdMin/1000) + 1),
                        color = "red")+ #
    ggplot2::geom_line() +
    ggplot2::facet_grid(gauge ~ . , scales = 'free') +
    ggplot2::labs(y = paste0("Flow (GL/day +1)")) +
    theme_hydrobot(legend.position = "bottom") +
      guides(color=guide_legend(nrow=2,byrow=TRUE)) +
    ggplot2::geom_label(data = NSWEWR_gauge, 
                        mapping = aes(x = Date, y = (FlowThresholdMin/1000)+1,
                                      label = Code), size = 3, color = "black") +
  # tempted to use 'pseudo_log' and not add 1, but the ticks aren't as nice
  ggplot2::scale_y_continuous(trans = 'log10',
                              sec.axis = sec_axis(~ . , name = "Gauge ID", 
                                                  breaks = NULL, labels = NULL))

hydro_plot_EWRs

galenR::ggsave_multi(file.path('images', 'Figure_3'), 
                     plot = hydro_plot_EWRs, 
                     device = c('png', 'eps'), 
                     width = 19, units = 'cm')
```

The EWR tool returns binary responses of hydrologic indicators. However, the LTWPs describe not only the indicator requirements assessed by the EWR tool, but also how those hydrologic indicators are expected to influence both proximate and larger-scale ecological outcomes according to the best available information from water managers, ecologists, scientific publications, and analysis of gauged and modeled flows [e.g. @nswdpiemacq2020; @lobegeiger2022]. We extracted these expected links from tables within the LTWPs for each planning unit, producing causal networks defining the expected relationships between the EWRs and several levels of ecological values. These clean causal networks are provided in HydroBOT (all links for a single gauge are shown in SI @suppfig-causal-example). While extracting these causal networks was a significant undertaking, it may not be for other response models that capture ecological values or if the hypothesized links are developed from the outset to be conceptualized causally and are machine-readable.

Causal networks link the hydrologic indicators produced by the EWR tool to the values for which the system is being managed. Thus, these networks greatly expand the utility of the EWR tool by allowing modeling of a range of ecological values dependent on those indicators. These values are defined at several levels, from components of the life cycle of single species to broad ecological groupings to whole-community outcomes at 10- or 20-year target dates (see SI @sec-glossary and @suppfig-causal-example). This increases the transparency in the causal relationships that underpin HydroBOT results and builds understanding and trust in the outcomes. For example, the SF1 indicator described above might contribute to multiple ecological objectives pertaining to native fish (ecological objectives NF1-9; e.g. NF1 = No loss of native fish species), native vegetation (NV1), and ecosystem functions (EF1-5). These ecological objectives are defined to support the completion of all elements of a life cycle of an organism or group of organisms (taxonomic or spatial) to achieve a "defined goal for a state, condition or characteristic of an ecological asset or function" [@nswdpiemacq2020 glossary]. Outcomes for ecological objectives are then linked in the causal network to five large-scale ecological groups [native fish, native vegetation, waterbirds, other species, and priority ecosystem functions, @murray-darlingbasinauthority2019] and are associated with long-term targets (5-, 10-, and 20-year). This structure not only provides a visual definition of the links in the LTWP, it also enables assessment of outcomes that are directly equivalent to the LTWP management strategies.

## Demonstration aggregations

The aggregation step is critically important for outputs and should be tailored to the values being aggregated and the questions being asked, as described in @sec-aggregator. The examples used here are designed for a simple demonstration; many other aggregations are possible, with the capacity explored in-depth on the documentation website. For any analysis, aggregation choices should be considered carefully. Since our purpose here is a simple demonstration, we use arithmetic means for nearly all aggregations. The exception is the first value dimension step (following temporal aggregation) due to the structure of the EWRs. In the EWR tool, the returned outcomes (and so finest scale on value dimension) gives achievement of multiple versions of EWR indicators, typically representing different leniency in flow conditions required to pass. Here, we consider that if any of the versions of an EWR is achieved, that EWR is achieved. We thus use a maximum for that aggregation step; first we obtain a time-average of each EWR version, and then we take the maximum of each of those versions (typically 1-4 values) to obtain the most-lenient outcome for that EWR. Specifying a different aggregation sequence would yield a different result and have different meaning (e.g. a minimum would require the most-strict version to pass, or we might skip this step entirely and treat the versions as fundamentally distinct indicators).

Though we use means for other steps, their interpretation changes depending on the level of aggregation. For simplicity, we assume the value of each outcome represents some 'condition', and the 'condition' at a particular level can be assessed as the mean of the conditions contributing to it. For example, the condition of detailed ecological values such as fish spawning or bird fledging might simply be the proportion of EWRs that contribute to each value that are achieved. Then, the condition of ecological groups, e.g. native fish, might be the mean condition over all the NF1...n values, despite those depending on different numbers and sets of EWRs. This captures the idea that native fish condition improves when the life-cycle components captured by constituent lower-level values are met, whether it takes 1 or 10 EWRs.

```{r}
#| label: simplfy-for-plots
#| include: false

# Create a grouping variable
obj_sdl_to_plot <- agged_data$sdl_units |>
  dplyr::mutate(env_group = stringr::str_extract(env_obj, '^[A-Z]+')) |>
  dplyr::filter(!is.na(env_group)) |>
  dplyr::arrange(env_group, env_obj)

obj_sdl_to_plot <- obj_sdl_to_plot |>
  mutate(Target = case_when(env_group == "NF" ~ "Native fish",
                            env_group == "NV" ~ "Native vegetation" ,
                            env_group == "OS" ~ "Other species",   
                            env_group == "EF" ~ "Priority ecosystem function", 
                            env_group == "WB" ~ "Waterbirds",
                            env_group == NA ~ NA))


# We can use spatial_aggregate directly to go straight to sdl from EWR without first averaging over env_obj or gauges. This gives a pure measure of the proportion ewr met in each sdl without issues of uneven contributions.
agg_ewr_sdl <- agged_data$ewr_code |> 
  spatial_aggregate(to_geo = sdl_units, 
                    groupers = c('scenario', 'climate_code', 'adapt_code'),
                    aggCols = ewr_achieved,
                    funlist = 'ArithmeticMean') |> 
  rename(ewr_achieved = spatial_ArithmeticMean_ewr_achieved)


```

## Demonstration outputs {#sec-outputs}

Here, we illustrate the outputs of HydroBOT for the demonstration scenarios and aggregations described above. Just as the aggregation steps demonstrate a small part of the capacity of HydroBOT, tailored for this example, so too do these figures demonstrate example capacity for a small subset of the potential outputs. Many more figures might be generated to address other questions or needs, with further detail available on the documentation website for HydroBOT. Moreover, because the outputs of the plotting functions are *ggplot* objects, additional bespoke tailoring is straightforward using the most common plotting package in R.

### Spatial relationships

Comparison of the direct outputs from the response model (in this example, pass/fail of EWRs) without any aggregation along the value dimension gives an overview of ecologically-relevant hydrologic outcomes at different locations (e.g. gauges) or areas (e.g. SDL units) to different scenarios (@fig-sdl-comparison; noting that these scenarios do not represent real climate simulations or proposed adaptations). Three focal 'climate' scenarios (A, E and I; 0.5x, no change, and 2x the historical base level, respectively) and three adaptation options (1, 2 and 3; additions of 0, 250 and 6500 ML/d, respectively) affect each SDL unit differently, with each catchment having some scenarios in which they have higher EWR achievement than the others. In all situations, the 'climate' (A, E, I) scenarios have less of an impact than the 'adaptation' (1, 2, 3) scenarios, though neither is reflective of expected change in these dimensions. The point here is simply that different types of changes to the hydrograph can affect locations differently. These outcomes are not linked to ecological values here (e.g. priority ecosystem functions or environmental assets) and so each hydrologic indicator (EWR) at each gauge is represented with equal importance, whether it is required for all ecological values or just one.

```{r}
#| label: map-setup
#| include: false
relevant_gauges <- filter(bom_basin_gauges,
                          gauge %in% unique(scenehydros$gauge))

relevant_sdl_units <- agged_data$sdl_units |>
  distinct(SWSDLName, geometry, .keep_all = TRUE)

# relevant_basin_rivers2 <- relevant_sdl_units |>
#   rename(sdl_geometry = geometry)|>
#   st_join(basin_rivers)
  
relevant_basin_rivers <-  basin_rivers |>
  st_intersection(relevant_sdl_units) |> 
  filter(ORD_STRA >= 4)
```

```{r}
#| label: fig-gauges
#| include: false



gauge_plot <- relevant_sdl_units |>
           plot_outcomes(outcome_col = 'SWSDLName',
              plot_type = 'map',
              colorset = 'SWSDLName',
              pal_list = SDL_pal,
              #underlay_list = list(list(underlay = basin,
              #                     pal_list = 'azure')),
              overlay_list = list(
                list(overlay = relevant_basin_rivers,
                                        pal_list = 'lightblue1'),
                list(overlay = relevant_gauges,
                                   pal_list = 'black')
                                   )) +
theme_hydrobot(axis.ticks = element_blank(), 
                   axis.text=element_blank(),
                   axis.title=element_blank())+
theme(legend.position = "none")+
  scale_x_continuous(limits = c(144, 151.5)) +
  scale_y_continuous(limits = c(-35, -29.7))+
  ggspatial::annotation_scale()

# gauge_plot

inset_map <- ggplot(ozmaps::ozmap_country) +
  geom_sf(fill = 'grey70') +              
  geom_sf(data = basin, fill = 'azure') +
  geom_sf(data = agged_data$sdl_units, color = 'NA', aes(fill = SWSDLName))+
  theme_hydrobot(axis.ticks = element_blank(), 
                     axis.text=element_blank(),
                     axis.title=element_blank())+
  coord_sf(ylim = c(-39.5,-9.5),
           # xlim = c(138, 154), # This is just the east, but doesn't actually fit well
           xlim = c(113, 154),
           expand = FALSE) +
  # scale_x_continuous(limits = c(113, 153)) +
  # scale_y_continuous(limits = c(-43.63, -9.22))+
  scale_fill_manual(values = SDL_pal)+
  theme(legend.position = "none") +
  ggspatial::annotation_scale(location = 'bl')


# overview_map <- gauge_plot +
#   patchwork::inset_element(inset_map, left = 0.01, bottom = 0.7,
#                            right = 0.4, top = 1)

```

```{r}
#| label: fig-sdl-comparison
#| fig-cap: (a) Location of the Murray-Darling Basin in eastern Australia. (b) Gauge locations within the three example SDL units (Macquarie--Castlereagh, Lachlan, and Namoi). (c-d) Scenario comparison for different Sustainable Diversion Limit areas emphasizing (c) quantitative differences and (d) spatial patterns. The proportion of environmental watering requirements (EWRs) that are achieved under each scenario for each SDL unit are shown. Climate scenarios and adaptation options as in @tbl-scenarios.
#| message: false

# The bars
sdl_achieve_bars <- agg_ewr_sdl |> 
  filter(scenario %in% scenarios_to_plot) |> 
  mutate(scenario = paste0(climate_code, adapt_code), # This makes the names clean
         SWSDLName = stringr::str_replace(SWSDLName, '–', '-\n')) |> 
  plot_outcomes(outcome_col = 'ewr_achieved',
                outcome_lab = 'Proportion\nEWR achieved',
                x_col = 'scenario',
                x_lab = 'Climate and adaptation scenario',
                colorset = 'SWSDLName',
                color_lab = '',
                pal_list = SDL_pal |> 
                  setNames(stringr::str_replace(names(SDL_pal), '–', '-\n')),
                position = 'dodge',
                setLimits = c(0,1)) +
  # guides(fill = guide_legend(nrow=2, label.position = 'top')) +
  theme(legend.position = 'bottom')

  # if we really want facetted, this will do it, but I don't think it's needed:  
# facet_col = 'scenario',
# scales = 'free_x',

# The map
sdl_achieve_map <- agg_ewr_sdl |> 
  filter(scenario %in% scenarios_to_plot) |> 
  plot_outcomes(outcome_col = 'ewr_achieved',
                outcome_lab = 'Proportion\nEWR\nachieved',
                plot_type = 'map',
                facet_row = 'climate_code',
                facet_col = 'adapt_code',
                colorset = 'ewr_achieved',
                pal_list = achieve_pal,
                #underlay_list = list(underlay = basin, underlay_pal = 'azure'),
                setLimits = c(0,1))

sdl_achieve_map <- sdl_achieve_map +
  theme(legend.position = 'bottom', 
        axis.ticks = element_blank(), 
        axis.text = element_blank()) +
  scale_y_continuous(sec.axis = sec_axis(~ . , name = "Climate scenario", 
                                         breaks = NULL, labels = NULL)) +
  scale_x_continuous(sec.axis = sec_axis(~ . , name = "Adaptation option",
                                           breaks = NULL, labels = NULL))

wrap_elements(full = inset_map) + wrap_elements(full = gauge_plot) +
wrap_elements(full = sdl_achieve_bars) + wrap_elements(full = sdl_achieve_map) +
  patchwork::plot_layout(nrow = 2, heights = c(5,10, 10)) &
  plot_annotation(tag_levels = "a")
# 
# wrap_elements((inset_map + inset_element(gauge_plot, 
#                            left = 0, bottom = 0.3, right = 0.65, top = 1, 
#                            align_to = 'full'))) /
#   (sdl_achieve_bars | sdl_achieve_map) +
#   plot_annotation(tag_levels = "a") +
#   patchwork::plot_layout()

# maplayout <- "
# AA##
# AACC
# BBCC
# BBCC
# "
# 
# free(wrap_elements((inset_map + inset_element(gauge_plot, 
#                            left = 0, bottom = 0.3, right = 0.65, top = 1, 
#                            align_to = 'full')))) +
#   sdl_achieve_bars + (sdl_achieve_map + theme(legend.title.position = 'top')) +
#   plot_annotation(tag_levels = "a") +
#   patchwork::plot_layout(design = maplayout)


galenR::ggsave_multi(file.path('images', 'Figure_4'),
                     device = c('png', 'eps'), 
                     width = 19, units = 'cm')
```

### High-level scenario comparisons

We use the causal networks to link these response model outputs to ecological outcomes and investigate how changes in flow affect ecological values at several levels of the 'value' dimension. Thus, we can compare how native fish, native vegetation, waterbirds, other species, and ecosystem function targets are likely to respond to our hypothetical set of multiplicative and additive changes to the hydrograph ('climate' and 'adaptation' scenarios; @fig-radar). Indeed, one of the primary purposes of HydroBOT is to provide this assessment of how high-level values respond to different scenarios. Such a summary collapses thousands of datapoints (EWR outcomes or proximate ecological responses at every gauge) across many scenarios into digestible yet scientifically-robust visualisations. At a glance, we can see in @fig-radar panel a that Priority ecosystem function outperforms Native vegetation in the halving (A) and no-change (E; historical hydrograph) scenarios, but is less sensitive to changes between scenarios. Halving water (moving from E to A) reduces Native fish outcomes more than doubling water (E to I) improves them, while the opposite is true for Waterbirds, and Other species respond roughly proportionally.

HydroBOT provides flexible aggregation sequences, allowing users to choose the options that best capture the nature of the data and the analysis needs. These choices can be interrogated with the Comparer to better understand their implications. For example, aggregating the 'versions' of the EWRs using the minimum (i.e. the strictest requirement for a given EWR) reduces the condition of all outcomes (@fig-radar panel b) compared to the case with the maximum in panel a. Using the median for all aggregations following an initial time average (panel c) yields much lower outcomes for the historical (E) and halving (A) climate scenarios, but idiosyncratic patterns in the doubling (I) scenario, with Waterbirds and Native Vegetation much lower than when using the means, while Other species is higher and Native fish and Ecosystem function show little change. These are relatively simple changes for the purpose of illustration; more complex aggregation functions or different functions used at different stages are likely appropriate in many situations. These choices should reflect the underlying biology (e.g. how do fish outcomes arise from the different set of flow conditions) and analysis questions (e.g. risk *vs.* resilience) and the consequences of these choices can be investigated as illustrated in @fig-radar or with other Comparer visualisations.

```{r}
#| label: make-radar
#| include: false

# Names dont match
agged_data$Target <- agged_data$Target |> 
  mutate(Target = ifelse(Target == 'Waterbird', 'Waterbirds', Target))
agged_data_min_timing$Target <- agged_data_min_timing$Target |> 
  mutate(Target = ifelse(Target == 'Waterbird', 'Waterbirds', Target))
agged_data_median$Target <- agged_data_median$Target |> 
  mutate(Target = ifelse(Target == 'Waterbird', 'Waterbirds', Target))

# Pretty should work better to just feed it the data, but it's not, so do a workaround to round up to the nearest 0.1
ymax = ceiling(filter(agged_data$Target, 
                  scenario %in% radar_scenarios & 
                    !is.na(Target) & 
                    grepl('Macq', SWSDLName))$ewr_achieved * 10) |> 
  max()/10
ymin = 0 #RELATIVE VERSIONS OF THIS PLOT WILL HAVE VALUES LESS THAN ONE

line_df <- tibble(y = c(ymin, ymax/2, ymax))

# Make background
background_df <- data.frame(Order = as.factor(seq(1, length(unique(agged_data$Target$Target)))),
                            Target =  factor(unique(agged_data$Target$Target),
                                             levels = unique(agged_data$Target$Target)), 
                            y = max(agged_data$Target$ewr_achieved),
                            scenario = unique(agged_data$Target$scenario)[1])|>
    mutate(Order = as.numeric(Target),
         Tshort = case_when(grepl('birds', Target) ~ 'WB',
                            grepl('fish', Target) ~ 'NF',
                            grepl('veg', Target) ~ 'NV',
                            grepl('Other', Target) ~ 'OS',
                            grepl('function', Target) ~ 'EF',
                            .default = NA))|>
  filter(!is.na(Target))


radar_plot <- agged_data$Target |>
  filter(grepl('Macq', SWSDLName))|> #
  mutate(Target = factor(Target),
         Order = as.numeric(Target))|>
  filter(scenario %in% radar_scenarios & !is.na(Target))|>
  ggplot(
      aes(
      x = reorder(stringr::str_wrap(Target, 6), Order),
      y = ewr_achieved,
      fill = climate_code)) +
  #Make background colors:
    geom_col(data = background_df,
           aes(x = reorder(stringr::str_wrap(Target, 6), Order), 
               y = ymax, fill = Target), color = NA, width = 1, alpha = 0.4)+
    geom_col(data = background_df,
           aes(x = reorder(stringr::str_wrap(Target, 6), Order), 
               y = ymin, fill = Target), color = NA, width = 1, alpha = 0.4)+
  # Make dashed lines:
  geom_hline(data = line_df,
    aes(yintercept = y),
    color = "grey40", linetype = "longdash"
  ) +
    geom_text(data = line_df,
    aes(label = y, y = y, x = "Waterbirds", fill = "Max"),
    nudge_x = 0.5, color = "grey20"
  ) +
  # Make scenario BARS - EWR achieved
   geom_col(position=position_dodge(), width = 0.65, linewidth = 0.3) +
  # Make arrows:
  geom_segment(
    aes(
      x = stringr::str_wrap(Target, 6), y = ymin, 
      xend = stringr::str_wrap(Target, 6), yend = ymax),  
    linetype = "solid", color = "gray20",arrow = arrow(length = unit(0.25, "cm"), type = "closed"), linewidth = 0.2) + 
  coord_cartesian(ylim = c(ymin, ymax))+
  # Make it circular:
  coord_polar() +
  theme_hydrobot(axis.ticks = element_blank(),
                     axis.text.y = element_blank(), # Leave .x, they label the arrows
                     text = element_text(size = 8), 
                     axis.title.x = element_blank(), 
                     axis.title.y = element_blank()) +
  scale_fill_manual(values = sceneTarget_pal,
                    aesthetics = "fill", breaks = c("A", "E", "I"), 
                    name = "Climate\nscenario")


radar_min_timing <- agged_data_min_timing$Target |>
  filter(grepl('Macq', SWSDLName))|> #
  mutate(Target = factor(Target),
         Order = as.numeric(Target),
         Tshort = case_when(grepl('birds', Target) ~ 'WB',
                            grepl('fish', Target) ~ 'NF',
                            grepl('veg', Target) ~ 'NV',
                            grepl('Other', Target) ~ 'OS',
                            grepl('function', Target) ~ 'EF',
                            .default = NA))|>
  filter(scenario %in% radar_scenarios & !is.na(Target))|>
  ggplot(
      aes(
      x = reorder(Tshort, Order),
      y = ewr_achieved,
      fill = climate_code)) +
  #Make background colors:
    geom_col(data = background_df,
           aes(x = reorder(Tshort, Order), 
               y = ymax, fill = Target), color = NA, width = 1, alpha = 0.4)+
    geom_col(data = background_df,
           aes(x = reorder(Tshort, Order), 
               y = ymin, fill = Target), color = NA, width = 1, alpha = 0.4)+
  # Make dashed lines:
  geom_hline(data = line_df,
    aes(yintercept = y),
    color = "grey40", linetype = "longdash"
  ) +
    geom_text(data = line_df,
    aes(label = y, y = y, x = "WB", fill = "Max"),
    nudge_x = 0.5, color = "grey20"
  ) +
  # Make scenario BARS - EWR achieved
   geom_col(position=position_dodge(), width=0.65, linewidth = 0.3) +
  # Make arrows:
  geom_segment(
    aes(
      x = Tshort, y = ymin, 
      xend = Tshort, yend = ymax),  
    linetype = "solid", color = "gray20",arrow = arrow(length = unit(0.25, "cm"), type = "closed"), linewidth = 0.2) + 
  coord_cartesian(ylim = c(ymin, ymax))+
  # Make it circular:
  coord_polar() +
  theme_hydrobot(axis.ticks = element_blank(),
                     axis.text.y = element_blank(), # Leave .x, they label the arrows
                     text = element_text(size = 8), 
                     axis.title.x = element_blank(), 
                     axis.title.y = element_blank()) +
  scale_fill_manual(values = sceneTarget_pal,
                    aesthetics = "fill", breaks = c("A", "E", "I"), 
                    name = "Climate\nscenario")


radar_median <- agged_data_median$Target |>
  filter(grepl('Macq', SWSDLName))|> #
  mutate(Target = factor(Target),
         Order = as.numeric(Target),
         Tshort = case_when(grepl('birds', Target) ~ 'WB',
                            grepl('fish', Target) ~ 'NF',
                            grepl('veg', Target) ~ 'NV',
                            grepl('Other', Target) ~ 'OS',
                            grepl('function', Target) ~ 'EF',
                            .default = NA))|>
  filter(scenario %in% radar_scenarios & !is.na(Target))|>
  ggplot(
      aes(
      x = reorder(Tshort, Order),
      y = ewr_achieved,
      fill = climate_code)) +
  #Make background colors:
    geom_col(data = background_df,
           aes(x = reorder(Tshort, Order), 
               y = ymax, fill = Target), color = NA, width = 1, alpha = 0.4)+
    geom_col(data = background_df,
           aes(x = reorder(Tshort, Order), 
               y = ymin, fill = Target), color = NA, width = 1, alpha = 0.4)+
  # Make dashed lines:
  geom_hline(data = line_df,
    aes(yintercept = y),
    color = "grey40", linetype = "longdash"
  ) +
    geom_text(data = line_df,
    aes(label = y, y = y, x = "WB", fill = "Max"),
    nudge_x = 0.5, color = "grey20"
  ) +
  # Make scenario BARS - EWR achieved
   geom_col(position=position_dodge(), width=0.65, linewidth = 0.3) +
  # Make arrows:
  geom_segment(
    aes(
      x = Tshort, y = ymin, 
      xend = Tshort, yend = ymax),  
    linetype = "solid", color = "gray20",arrow = arrow(length = unit(0.25, "cm"), type = "closed"), linewidth = 0.2) + 
  coord_cartesian(ylim = c(ymin, ymax))+
  # Make it circular:
  coord_polar() +
  theme_hydrobot(axis.ticks = element_blank(),
                     axis.text.y = element_blank(), # Leave .x, they label the arrows
                     text = element_text(size = 8), 
                     axis.title.x = element_blank(), 
                     axis.title.y = element_blank()) +
  scale_fill_manual(values = sceneTarget_pal,
                    aesthetics = "fill", breaks = c("A", "E", "I"), 
                    name = "Climate\nscenario")

```

```{r}
#| label: fig-radar
#| fig-cap: !expr glue::glue("Condition results for large ecological groupings and three 'climate' scenarios (color) and three different aggregation options (a-c). Visualising as a radar plot allows comparing outcomes of disparate thematic variables (as illustrated in the graphical abstract) and is useful for quick broad-scale representation of the results. Outcomes here for Macquarie--Castlereagh SDL unit. Dotted lines provide axis values, with the outer line corresponding to a condition of {ymax} and the center of the circle being a condition of {ymin}. One advantage of HydroBOT is the ability to specify aggregations relevant to a question, or to test the impact of different aggregation choices, reflected here in the different panels; a) Aggregation as described in the text, with means at each stage except where the 'versions' of EWRs use the maximum to get the EWR itself; b) As in a, except using a minimum of those versions and so the most stringent requirement for the EWR itself; c) Using the median at all steps other than the initial time-average.")
#| message: false
#| warning: false


triple_radar <- radar_plot / 
  (radar_min_timing + theme(legend.position = 'none') +
                                radar_median + theme(legend.position = 'none')) +
  plot_annotation(tag_levels = 'a') +
  plot_layout(heights = c(2, 1))

triple_radar

galenR::ggsave_multi(file.path('images', 'Figure_5'), 
                     plot = triple_radar, 
                     device = c('png', 'eps', 'pdf'), 
                     width = 16, height = 18, units = 'cm')
```

### Values at multiple levels of detail

High-level outcomes are essential, but managers need to drill down to understand how they arise, including comparing lower-level values, spatial areas, and the scenarios themselves. While there are many ways to display this information (See SI @sec-map-versions for spatial analysis of each step), @fig-obj-in-groups consolidates a large amount of information across scenarios, planning units, and multiple value scales. Each set of colors (and row of panels) represents outcomes at the scale of large ecological value groups. Within each bar, the different shades represent single smaller-scale ecological values (e.g. WB1; Maintain the number and type of waterbird species) contributing to the larger value group, with the heights of these shades being the proportion of the constituent hydrologic requirements that are met (EWRs). Because the overall bar heights are a sum of these proportions, we provide a dashed line as reference that shows the situation where all relevant EWRs are met. This reference is necessary because the number of EWRs contributing to each small-scale ecological value varies, as does the number of small-scale ecological values contributing to the larger ecological value groups and spatial units. Dividing total bar heights by this line would thus give the proportional 'condition' score for the larger groupings.

@fig-obj-in-groups provides a useful overview of the impact of different scenarios on large ecological value groups across space, while also retaining the ability to assess more proximate constituent ecological values. Each shade represents a unique smaller-scale ecological value, and so this view shows how those smaller values contribute to the overall condition at the larger scale without undue complexity. If an analysis needed to examine these contributions more explicitly, a different figure might be used to accentuate the lower-level environmental objectives more clearly (e.g. @suppfig-obj-detail, @suppfig-obj-waterbirds).

Though the scenarios here are only demonstrations, they illustrate the sorts of comparisons that are possible. For example, WB1 (Maintain the number and type of waterbird species) and WB2 (Increase total waterbird abundance across all functional groups) are only achieved to any appreciable extent in the Macquarie--Castlereagh in the high water addition (3) scenarios, while they are met more generally in the Namoi, and show an interaction with the 'climate' scenarios in the Lachlan (met in 'adaptation' scenarios 1 and 2 only in the doubled water 'climate' scenario). At the larger ecological value group scale, we can see that the effect of halving water (moving from the baseline E1 scenario to the A1 scenario) has a disproportionately greater impact on Native fish than doubling water (the I1 scenario) in the Macquarie--Castlereagh, while the Lachlan and Namoi show slightly larger impacts of doubling than halving.

```{r}
#| label: fig-obj-in-groups
#| fig-cap: "EWR achievement for broader ecological values, including: priority ecosystem function (EF), native fish (NF), native vegetation (NV), other species (OS) and waterbirds (WB) (color groups & rows). Columns stack all small-scale ecological values (e.g. WB1-5) (shades) that contribute to each broader ecological value (e.g. Waterbirds). This provides an assessment of the performance of individual small-scale values, as well as how those contribute to the overall sensitivity of the broader groups. Within each bar, different stacked shades represent single smaller-scale ecological values (e.g. WB1; Maintain the number and type of waterbird species) contributing to the larger value group. These values are distinct within each group; e.g. WB1 is not the same as NF1. Each small-scale value depends on a set of constituent hydrologic requirements (EWRs), with the heights of each individual shade being the proportion of these EWRs that are met. The full bar heights are then the sum of these proportions. Dashed lines represent full achievement of all constituent EWRs for all small-scale values. If all EWRs contributing to small-scale values were met, the columns would reach the lines. Not all EWRs are applicable in all locations and there are not equal number of EWR in each category, hence different values of the dashed lines. If the details of the smaller-scale ecological values were the focus of an investigation, more granular plots might be created that better differentiate these values for target larger-scale values, as illustrated in @suppfig-obj-detail and @suppfig-obj-waterbirds. This illustration includes three 'climate' scenarios: A (0.5x), E (historical base level/no change), and I (2x); and three 'adaptation' options: 1 (no adaptation), 2 (+250 ML/d), and 3 (+6500 ML/d). There are no EWRs contributing to 'Other species' in the Namoi. Columns for scenarios A1, E1, and I1 for Macquarie--Castlereagh correspond to values shown in @fig-radar panel a." 
#| message: false
#| warning: false
#| width: 19

obj_in_groups <- obj_sdl_to_plot |>
  filter(env_group != 'EB') |> # There's only one, this is just distracting.
  filter(scenario %in% scenarios_to_plot) |> 
  # clean the names
  mutate(scenario = paste0(climate_code, adapt_code), 
         SWSDLName = stringr::str_replace(SWSDLName, '–', '-\n'),
         Target = stringr::str_replace(Target, 'Priority e', 'E'),
         Target = stringr::str_wrap(Target, width = 12)) |> 
  plot_outcomes(outcome_col = 'ewr_achieved',
                outcome_lab = "EWR achievement\nstacked proportion achieved (shades)",
                x_col = 'scenario',
                x_lab = "Climate & Adaptation Option Scenario",
                colorgroups = 'env_group',
                colorset = 'env_obj',
                pal_list = env_pals,
                color_lab = "Ecological\nobjectives",
                facet_col = 'SWSDLName',
                facet_row = 'Target', 
                scales = 'free_y',
                sceneorder = rename_sceneorder
                )

# Just get max possible
maxdata <- obj_sdl_to_plot |> 
  st_drop_geometry() |> 
  filter(env_group != 'EB') |> # There's only one, this is just distracting.
  filter(scenario  %in% scenarios_to_plot[1]) |> 
  summarise(ewr_achieved = n(), .by = c(SWSDLName, Target)) |> # Get how many
  # clean the names
  mutate(SWSDLName = stringr::str_replace(SWSDLName, '–', '-\n'),
         Target = stringr::str_replace(Target, 'Priority e', 'E'),
         Target = stringr::str_wrap(Target, width = 12))

obj_in_groups <- obj_in_groups +
  geom_hline(data = maxdata, 
             mapping = aes(yintercept = ewr_achieved),
             linetype = 'dashed', color = 'grey30')

obj_in_groups + theme(legend.key.size = unit(0.5, 'cm'))


galenR::ggsave_multi(file.path('images', 'Figure_6'),
                     device = c('png', 'eps'), 
                     width = 19, units = 'cm')
```

### Quantitative scenario descriptions

Scenarios can often by described quantitatively, most obviously here in the flow multipliers used for 'climate' and flow additions used for 'adaptation', though these can also be combined to yield total flow rates. This quantification makes additional visualisations possible, as well as quantitative analyses to explore the impact changing water has on changing ecological values. The next three figures provide examples of different ways this might be done.

Calculating comparisons from a baseline clarifies disproportionate impacts and thresholds where management actions could be most effective. Here, we represent both our 'climate' (multiplicative) and 'adaptation' (additive) scenarios on a single axis by quantifying the difference in mean flow from the baseline condition (historical hydrograph, E1) using the baselining functionality provided by HydroBOT (see @sec-baselining). Plotting the proportion of EWRs achieved for each of the Native fish ecological values shows how that EWR achievement is related to changes in the overall levels of flow. One striking feature of @fig-difference-baseline is that the lines do not smoothly increase; EWR achievement is not simply a direct relationship to discharge. Instead, the timing matters. There are particularly steep slopes between the '1' (no-addition baseline) and '2' (+250 ML/d) 'adaptations'. The application of water at those particular times is thus disproportionately impactful in these example scenarios. Indeed, the 'A2' scenarios yield better outcomes than the 'E1' even though they have less water. The same is true for 'E2' compared to 'I1' in the Macquarie--Castlereagh and Namoi. Though these scenarios are not developed from real adaptation proposals, they identify real impacts of the timing of water additions. Such analyses can identify highly efficacious points to add water to the system, provided they represent real responses rather than model artefacts.

```{r}
#| label: fig-difference-baseline
#| fig-cap: "Quantitative scenario comparison for Native fish objectives for three SDL units. Scenarios defined here as the difference in mean flow (GL/d) from the baseline historical scenario (E1). The lines are not smooth because EWR achievement is not simply a function of the amount of water. Instead, the 'adaptation' options, which add water at particular times, particularly the '2' scenarios of adding 250 ML/d of water, have disproportionately large impact (steep slopes). Shading indicates different ecological objectives within the native fish ecological value. Three 'climate' scenarios are shown: A (0.5x), E (historical base level/no change), and I (2x) and three 'adaptation' options: 1 (no adaptation), 2 (+250 ML/d), and 3 (+6500 ML/d). HydroBOT provides in-built capacity for baselining with differences, relative change, or user-defined comparison functions. Difference was used here due to some additive flow changes, though relative would be a reasonable choice as well."
#| message: false


# We use dif_flow as a join here because this is baselining the *inputs*- the amount of flow. And so we have to do it here, not in plot_outcomes where we use it, since that baselines the *outputs* (EWR achievement)

gl_difference <- obj_sdl_to_plot |>
  dplyr::filter(scenario %in% scenarios_to_plot) |>
  dplyr::filter(env_group == 'NF') |> 
  left_join(dif_flow, by = 'scenario') |> 
  # clean names
  mutate(SWSDLName = stringr::str_replace(SWSDLName, '–', '-\n')) |> 
  
  plot_outcomes(outcome_col = 'ewr_achieved',
                outcome_lab = "Proportion EWR achieved",
                x_col = "scenario_difference",
                x_lab = "Mean flow difference (GL)",
                colorgroups = 'env_group',
                colorset = 'env_obj',
                pal_list = env_pals,
                # base_lev = 'E1',
                # comp_fun = 'difference',
                # group_cols = c('env_obj', 'polyID'),
                color_lab = "Ecological\nobjectives",
                facet_row = 'SWSDLName',
                facet_col = '.') 

gl_difference <- gl_difference + 
  geom_vline(data = filter(scenarios, scenario  %in% scenarios_to_plot),
             mapping = aes(xintercept = scenario_difference))

# This gets pretty close without needing the weird extra facet
# gl_difference <- gl_difference + 
#   geom_text(gl_difference$data |> filter(SWSDLName == "Lachlan"),
#             mapping = aes(label = scenario, y = Inf),
#             vjust = 1.5, size = 3)

header_difference <-  scenarios |> 
  filter(scenario  %in% scenarios_to_plot) |> 
  mutate(scenario = ifelse(scenario == 'MAX', 'MAX', 
                           paste0(climate_code, adapt_code)),
         scenario_difference = case_when(
           grepl('1', scenario) ~ scenario_difference -0.02,
           grepl('2', scenario) ~ scenario_difference + 0.02,
           .default = scenario_difference
           )) |> 
  ggplot(aes(x = scenario_difference,
             y = 1)) +
  geom_text(mapping = aes(label = scenario), size = 3) +
  theme_hydrobot(legend.position = "none", axis.title=element_blank(),
                     axis.text=element_blank(), axis.ticks=element_blank())

# put those together
header_difference + gl_difference + 
  plot_layout(ncol = 1, heights = c(1,15)) + theme(legend.position = "right")

galenR::ggsave_multi(file.path('images', 'Figure_7'), 
                     device = c('png', 'eps'), 
                     width = 19, units = 'cm')
```

```{r}
#| label: build-smooth-figs
#| include: false
sdl_smooth_groups <- obj_sdl_to_plot |>
  dplyr::filter(adapt_code %in% c(1,2,3) &
                  scenario != 'MAX') |> # max isn't really relevant here
  dplyr::filter(env_group != 'EB') |> 
  # mutate(ewr_achieved = ewr_achieved + 1) |> 
  # clean names
  mutate(scenario = paste0(climate_code, adapt_code), 
         SWSDLName = stringr::str_replace(SWSDLName, '–', '-\n'),
         adapt_code = as.character(adapt_code)) |>
  plot_outcomes(outcome_col = 'ewr_achieved',
                x_col = 'flow_multiplier',
                outcome_lab = 'Condition',
                x_lab = 'Flow relative to E1',
                transx = 'log10',
                transoutcome = 'log10',
                scales = 'free_y',
                
                color_lab = 'Adaptation',
                colorgroups = NULL,
                colorset = 'adapt_code',
                # point_group = 'env_obj',
                pal_list = adapt_pal,
                facet_row = 'env_group',
                facet_col = 'SWSDLName',
                position = position_jitter(height = 0, width = 0.02),                
                zero_adjust = 0.01, # needed here to make the trans work.

                base_list = list(base_lev = 'E1',
                                 comp_fun = 'relative',
                                 group_cols = c('env_obj', 'polyID')),
                smooth_arglist = list())

# This is better in some ways and worse in others, flippig the colors and facets
sdl_smooth_groups_flipped <- obj_sdl_to_plot |>
  dplyr::filter(adapt_code %in% c(1,2,3) &
                  scenario != 'MAX') |> # max isn't really relevant here
  dplyr::filter(env_group != 'EB') |> 
  # mutate(ewr_achieved = ewr_achieved + 1) |> 
  # clean names
  mutate(scenario = paste0(climate_code, adapt_code), 
         SWSDLName = stringr::str_replace(SWSDLName, '–', '-\n')) |>
  plot_outcomes(outcome_col = 'ewr_achieved',
                x_col = 'flow_multiplier',
                outcome_lab = 'Ecological objectives\nrelative to E1',
                x_lab = 'Flow relative to E1',
                transx = 'log10',
                transoutcome = 'log10',
                scales = 'free_y',
                
                color_lab = 'Ecological values',
                colorgroups = NULL,
                colorset = 'env_group',
                # point_group = 'env_obj',
                pal_list = list('scico::berlin'),
                facet_row = 'adapt_code',
                facet_col = 'SWSDLName',
                position = position_jitter(height = 0, width = 0.02),
                zero_adjust = 0.01, # needed here to make the trans work.

                base_list = list(base_lev = 'E1',
                                 comp_fun = 'relative',
                                 group_cols = c('env_obj', 'polyID')),
                smooth_arglist = list())

# just native fish in the Namoi
# This is better in some ways and worse in others, flippig the colors and facets
sdl_smooth_groups_NFNamoi <- obj_sdl_to_plot |>
  dplyr::filter(adapt_code %in% c(1,2,3) &
                  scenario != 'MAX') |> # max isn't really relevant here
  dplyr::filter(env_group == 'NF' & SWSDLName == 'Namoi') |> 
  # mutate(ewr_achieved = ewr_achieved + 1) |> 
  # clean names
  mutate(scenario = paste0(climate_code, adapt_code), 
         SWSDLName = stringr::str_replace(SWSDLName, '–', '-\n'),
         adapt_code = as.character(adapt_code)) |>
  plot_outcomes(outcome_col = 'ewr_achieved',
                x_col = 'flow_multiplier',
                outcome_lab = 'Condition',
                x_lab = 'Flow relative to E1',
                transx = 'log10',
                transoutcome = 'log10',
                # scales = 'free_y',
                
                color_lab = 'Adaptation',
                colorgroups = NULL,
                colorset = 'adapt_code',
                # point_group = 'env_obj',
                pal_list = adapt_pal,
                facet_row = 'Target',
                facet_col = 'SWSDLName',
                position = position_jitter(height = 0, width = 0.02),                
                zero_adjust = 0.01, # needed here to make the trans work.

                base_list = list(base_lev = 'E1',
                                 comp_fun = 'relative',
                                 group_cols = c('env_obj', 'polyID')),
                smooth_arglist = list())


# What if we really try to smash down what we're showing? The adaptations are blowing it out. Which is a good message, but confusing. Maybe it's a two-parter?
tarpal_wrap <- Target_pal
names(tarpal_wrap) <- names(Target_pal) |> stringr::str_replace('Priority e', 'E') |> stringr::str_wrap(width = 12)

# First, the climate response at no adaptation
sdl_smooth_clim <- obj_sdl_to_plot |>
  dplyr::filter(adapt_code %in% c(1) &
                  scenario != 'MAX') |> # max isn't really relevant here
  dplyr::filter(env_group != 'EB') |> 
  # mutate(ewr_achieved = ewr_achieved + 1) |> 
  # clean names
  mutate(scenario = paste0(climate_code, adapt_code), 
         SWSDLName = stringr::str_replace(SWSDLName, '–', '-\n'),
         Target = stringr::str_replace(Target, 'Priority e', 'E'),
         Target = stringr::str_wrap(Target, width = 12)) |>
  plot_outcomes(outcome_col = 'ewr_achieved',
                x_col = 'flow_multiplier',
                outcome_lab = 'Condition',
                x_lab = 'Flow relative to E1',
                transoutcome = 'log10',
                transx = 'log10',
                # scales = 'free_y',
                color_lab = 'Ecological values',
                colorgroups = NULL,
                colorset = 'Target',
                # point_group = 'env_obj',
                pal_list = tarpal_wrap,
                facet_row = 'Target',
                facet_col = 'SWSDLName',
                position = position_jitter(height = 0, width = 0.02),
                zero_adjust = 0.01, # needed here to make the trans work.

                base_list = list(base_lev = 'E1',
                                 comp_fun = 'relative',
                                 group_cols = c('env_obj', 'polyID')),
                smooth_arglist = list())

# Next, the adaptation response at no climate
sdl_smooth_adapt <- obj_sdl_to_plot |>
  dplyr::filter(climate_code %in% c('E') &
                  scenario != 'MAX' & 
                  flow_addition < 10000 ) |> # max isn't really relevant here, and 12,500 is a LOT
  dplyr::filter(env_group != 'EB') |> 
  # get the log to work, saying we added 1 is fine here
  mutate(flow_addition = flow_addition + 1) |>
  # clean names
  mutate(scenario = paste0(climate_code, adapt_code), 
         SWSDLName = stringr::str_replace(SWSDLName, '–', '-\n')) |>
  plot_outcomes(outcome_col = 'ewr_achieved',
                x_col = 'flow_addition',
                outcome_lab = 'Condition',
                x_lab = 'Flow addition (ML/d)',
                transx = 'log10',
                transoutcome = 'log10',
                scales = 'free_y',
                color_lab = 'Ecological values',
                colorgroups = NULL,
                colorset = 'Target',
                # point_group = 'env_obj',
                pal_list = Target_pal,
                facet_row = '.',
                facet_col = 'SWSDLName',
                position = position_jitter(height = 0, width = 0.02),
                zero_adjust = 0.01, # needed here to make the trans work.
                base_list = list(base_lev = 'E1',
                                 comp_fun = 'relative',
                                 group_cols = c('env_obj', 'polyID')),
                smooth_arglist = list())
```

With a large number of scenarios, we can characterize how values respond along axes relevant to how those scenarios change. Using smoothed fits, we show trends in the performance of ecological values (and groups thereof) in response to changes in flow from both 'climate' and 'adaptation' scenarios (@fig-smooth-climate-adapt, SI @suppfig-smooth-all). We use baselining (see @sec-baselining) to show the relative change on both the x (flow) and y (response) axes. Considering these relative changes on a log-log axis then illuminates whether doubling flow has the same impact as halving, and whether doubling (or halving) flow doubles (or halves) response. Thus, any slope other than 1:1 on the log-log axes represents a disproportionate impact of increases *versus* decreases in flow, and whether ecological condition shifts proportionately with flow.

The responses seen in @fig-smooth-climate-adapt vary between SDL unit (columns) and ecological values (rows), indicating different sensitivity to both 'climate' and 'adaptation' flow conditions across space and among ecological groupings. For example, Ecosystem function responds disproportionately positively on a multiplicative scale to flow across the range in the Lachlan (and so doubling flow more than doubles ecological condition ). Ecosystem function responds approximately proportionately to flow changes in the Namoi, and more strongly to decreased than increased flows in the Macquarie--Castlereagh. Native vegetation responds similarly to both increases and decreases in flow in the Macquarie--Castlereagh, while all other groups are both more sensitive to decreases than increases. By using smoothed fits, we can identify thresholds or areas of flow change that are disproportionately more important (i.e. where small changes in flow can yield large shifts in condition). Though the scenarios here do not represent real changes, these results do show disproportionate change across a range of flows; whether that is also true for realistic ranges would require a similar analysis of meaningful scenarios.

The response to 'adaptation' options (simulated seasonal water additions; difference between the lines in @fig-smooth-climate-adapt panel b) tends to be much stronger than the response to 'climate' (multiplicative changes to the whole hydrograph; slopes), even though the shift in total water may be lower (particularly for the baseline '1' and +250 ML/d '2' adaptations; see x-axis of @fig-difference-baseline). Moreover, the adaptation options are not equally sensitive to the climate scenarios; adaptation options '2' and '3' show less change in response to climate than '1' (no adaptation) (@suppfig-smooth-all). Thus, these 'adaptations' are increasing resilience to holistic 'climate' flow changes. Although these scenarios do not represent true adaptation options or climate scenarios, this shows that such changes to resilience are possible with targeted interventions, and HydroBOT provides the capacity to investigate them.

```{r}
#| label: fig-smooth-climate-adapt
#| fig-cap: Smoothed fits of shifts in condition (proportion of EWR achieved relative to the scenario with no climate or adaptation changes [E1]) of broad ecological values to relative changes in water availability (also relative to E1). (a)  All 9 'climate' scenarios (without adaptation; adaptation code 1) are included, ranging from halving to doubling flows (@tbl-scenarios). (b) The full combination of scenarios (all climate and adaptations options) are shown for the example of native fish in the Namoi (with each represented as a dot). The green points and line are the same as the Namoi Native fish panel in a. Panel b thus illustrates the larger impact of the seasonal additions ('adaptation' options) used here compared to the 'climate' shifts; differences between lines are greater than the change along the lines. The 'adaptations' also make the outcome less sensitive to 'climate' (the yellow and grey lines have lower slope than green). In all plots, both axes are presented on the log scale so multiplicative changes are correctly represented (i.e. halving yields the same axis distance as doubling). The multiplicative 'climate' scenarios in a and b range from halving to doubling flows, but outcomes over the range of flow changes varied between approximately 1/3x and 3x. Thus, the x-axis is extended to help visualize multiplicative proportionality of outcome changes relative to flow changes. We also add dashed lines at y = 0.5 and 2, which are the minumum and maximum multiplicative flow changes, to better see where outcomes have multiplicative changes outside these values. Slopes steeper than 1:1 and values outside these dashed lines indicate that outcomes multiply faster than flows, while shallower slopes indicate changes in flows result in less than proportional changes in outcomes. For example, doubling flows yields less than doubly-good outcomes. Nonlinear relationships mean that a multiplicative increase in flows (e.g. doubling) does not have the same impact as an equivalent multiplicative decrease (e.g. halving). In all plots, fitted lines are loess smooths. Y-axes are restricted to better visualize the majority of the data; thus, a small amount of data is not plotted but is accounted for in the loess fits. The full set of SDL units and groups as in b are shown in SI @suppfig-smooth-all. There are no EWRs contributing to 'Other species' in the Namoi.
#| message: false
#| warning: false


biglayout <- c(
  "AA#
  AAB
 AAB
  AA#"
)

target_legend <- sdl_smooth_clim +
  theme(legend.direction = 'horizontal', 
	        legend.key.size = unit(0.5, 'cm'),
	        legend.text.position = 'bottom', 
	        legend.title.position = 'top') 

target_legend <- target_legend |> 
  ggpubr::get_legend() |> 
  ggpubr::as_ggplot()

sdl_smooth_clim +
  coord_fixed(ylim = c(0.25, 4), xlim = c(0.25, 4)) +
  labs(y = 'Condition relative\nto E1') +
  geom_hline(aes(yintercept = 0.5), linetype = 'dashed', color = 'grey30') +
  geom_hline(aes(yintercept = 2), linetype = 'dashed', color = 'grey30') +
  theme(legend.position = 'none') +
sdl_smooth_groups_NFNamoi +
  coord_fixed(ylim = c(0.25, 4), xlim = c(0.25, 4)) +
  labs(y = 'Condition relative\nto E1') +
  geom_hline(aes(yintercept = 0.5), linetype = 'dashed', color = 'grey30') +
  geom_hline(aes(yintercept = 2), linetype = 'dashed', color = 'grey30') +
  theme(legend.position = 'bottom', 
        legend.key.size = unit(0.5, 'cm'),
        legend.text.position = 'bottom', 
        legend.title.position = 'top') +
# target_legend +
# guide_area() +
  plot_layout(design = biglayout) + 
  plot_annotation( tag_levels = 'a')

galenR::ggsave_multi(file.path('images', 'Figure_8'), 
                     device = c('png', 'eps'), 
                     width = 19, height = 18, units = 'cm')
```

Scenarios will often be defined along more than one axis. In this demonstration, we define a flow multiplication axis as a proxy for 'climate' shifts, and a flow addition axis as a proxy for 'adaptations'. Similarly, values often respond to several different aspects of the flow regime, for example the mean flow and the flow variance or the return interval of floods or low-flow periods. Heatmaps or contour surfaces provide a powerful tool for visualising these interacting responses (@fig-contour, SI @suppfig-heatmap). By examining multiple driver axes, such plots can highlight important interactions and identify where thresholds occur and where change along one axis (e.g. management actions, illustrated with our 'adaptation' options) can mitigate change along the other (e.g. 'climate' shifts). This ability to identify the axes that provide resilience or sensitivity to changes in others will be critically important for management uses of HydroBOT targeting climate change adaptation or efficient use of limited water. Such assessments must also take spatial and value differences into account; the different ecological values and geographical SDL units show very different patterns in how they respond to the interaction between the 'climate' and 'adaptation' scenarios (@fig-contour).

Perhaps most usefully, if scenarios are carefully developed to explore the range of potential change in the system, then the heatmap would represent the response surface of values over this range. Developing the response surface can be iterative, with subsequent scenarios developed to increase resolution near areas of rapid change in outcome. This approach differs from the usual approach of assessing only a small set of scenarios targeting specific proposed actions or environmental conditions [@marchau2019; @helgeson2020]. Instead, by covering the range to generate a response surface, it can provide hypotheses about how proposed scenarios might perform and assess how sensitive the outcomes are to uncertainty in single scenarios. Specific proposed scenarios could, of course, also be assessed and mapped onto the surface. For example, we might think of the flow multipliers here as defining the entire range of plausible 'climate' changes, and the additive changes as the entire potential range of 'adaptation' options. Then, specific proposed adaptations or climate sequences could be mapped onto the heatmaps in @fig-contour at particular points. The reverse is also possible; identification of areas of high sensitivity in the heatmaps could be used to choose a set of potential management actions designed to increase climate resilience. This idea extends to additional dimensions, which can then be collapsed in various ways (e.g. via principal component analysis, or by identifying dominant hydrometrics) to visualize with 2d heatmaps even when the response surface itself is best defined and studied in more dimensions.

```{r}
#| label: build-heatmaps
# Use the Target here to get to the big groups

# qualitative axes
qual_heatmap <- agged_data$Target |>
  dplyr::filter(adapt_code %in% c(1,2,3, 4) &
                  scenario != 'MAX') |> # max isn't really relevant here
  dplyr::filter(!is.na(Target)) |> 
  # clean names
  mutate(scenario = paste0(climate_code, adapt_code), 
         SWSDLName = stringr::str_replace(SWSDLName, '–', '-\n'),
         Target = stringr::str_replace(Target, 'Priority e', 'E'),
         Target = stringr::str_wrap(Target, width = 12),
         adapt_code = as.character(adapt_code)) |>
  plot_outcomes(outcome_col = 'ewr_achieved',
                outcome_lab = 'Condition',
                y_col = 'adapt_code', 
                y_lab = 'Adaptation option',
                x_col = 'climate_code', 
                x_lab = 'Climate scenario',
                plot_type = 'heatmap',
                colorset = 'ewr_achieved',
                pal_list = 'grDevices::Viridis',
                facet_row = 'Target',
                facet_col = 'SWSDLName')

# Quantitative axes- it's more informative, but uglier
quant_heatmap <- agged_data$Target |>
  dplyr::filter(adapt_code %in% c(1,2,3) &
                  scenario != 'MAX') |> # max isn't really relevant here
  dplyr::filter(!is.na(Target)) |> 
  # clean names
  mutate(scenario = paste0(climate_code, adapt_code), 
         SWSDLName = stringr::str_replace(SWSDLName, '–', '-\n'),
         Target = stringr::str_replace(Target, 'Priority e', 'E'),
         Target = stringr::str_wrap(Target, width = 12),
         adapt_code = as.character(adapt_code)) |>
  mutate(flow_addition = flow_addition + 1) |> 
  plot_outcomes(outcome_col = 'ewr_achieved',
                outcome_lab = 'Condition',
                y_col = 'flow_addition', 
                y_lab = "Flow addition ('adaptation')",
                x_col = 'flow_multiplier', 
                x_lab = "Flow multiplier ('climate')",
                plot_type = 'heatmap',
                transy = 'log10',
                transx = 'log10',
                colorset = 'ewr_achieved',
                pal_list = 'grDevices::Viridis',
                facet_row = 'Target',
                facet_col = 'SWSDLName',
                setLimits = c(0,1))

# interpolated raster- just one argument different
  # THe spacing is too uneven though
quant_interp_heatmap <- agged_data$Target |>
  dplyr::filter(adapt_code %in% c(1,2,3) &
                  scenario != 'MAX') |> # max isn't really relevant here
  dplyr::filter(!is.na(Target)) |> 
  # clean names
  mutate(scenario = paste0(climate_code, adapt_code), 
         SWSDLName = stringr::str_replace(SWSDLName, '–', '-\n'),
         Target = stringr::str_replace(Target, 'Priority e', 'E'),
         Target = stringr::str_wrap(Target, width = 12),
         adapt_code = as.character(adapt_code)) |>
  mutate(flow_addition = flow_addition + 1) |> 
  plot_outcomes(outcome_col = 'ewr_achieved',
                outcome_lab = 'Condition',
                y_col = 'flow_addition', 
                y_lab = "Flow addition ('adaptation')",
                x_col = 'flow_multiplier', 
                x_lab = "Flow multiplier ('climate')",
                plot_type = 'heatmap',
                transy = 'log10',
                transx = 'log10',
                colorset = 'ewr_achieved',
                pal_list = 'grDevices::Viridis',
                facet_row = 'Target',
                facet_col = 'SWSDLName',
                setLimits = c(0,1),
                contour_arglist = list(interpolate = TRUE))

# This would be better if we had a more even and tighter set of scenarios
  contour_heatmap <- agged_data$Target |>
  dplyr::filter(adapt_code %in% c(1,2,3) &
                  scenario != 'MAX') |> # max isn't really relevant here
  dplyr::filter(!is.na(Target)) |> 
  dplyr::mutate(Target = ifelse(Target == "Waterbird", "Waterbirds", Target))|>
  # clean names
  mutate(scenario = paste0(climate_code, adapt_code), 
         SWSDLName = stringr::str_replace(SWSDLName, '–', '-\n'),
         Target = stringr::str_replace(Target, 'Priority e', 'E'),
         Target = stringr::str_wrap(Target, width = 12),
         adapt_code = as.character(adapt_code)) |>
  mutate(flow_addition = flow_addition + 1) |> 
  plot_outcomes(outcome_col = 'ewr_achieved',
                outcome_lab = "Proportion\nEWR achieved",
                y_col = 'flow_addition', 
                y_lab = "Flow addition ('adaptation')",
                x_col = 'flow_multiplier', 
                x_lab = "Flow multiplier ('climate')",
                plot_type = 'heatmap',
                transy = 'log10',
                transx = 'log10',
                colorset = 'ewr_achieved',
                pal_list = achieve_pal,
                facet_row = 'Target',
                facet_col = 'SWSDLName',
                setLimits = c(0,1),
                contour_arglist = list()
  )

```

```{r}
#| label: fig-contour
#| fig-cap: Condition results visualized as a surface with the two scenario definitions on the axes. This approach allows visualising changes in outcome as the result of multiple axes on which scenarios might differ. These axes might be different aspects of scenario creation (as here), or they might be different axes describing the outcome of scenarios (e.g. two different hydrometrics such as mean flow and flow variance). There are no EWRs contributing to 'Other species' in the Namoi.
#| message: false

contour_heatmap

galenR::ggsave_multi(file.path('images', 'Figure_9'), 
                     plot = contour_heatmap, 
                     device = c('png', 'eps'), 
                     width = 19, units = 'cm')
```

### Outcomes on the causal network

Plotting the condition of each value directly on the network shows how condition changes across values at different scales (illustrated here for the historical \[E1\] scenario, @fig-causal-results). Perhaps most usefully, tracing through the causal network shows how higher-level outcomes result from the complex sets of dependencies on lower levels. For example, in the E1 scenario, the EWRs themselves (leftmost nodes) either nearly always fail (LF1 and above), or nearly always pass (SF2 and below). Many detailed ecological values (middle column) depend only on those EWRs that frequently fail, and so have very low condition (EF4 and above). In contrast, ecological values that depend on a range of EWRs (EF5 and below) show variable condition, depending not only on the values of those EWRs, but the mix of EWRs contributing to each. For example, EF5 has low condition because only two of its six dependencies had high condition, while EF1 has high condition because only one of its six dependencies had low condition. These outcomes then combine to yield larger-scale ecological value groups (rightmost column). Here, we can see that no detailed values contributing to Waterbirds has good condition, and so neither does the Waterbird group. In contrast, the other groups show a range of conditions reflective of the number and condition of their constituent lower-level values.

This network view provides a clear visualisation of the importance of the aggregation functions. By calculating the 'condition' at each step as the mean of the constituent values at earlier steps, the network connections act to smooth out impacts. While the EWRs themselves tend to have extreme values (leftmost nodes), they combine to yield more-similar values in the ecological groupings as they incorporate multiple contributing lower-scale values (@fig-causal-results). This smoothing is a feature of averaging, and occurs with spatial and temporal aggregation as well; it is simply more evident here because the networks show the steps in the process (see SI @sec-map-versions for a spatial example). Whether the mean is appropriate is an empirical question relevant for each particular use, and may vary within and between sets of analyses. Using a mean implies that adding more constituent nodes would increase resilience, as good condition for some would make up for poor condition of others. Using minima or maxima, for example, would have different biological meaning and management interpretation and would yield more persistent differences through the network. These decisions are critical for extracting meaning and interpretation and should be interrogated thoroughly to ensure they are appropriate for the particular analysis. HydroBOT encourages comparison of different aggregation choices to assess their impact, as we illustrate above in @fig-radar.

```{r}
#| label: network-setup
#| message: false
#| 
# NETWORK 1) demonstrates steps in aggregation, some relative results, for one gauge. This does not include spatial aggregation so we aren't mixing scales and bringing in data from other locations.

# for a single gauge
netgauge <- gauges_to_plot[1]

# # just get the theme-scale values
# # First we need the sequence lists
# 
aggparams <- yaml::read_yaml(file.path(agg_results_gauge,
                                      'agg_metadata.yml'),
                             eval.expr = TRUE) # not needed, but if the aggregations are sent as functions, this prevents a warning.

themeseq <- aggparams$aggregation$aggsequence[
  !names(aggparams$aggregation$aggsequence) %in%
    c('all_time', 'planning_unit', 'sdl_units', 'mdb')
]

# skip the _timing
# have to use the gaugefilter, or we get links not present at that gauge.
ewr_edges <- make_edges(dflist = causal_ewr,
                        fromtos = themeseq[2:length(themeseq)],
                        gaugefilter = netgauge)

# get the nodes
nodes <- make_nodes(ewr_edges)

aggvals <- extract_vals_causal(agged_data_gauge,
                               whichaggs = aggparams$aggregation$funsequence, # no need to filter, since only one path
                               valcol = 'ewr_achieved',
                               targetlevels = names(themeseq)[names(themeseq) !='target_5_year_2024'])

# filter to a single gauge. Multiple gauges should have separate networks or otherwize split the gauge-specific nodes. And include the larger scales pertaining to that gauge.

# if we stay within the gauge, and just do value, this works
aggvals <- aggvals |> 
  filter(gauge == netgauge) |> 
  st_drop_geometry()

# join to the nodes
nodes_with_vals <- nodes |>
  dplyr::filter(NodeType != 'target_5_year_2024') |>
  dplyr::left_join(aggvals) |>
  dplyr::filter(!is.na(scenario)) |>
  # Scenario metadata fell off, return it
  dplyr::left_join(scenarios, by = 'scenario') |>
  # clean up names
    dplyr::mutate(scenario = ifelse(scenario == 'MAX', 'MAX',
                           paste0(climate_code, adapt_code)),
         adapt_code = as.character(adapt_code))

# pre-filter to make plotting simpler
basenodes <- nodes_with_vals |>
  dplyr::filter(flow_multiplier %in% c(0.5, 1, 2) & 
                  flow_addition %in% c(0, 250, 6500)) |>
  baseline_compare(compare_col = 'scenario', base_lev = 'E1',
                   values_col = 'ewr_achieved',
                   group_cols = c('Name', 'NodeType', 'nodeorder'),
                   comp_fun = 'relative',
                   add_eps = 0.01) |>
  mutate(logrel_ewr_achieved = log(relative_ewr_achieved))
```

```{r}
#| label: make-networks
#| include: false
#| warning: false
#| message: false

# use a subset again
aggNetworkdown_rel <- basenodes |>
  dplyr::filter(flow_multiplier == 0.5 & flow_addition == 0) |>
  make_causal_plot(edges = ewr_edges,
                   # focalnodes = sampleenvobj,
                 edge_pal = 'black',
                 node_pal = list(value = compare_pal),
                 node_colorset = 'logrel_ewr_achieved',
                 render = TRUE,
                 setLimits = c(min(basenodes$logrel_ewr_achieved),
                               0,
                               max(basenodes$logrel_ewr_achieved)),
                 save = TRUE,
                 savedir = file.path(demo_webdir,'images'),
                 savename = 'aggNetworkdown_rel')


aggNetworkup_rel <- basenodes |>
  dplyr::filter(flow_multiplier == 2 & flow_addition == 0) |>
  make_causal_plot(edges = ewr_edges,
                   # focalnodes = sampleenvobj,
                 edge_pal = 'black',
                 node_pal = list(value = compare_pal),
                 node_colorset = 'logrel_ewr_achieved',
                 render = TRUE,
                 setLimits = c(min(basenodes$logrel_ewr_achieved),
                               0,
                               max(basenodes$logrel_ewr_achieved)),
                 save = TRUE,
                 savedir = file.path(demo_webdir,'images'),
                 savename = 'aggNetworkup_rel')

# GET LEGEND: THIS NEEDS TO BE INTEGRATED IN FUNCTION
thisbase <- basenodes |>
           dplyr::filter(flow_multiplier == 0.5 & flow_addition == 0)

pal_ggc <- thisbase |> 
ggplot(aes(x = relative_ewr_achieved, y = 1,
           color = relative_ewr_achieved)) + 
    geom_point() +
    paletteer::scale_color_paletteer_c(compare_pal,
                                       limits = c(min(thisbase$relative_ewr_achieved), 1/min(thisbase$relative_ewr_achieved)),
                                       trans = 'log10') +
  labs(color = 'Relative condition') +
  theme(legend.direction = 'horizontal',
        legend.title.position = 'top')


net_legend <- ggpubr::get_legend(pal_ggc) |>
  ggpubr::as_ggplot()

galenR::ggsave_multi(plot = net_legend, 
                     filename = file.path(demo_webdir,'images',
                                          'aggNetwork_relative_legend'),
                     device = c('png', 'pdf'),
                     width = 4, height = 2, units = 'cm')


```

```{r}
#| label: make-raw-networks
#| include: false
#| warning: false
#| message: false
aggNetworkbase <- basenodes |>
  dplyr::filter(flow_multiplier == 1 & flow_addition == 0) |>
  make_causal_plot(edges = ewr_edges,
                   # focalnodes = sampleenvobj,
                 edge_pal = 'black',
                 node_pal = list(value = achieve_pal),
                 node_colorset = 'ewr_achieved',
                 render = TRUE,
                 setLimits = c(0, 1),
                 save = TRUE,
                 savedir = file.path(demo_webdir,'images'),
                 savename = 'aggNetworkbase')

aggNetworkdown <- basenodes |>
  dplyr::filter(flow_multiplier == 0.5 & flow_addition == 0) |>
  make_causal_plot(edges = ewr_edges,
                   # focalnodes = sampleenvobj,
                 edge_pal = 'black',
                 node_pal = list(value = achieve_pal),
                 node_colorset = 'ewr_achieved',
                 render = TRUE,
                 setLimits = c(0, 1),
                 save = TRUE,
                 savedir = file.path(demo_webdir,'images'),
                 savename = 'aggNetworkdown')

aggNetworkup <- basenodes |>
  dplyr::filter(flow_multiplier == 2 & flow_addition == 0) |>
  make_causal_plot(edges = ewr_edges,
                   # focalnodes = sampleenvobj,
                 edge_pal = 'black',
                 node_pal = list(value = achieve_pal),
                 node_colorset = 'ewr_achieved',
                 render = TRUE,
                 setLimits = c(0, 1),
                 save = TRUE,
                 savedir = file.path(demo_webdir,'images'),
                 savename = 'aggNetworkup')

pal_gg_a <- thisbase |> 
ggplot(aes(x = ewr_achieved, y = 1,
           color = ewr_achieved)) + 
    geom_point() +
    paletteer::scale_color_paletteer_c(achieve_pal,
                                       limits = c(0,1)) +
  labs(color = 'Condition') +
  theme(legend.direction = 'horizontal',
        legend.title.position = 'top')


net_legend_achieve <- ggpubr::get_legend(pal_gg_a) |>
  ggpubr::as_ggplot()

galenR::ggsave_multi(plot = net_legend_achieve, 
                     filename = file.path(demo_webdir,'images',
                                          'aggNetwork_achieve_legend'),
                     device = c('png', 'pdf'),
                     width = 4, height = 2, units = 'cm')
```

![a) Condition outcomes for nodes at several levels along the value dimension described by the causal network. From left to right, the columns here represent EWR codes, proximate ecological values such as NF5 - Improve population structure for moderate to long-lived riverine specialist native fish species, and the larger ecological value groupings. The network shown here is for a single gauge (`r gauges_to_plot[1]`), which is the scale at which EWR codes and the small-scale values (middle column) are defined. The ecological theme value definitions (Native fish, etc) are not tied to gauges, but only those that apply to the EWRs present at this gauge are shown here. colors show condition of each value for the historical hydrograph (E1; no multiplicative or additive changes), with each node's condition being the mean of contributing nodes at lower (more leftward) levels. The minimum possible value is 0, and largest is 1.](images/causal_base.png){#fig-causal-results}

Visualising the causal network can also show the holistic consequences of the different scenarios across the complex and interrelated sets of values, as well as identify nodes that are unusually resilient or sensitive to change using comparisons with a baseline scenario (SI @sec-causal-scenarios). While the relative changes are a useful way of understanding change in condition for each node, they should not themselves be propagated through the network because they are nonlinear transformations and do not capture the meaning of the causal relationships. Instead, the condition scores (@suppfig-causal-all) capture the causal relationships between conditions at nodes as a consequence of conditions at constituent nodes within a scenario. Then, these condition scores are compared across scenarios to visualize differences (@suppfig-causal-relative).

Analysis of network structure, combined with aggregated values at each node, could identify critical nodes with outsized importance for outcomes at other nodes in the network. Any such nodes should be investigated to determine whether they capture key aspects of the system or are instead an artifact of model structure (possibly resulting from the way the network was developed) that may bias results. If their sensitivity does in fact capture the system, these nodes may be ideal targets for management intervention. The edges also identify the dependence between values, where we can see that different environmental outcomes depend on not only different hydrologic indicators (EWRs), but also different numbers or sets of those indicators. HydroBOT provides functionality to extract parts of the causal network relevant to a node or nodes, allowing more targeted visualisation and investigation of these effects.

# Implications

HydroBOT provides consistent, scientifically robust, and repeatable capacity to model responses to flow, producing management-relevant outcomes at multiple dimensions. This capacity provides a step change for management agencies such as the Murray-Darling Basin Authority to move beyond assessment of hydrologic outcomes and towards assessing the values that depend on that hydrology. Water managers must make decisions with the tools and information currently available, while also seeking to identify knowledge gaps to address for future decisions. Even where HydroBOT is lacking (e.g. additional response models, better knowledge of aggregation choices), it serves to accentuate this missing information, leading to improvements and acknowledgment of limitations. Attempting these models and identifying weaknesses is a far more robust basis for decision making than being unaware or ignoring these issues. Requirements such as those for a "healthy working basin" [@murray-darlingbasinauthority2011] that demand attention across socio-economic, cultural, and environmental values are commonly included in management plans for large basins [e.g. @usdepartmentoftheinteriorbureauofreclamation2012; @deltastewardshipcouncil2013; @ziolkowska2016; @connor2015], and reflect the interconnections of a range of values provided by these systems. Key to assessing this range of values is modeling their dependence on hydrology and other management levers, and aggregating the outcomes to management-relevant scales.

Large-scale natural resource management requires the capacity to make decisions relating to multiple spatial, temporal, and value dimensions, and is most successful when multiple scales within those dimensions are considered [@moore2021]. The HydroBOT aggregation and scaling framework can navigate those dimensions for water-dependent social, economic, environmental, and cultural values, even when the underlying response models are highly detailed. Combining such disparate information in a standard and comparable manner can illuminate synergies and trade-offs, which could be critical for decision making. Moreover, the scaling provided by HydroBOT condenses and synthesizes large numbers of complex outcomes to results tailored for interpretation for management questions, and provides consistency, rigour, and reproducibility. Our demonstration concerns the ecological values of the Murray-Darling Basin; however, the framework is equally applicable to social, economic, and cultural values and to other locations. HydroBOT itself has a modular design to incorporate disparate response models and spatial units.

Water management faces an increasing need and expectation for scientifically-sound and interpretable modeling from a range of stakeholders [@ryder2010; @gawne2018]. These issues are magnified when facing major long-range decision making to understand the impacts of climate change and potential policy or operational adaptations management agencies might undertake [@neave2015; @tonkin2019]. Co-design of HydroBOT with a diverse team within the Murray-Darling Basin Authority yielded distinct benefits to achieving these goals, with developers and researchers better understanding and building in the needs of the management agency, while the relevant managers better understand the limitations, uses, and potential of the tool. The focus on communication both within management agencies and to external partners, including model provenance, production of tailored synthesis figures, and causal networks, is a key outcome to build trust and understanding in HydroBOT as a tool and the results it produces. HydroBOT provides new capacity to assess a wide range of target values across scenarios and an exciting opportunity for continued advances and improvement with the development of new response models and climate scenarios.

# CRediT authorship contribution statement

Galen Holt\*: Writing -- original draft, review & editing, Visualization, Validation, Software, Methodology, Investigation, Formal analysis, Data curation, Conceptualization. Georgia Dwyer\*: Writing -- original draft, Visualization, Methodology, Investigation, Formal analysis, Conceptualization. David Robertson: Writing -- review & editing, Supervision, Conceptualization, Funding acquisition. Martin Job: Writing -- review & editing, Supervision, Conceptualization. Rebecca E Lester Writing -- review & editing, Supervision, Investigation, Conceptualization, Funding acquisition.

\*Holt and Dwyer co-first authors.

# Declaration of competing interest

The authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper.

# Acknowledgements

This research was supported through funding from the Australian Government Murray–Darling Water and Environment Research Program (MD WERP).

We thank Murray-Darling Basin Authority collaborators including Lara Palmer, Elisha Freedman, Tumi Bjornsson, Matt Coleman, and Joel Bailey for their assistance and support.

# Data availability

All data and their sources have been explained in the manuscript. HydroBOT code is available at github.com/galenholt/HydroBOT, and code to create this manuscript is available at github.com/galenholt/toolkit-demo-paper. Documentation with examples is available at github.com/MDBAuth/HydroBOT_website and an installation template at github.com/MDBAuth/HydroBOT_template. All are archived at 10.6084/m9.figshare.27605157. *Links are public. HydroBOT and paper code at submission are archived at https://figshare.com/s/699c18f781df7ed2f39d.*

# References

::: {#refs-main}
:::

{{< pagebreak >}}

# Supplementary material {#sec-appendix1}

## Glossary {#sec-glossary}

::: {#supptbl-glossary}
```{r}
#| message: false

gloss_tab <- readr::read_csv(file.path(demo_webdir, "definitions.csv"), show_col_types = FALSE)|>
  dplyr::filter(!is.na(Definition))

flextable(gloss_tab) |> 
  font(fontname = 'Calibri') |> 
  fontsize(size = 10, part = 'all') |> 
  set_table_properties(layout = "autofit", width = 1)

```

Glossary adapted from the Murray-Darling Basin Long Term Watering Plans (LTWPs) [@nswdpiemacq2020].
:::

## Component details {#sec-component-details}

The HydroBOT architecture comprises three major processing components, the Controller, Aggregator and Comparer, that receive data and information from several input sources, including input scenarios, hydrological modeling, spatial data, causal networks and response models (@suppfig-architecture, @supptbl-components). Here we detail some specific details about each of these components and other input sources.

![Architecture of HydroBOT. Hydrographs are inputs, typically reflecting modeled scenarios or historic flows. The flow of data during a modeling run follows the bold arrows, with the additional components of the Causal network and Spatial units providing necessary grouping information for the Aggregator. Dashed lines indicate that hydrographs and direct Response model output can utilize the Comparer functionality directly. Causal networks are linked closely to each Response model and, while both are defined externally to HydroBOT, they may require significant work to integrate into a compatible, modular HydroBOT component, as was the case for the EWR tool example here, or may be quite simple, depending on the detail available in the response model and their format. Spatial units are typically more general, often polygons of management interest, and require only light changes to make compatible. Each set of boxes represents a distinct component of HydroBOT, allowing changes to be made at any step in a modular way without impacting the functioning of other stages.](images/architecture.png){#suppfig-architecture}

::: {#supptbl-components}
```{r}

comp_tab <- readr::read_csv(here::here('component_table.csv'), show_col_types = FALSE)

comp_tab |> 
  # Too much text in the last col
  dplyr::select(-last_col()) |> 
  flextable() |> 
  font(fontname = 'Calibri') |> 
  fontsize(size = 10, part = 'all') |> 
  set_table_properties(layout = "autofit", width = 1)
```

Components of HydroBOT architecture. Input data is included here to discuss its properties, but is not part of the architecture proper, which consists of three workflow components and three integrated external components.
:::

### Included data

HydroBOT provides some datasets relevant for consistent spatial and value scaling in the Murray-Darling Basin. Spatial data includes sf objects (spatial dataframes using simple features, as implemented by the sf package, [@pebesma2023] for the Murray-Darling Basin, all gauges in the EWR tool, Sustainable Diversion Limit (SDL) units, Resource Plan Areas, Planning Units in New South Wales, and catchments defined by the Commonwealth Environmental Water Holder. These have all been prepared from relevant shapefiles from each agency. In addition, a riverlines sf object is provided for visualisation of the river network itself.

A causal network for the EWR Tool is provided, extracted from various sources including the EWR tool itself, New South Wales water managers, and Long-Term Watering Plans. This network includes levels for sub-EWR codes, EWR codes, environmental objective code, target groups, species or other specific goals, management objectives, and 5-, 10-, and 20- year management targets (see glossary @sec-glossary). Different levels are defined at different spatial scales; for example, the mapping from EWR code to particular fish species typically should happen within a planning unit or SDL unit, as that EWR code might map to a different species in another location.

### EWRs

The EWR tool tests whether hydrographs meet certain requirements set out in the Long Term Watering plans, typically regarding discharge or level, timing, and frequency of occurrence. An example for one gauge is in @supptbl-ewrs.

::: {#supptbl-ewrs}
```{r}
ewr_tab <- ewrs_in_pyewr |>
  dplyr::filter(gauge %in% gauges_to_plot[1]) |>
  dplyr::mutate(maxinter = signif(as.numeric(`MaxInter-event`), 1)) |> 
  # Why these? Same as Georgia had
  dplyr::select(Code,
                `Start month` = StartMonth, 
                `End month` = EndMonth,
                `Min flow (ML/d)` = FlowThresholdMin,
                `Max flow (ML/d)` = FlowThresholdMax,
                `Days per year` = Duration,
                `Consecutive days` = MinSpell,
                `Events per year` = EventsPerYear,
                `Target freq. (%)` = TargetFrequency,
                `Max freq. (%)` = TargetFrequencyMax,
                `Max inter-event` = maxinter)

whichcatch <- ewrs_in_pyewr |> 
  filter(gauge %in% gauges_to_plot[1]) |> 
  select(LTWPShortName) |> 
  distinct() |> pull()

ewr_tab |> 
    flextable() |> 
  font(fontname = 'Calibri') |> 
  fontsize(size = 10, part = 'all') |> 
  set_table_properties(layout = "autofit", width = 1) |> 
  align(align = 'right')
```

Environmental water requirements (EWR) for one example gauge (`r gauges_to_plot[1]`) in the `r whichcatch`. Start month, End month, and Min and Max flow define whether an event occurs. Days per year, consecutive days, and events per year determine whether enough events occurred during a year. Target frequency is the required number of years out of 10 with an event, while Max frequency is the maximum number of years out of 10 that can have an event. Max inter-event is the maximum number of years that can pass without an event.
:::

### Causal network

Causal networks are available linking the EWRs to other values. Here, we show a limited set for a single gauge, illustrating only some of the value levels that can be linked (@suppfig-causal-example). This network is derived from the New South Wales Long Term Watering plans [@nswdpiemacq2020].

![HydroBOT incorporates causal networks that describe the environmental objectives for a system. In the current example, these causal networks are extracted from the Murray-Darling Basin Long Term Watering Plans (LTWPs), which sets environmental watering requirements (EWRs), objectives, and long-term targets for key water-dependent plants, waterbirds, fish and ecosystem functions. From left to right, the columns here represent EWR codes, proximate environmental Objectives typically capturing portions of the life cycle or changes in abundance, species goals (which also include ecosystem components such as 'Refugia'), target ecological groupings, and 5-year management targets. The network shown here is for a single gauge (`r gauges_to_plot[1]`) and Planning Unit, which is the scale at which EWR codes and proximate Environmental Objectives are defined. The other levels are defined at larger spatial scales, but only those that apply to the EWRs present at this gauge are shown here.](images/all_causal.png){#suppfig-causal-example}

```{r}
#| eval: false
#| label: suppfig-causal-example-old
#| fig-cap: !expr glue::glue("HydroBOT incorporates causal networks that describe the environmental objectives for a system. In the current example these causal networks are extracted from the Murray-Darling Basin Long Term Watering Plans (LTWPs), which sets environmental watering requirements (EWRs), objectives, and long-term targets for key water-dependent plants, waterbirds, fish and ecosystem functions. From left to right, the columns here represent EWR codes, proximate environmental Objectives typically capturing portions of the life cycle or changes in abundance, species goals (which also include ecosystem components such as 'Refugia'), target ecological groupings, and 5-year management targets. The network shown here is for a single gauge ({gauges_to_plot[1]}) and Planning Unit, which is the scale at which EWR codes and proximate Environmental Objectives are defined. The other levels are defined at larger spatial scales, but only those that apply to the EWRs present at this gauge are shown here.")   

# edges <- make_edges(dflist = causal_ewr, 
#                fromtos = list(c('ewr_code', 'env_obj'), 
#                               c('env_obj', 'Specific_goal'), 
#                               c('Specific_goal', 'Target'), 
#                               c('env_obj', 'target_5_year_2024')),
#                gaugefilter = gauges_to_plot[1]) 
# 
# nodes <- make_nodes(edges)
# 
# 
# # To work with both html and word, save out and read back in.
# causal_example <- make_causal_plot(nodes,
#                  edges,
#                  focalnodes = filter(nodes, NodeType == "ewr_code")$Name,
#                  edge_pal = 'black',
#                  node_pal = net_pal,
#                  render = FALSE,
#                  save = TRUE,
#                  savedir = 'images',
#                  savename = 'causal_structure') 
# 
# # if (knitr::is_html_output()) {
#   # causal_example |> 
#   # DiagrammeR::render_graph()
# # } else {
# #   knitr::include_graphics("images/causal_structure.png")
# # }
# 
# causal_structure <- png::readPNG('images/causal_structure.png')
# causal_structure_grob <- grid::rasterGrob(causal_structure, interpolate = TRUE)
# patchwork::wrap_plots(causal_structure_grob)

```

## Aggregation choices

One of the key features of HydroBOT is aggregating responses in the space, time, and value dimensions. Best available science indicates that a flexible approach to aggregation is needed. Values are best combined in different ways, depending on their biological meaning, the management questions, and the dimension being summarized. Thus, a standard approach would produce misleading results and so HydroBOT provides flexibility in the aggregation sequence as well as the aggregation functions. Some common summary functions are built-in, e.g. `ArithmeticMean`, `GeometricMean`, `LimitingFactor` (equivalent to `Min`) and `CompensatingFactor` (equivalent to `Max`), though users can also define custom functions to meet new needs. More complex functions linking the nodes are also possible, such as population dynamics models. Those should be developed by subject-matter experts; our focus here is on simpler summary functions.

To illustrate the need for this flexible approach to aggregation, an example is useful. Consider two different environmental objectives, ‘no species loss’ and ‘successful bird breeding’. The most appropriate method to aggregate each is likely to be very different. To meet the ‘no species loss’ objective, all species must persist in all locations at all times (otherwise species loss will have occurred at one or more gauges). From an aggregation perspective, this means that locations, time steps and species cannot compensate for one another: the loss of a species at any point or in any location should cause the overall objective to fail. Given the manner in which the EWR tool functions, a mathematical minimum is likely to be the most appropriate method of aggregation to represent this set of circumstances. HydroBOT provides `Min` and `LimitingFactor` functions for this situation, which are named differently to reflect mathematical or biological interpretation but are otherwise identical.

In contrast, the ‘successful bird breeding’ objective should be aggregated using quite a different approach. Here, different species will have different requirements regarding a minimum interval between breeding events. These might range from one to five years, for example. For a given species, successfully breeding once within that interval would qualify as success, and so breeding is not necessarily required in all years or locations for the objective to be met. Thus, years can biologically compensate for each other, a situation captured by the built-in functions `CompensatingFactor` and `Max` (again, identical but with different names depending on whether the focus is biological or mathematical).

Different degrees of spatial aggregation will likely be required for different species in the bird breeding example. For example, for some species, successful breeding at one location in the Basin will be sufficient whilst, for others, localized breeding will not be sufficient. As with the ‘no species loss’ objective, successful breeding in one species can not compensate for a lack of breeding in another species. Thus, no compensation is possible across species but, within each species, success in some locations and some times can compensate for a lack of success at other locations or times. As a result, a mathematical maximum could be an appropriate aggregation method for the outputs of the EWR tool for the spatial extent and time frame for breeding, with each tailored to the relevant species’ requirements. Following this spatial and temporal aggregation, an arithmetic mean may be a useful way to combine species into a single aggregated ‘successful bird breeding’ objective, presuming good and bad conditions should be equally-weighted.

The built-in `GeometricMean` and `HarmonicMean` functions provide aggregations that capture the central tendency (unlike LimingFactor or CompensatingFactor), but weight low values more than high (unlike the equal weighting of `ArithmeticMean`) due to their multiplicative nature. Care should be taken, however, as a single zero in the set of values will result in an overall zero value. The geometric mean is particularly appropriate as a summary of multiplicative processes such as population growth rates through time. The harmonic mean is most appropriate if the output data represent ratios.

To ensure robust aggregation and reduce bias, HydroBOT begins aggregation sequences with the direct outputs of the response models, which are typically local, short-time, and small-value-scale objectives. By scaling the responses, we avoid the large potential biases created by nonlinear relationships between drivers and responses [Jensen’s inequality; @ruel1999]. Nonlinearities in later steps are also subject to Jensen's inequality, which is another reason for careful consideration. For example, using arithmetic temporal means of multiplicative population dynamics will incorrect long-run growth rates, while use of LimitingFactor aggregations can introduce inappropriate nonlinearities if used for outcomes that are interchangeable. The impact of Jensen's inequality is particularly important when using pass/fail outcomes because this is an extreme sort of nonlinearity and so is particularly susceptible to large errors.

### Choosing an aggregation function

There are no hard and fast rules for which aggregation functions should be used, as they should reflect the characteristics of the data, the processes being modeled, and the needs of the analysis. However, we note here some general features of different sorts of aggregation functions and when they might be appropriate. We focus here on simple summary functions, rather than more complex aggregation forms of which the options are essentially infinite and should be chosen based on expert knowledge.

There are a multitude of ways to summarize data, though in general for the sorts of summaries HydroBOT is used for, these largely fall into two groups; those that capture extreme values, and so only a single component determines the final value, and those that include information from all values. Examples of the former include maxima and minima, while the latter is often some measure of central tendency (a mean). A decision tree covering some of the most common choices is provided in @suppfig-aggregation-choices.

In the language of 'compensation', the maxima and minima represent full compensation and no compensation, respectively, while those summaries including information from all values reflect partial compensation. Where full compensation allows a good outcome (pass or high values) in one component to offset poor outcomes (fail or low values) in all other components, only the best outcome determines the aggregated value. Partial compensation allows good outcomes in one or multiple components to offset poor outcomes in other elements, but not completely – all outcomes contribute to the aggregated value. These outcomes may not contribute equally to the final value except in the case of the arithmetic mean. Nonlinearities in the aggregation functions (e.g. logs in geometric means or reciprocals in harmonic) can alter the extent to which high values can compensate for low, while the median also reduces the influence of extreme values. No compensation means that a poor outcome in one component cannot be offset by good outcomes in other components – only the worst outcome determines the aggregated value. An illustration of how the different functions yield different aggregated values is shown in @suppfig-aggregation-examples. In general, it is good practice to examine the implications of these choices on real data.

Two related considerations are often considered when summarising data

1.  the need to adjust the distribution of the data for good visualisation (e.g. taking logs to better see data spanning a range over several orders of magnitude)
2.  the need for the summary function to respect the properties of the processes or data being summarized (e.g. taking logs because the values represent a multiplicative process)

The second should generally take precedence, though often the final choice will be the same. Note also that some functions are nonlinear such as the geometric mean and the data itself might be as well, as is the case with the pass/fail outputs of the EWR tool or presence/absence data.

In context-specific instances, aggregation may require custom mathematical functions, but in most cases we expect that one of the default aggregation methods provided by HydroBOT (or similar base functions) will be most appropriate. We provide a decision tree to aid decision making for some of the most common choices, while noting that much has been written about appropriate ways to summarize data, and the usual considerations apply. Other functions are provided as well, including the `Sum`, `NumberOfValues`, and `Variance`. Weighted versions of these functions are possible, with `SpatialWeightedMean` provided for the common situation of weighting by area.

![There are infinite possibilities for each aggregation step, but the reasons for choosing some common options are shown here. The primary splits are in whether a user is interested in extreme values (full or no compensation) or whether all values should contribute to the final outcome. If the latter, how those values combine should then take into account desired data transformations or the underlying processes in choosing the summary. Blue boxes are decision points, purple are the functions included with HydroBOT that could be used. Other functions re included and not shown here, which generally address different sorts of questions, e.g. sums, variance, or the number of values. Examples of the outcome of these different functions are shown in .](images/aggregation_choices.png){#suppfig-aggregation-choices}

![To illustrate the influence of the choice of aggregation function, we illustrate the outcome of those in for aggregating a small set of four values (top boxes). Each of the bottom boxes is the single aggregated value according to the function labeled below. We do no include zero in the set of top values, as a single zero forces the Geometric and Harmonic means to equal zero due to their multiplicative nature.](images/aggregation_examples.png){#suppfig-aggregation-examples}

## Scenarios {#sec-scenarios}

::: {#suppfig-hydrographs}
```{r}
#| message: false

hydro_plot <- scenehydros |>
    dplyr::filter(scenario %in% scenarios_to_plot & gauge %in% gauges_to_plot) |>
  dplyr::mutate(flow = flow/1000) |> 
  plot_outcomes(outcome_col = 'flow',
                outcome_lab = 'Flow (GL/day)',
                x_col = 'Date',
                colorset = 'gauge',
                color_lab = 'Gauge ID:',
                pal_list = gauge_pal,
                facet_row = 'climate_code',
                facet_col = 'adapt_code',
                ) +
    ggplot2::scale_y_continuous(sec.axis = sec_axis(~ . ,
                                                    name = "Climate scenario",
                                                    breaks = NULL, labels = NULL)) +
    ggplot2::scale_x_date(sec.axis = sec_axis(~ . , 
                                              name = "Adaptation option", 
                                              breaks = NULL, labels = NULL)) +
    theme_hydrobot(legend.position = "bottom")

hydro_plot
```

Hydrographs for two example gauges (represented by color) with 'climate' scenarios on rows and 'adaptation' scenarios as columns. Scenario codes as in @tbl-scenarios.
:::

## Comparing hydrographs to a baseline {#sec-baselining}

::: {#suppfig-baseline-hydro-clim}
```{r}

# Relative is how we should look at this for climate scenarios, but when the addition in the adaptation options happens when the baseline is at 0 or close to it, it goes to inf. So make two plots, I think.

# The relative one is supremely uninteresting, but maybe we need it to make a point?
base_hydro_clim <- scenehydros |>
    dplyr::filter(scenario %in% scenarios_to_plot & 
                    gauge %in% gauges_to_plot & 
                    flow_addition == 0) |>
    plot_outcomes(outcome_col = 'flow',
                  outcome_lab = 'Relative flow',
                  x_col = 'Date',
                  colorset = 'gauge',
                  color_lab = 'Gauge ID:',
                  pal_list = gauge_pal,
                  base_list = list(base_lev = "climatebaseadapt0",
                     values_col = 'flow',
                     comp_fun = "relative",
                     group_cols = c('Date', 'gauge')),
                  facet_col = 'climate_code')

 base_hydro_clim <- base_hydro_clim +
   ggplot2::scale_x_date(sec.axis = sec_axis(~ . ,
                                              name = "Climate scenarios",
                                              breaks = NULL, labels = NULL)) +
    theme_hydrobot(legend.position = "bottom")+
      guides(color=guide_legend(nrow=2,byrow=TRUE))+
   ylab("Flow relative to E1")

base_hydro_clim
```

Flow relative to the E1 scenario as the baseline. These are flat lines because the relativisation occurs at each timepoint. The E1 scenario is the observed historical data with no climate change or adaptation options applied, and so is a natural baseline for comparison.
:::

::: {#suppfig-baseline-hydro-adapt}
```{r}

# Look at difference just at the the base multiplier
base_hydro_adapt <- scenehydros |>
    dplyr::filter(scenario %in% scenarios_to_plot & 
                    gauge %in% gauges_to_plot & 
                    flow_multiplier == 1) |>
      plot_outcomes(outcome_col = 'flow',
                  outcome_lab = 'Difference flow',
                  x_col = 'Date',
                  colorset = 'gauge',
                  color_lab = 'Gauge ID:',
                  pal_list = gauge_pal,
                  base_list = list(base_lev = "climatebaseadapt0",
                     values_col = 'flow',
                     comp_fun = "difference",
                     group_cols = c('Date', 'gauge')),
                  facet_col = 'adapt_code') +
    ggplot2::scale_x_date(sec.axis = sec_axis(~ . ,
                                              name = "Adaptation options",
                                              breaks = NULL, labels = NULL)) +
    theme_hydrobot(legend.position = "bottom")+
      guides(color=guide_legend(nrow=2,byrow=TRUE))+
   ylab("Flow difference from E1")

base_hydro_adapt
```

Difference in flow compared to the E1 scenario as the baseline. The E1 scenario is the observed historical data with no climate change or adaptation options applied, and so is a natural baseline for comparison.
:::

## Additional comparison plots

### Spatial aggregation {#sec-map-versions}

Maps allow large-scale visualization of ecological objectives under various scenarios. These visualisations can be quite important for communications and quickly grasping how outcomes aggregate spatially and spatial patterns in the data (SI @sec-map-versions). Management targets are often defined spatially and, in the case of EWRs, they are defined in local Planning Units (which are constituents of the SDL units defined above), where outcomes may depend on hydrographs at one or more gauges. Representing the outcomes as maps can provide intuitive assessment of the condition of values across space and whether different spatial scales or spatial locations are responding differently to scenarios. Moreover, the ecology (in this example) or other processes might themselves be large scale, and so capturing the condition over a large area is a better descriptor of the true outcome than assessing each specific location separately. For example, objective EF3 is "Provide movement and dispersal opportunities for water dependent biota to complete lifecycles and disperse into new habitats within catchments", and so necessarily incorporates a spatial dimension. Particularly in these situations, the aggregation method should be considered carefully -- for movement opportunities to succeed, perhaps the success of the SDL unit should be determined by the lowest value at a gauge if it represents a loss of connectivity. In contrast, for WB4: Increase opportunities for colonial waterbird breeding, it might be sufficient if a single site within the SDL unit provides those opportunities.

```{r}
#| label: build-map-figs
#| include: false
#| 
# a single sdl map for comparison
nf_maps_single <- obj_sdl_to_plot |>
    dplyr::filter(env_obj == 'NF1' & scenario == 'climatebaseadapt0') |>
  mutate(scenario = ifelse(scenario == 'MAX', 'MAX', 
                           paste0(climate_code, adapt_code)), 
         SWSDLName = stringr::str_replace(SWSDLName, '–', '-\n')) |> 
  plot_outcomes(outcome_col = 'ewr_achieved',
                outcome_lab = 'Proportion\nEWR achieved',
                plot_type = 'map',
                colorset = 'ewr_achieved',
                pal_list = achieve_pal,
                underlay_list = list(underlay = basin,
                                     pal_list = 'azure'),
                setLimits = c(0,1))  +
  theme(axis.ticks = element_blank(), 
                         axis.text=element_blank())

# a smaller subset of sdls and scenarios
# a single sdl map for comparison
obj_maps_few <- obj_sdl_to_plot |>
    dplyr::filter(env_obj %in% c('NF1', 'EF3', 'WB4') & 
                    scenario %in% c('climatedown2adapt250', 
                                    'climatebaseadapt0', 
                                    'climateup2adapt6500')) |>
  mutate(scenario = ifelse(scenario == 'MAX', 'MAX', 
                           paste0(climate_code, adapt_code)), 
         SWSDLName = stringr::str_replace(SWSDLName, '–', '-\n')) |> 
  plot_outcomes(outcome_col = 'ewr_achieved',
                outcome_lab = 'Proportion\nEWR achieved',
                plot_type = 'map',
                colorset = 'ewr_achieved',
                pal_list = achieve_pal,
                facet_row = 'scenario',
                                facet_col = 'env_obj',

                #underlay_list = list(underlay = basin,
                #                     pal_list = 'azure'),
                setLimits = c(0,1))  +
  theme(axis.ticks = element_blank(), 
                         axis.text=element_blank())

```

Here, we show results at the gauge, SDL and basin scales, and also to show how the outcomes aggregate along the thematic dimension. To start, @suppfig-gauge-to-sdl-map-all-0 illustrates a subset of EWRs (columns) that contribute to priority ecosystem function at the gauge scale. Our aggregation sequence then proceeds to aggregate these EWRs to the environmental objectives at each gauge. Here, @suppfig-gauge-to-sdl-map-all-1 shows the outcomes for gauges for all ecological objectives contributing the priority ecosystem function (left panels) in addition to a gauge level aggregation to the Ecological value scale of the thematic dimension. @suppfig-gauge-to-sdl-map-all-2 then shows these outcomes at the SDL scale; and @suppfig-gauge-to-sdl-map-all-3 shows these outcomes at the basin scale.

```{r}
#| include: false
#| message: false

agged_EWRs_gauges <- agged_data$ewr_code |>
  left_join(causal_ewr$ewr2obj, relationship = 'many-to-many')|>
  dplyr::mutate(env_group = stringr::str_extract(env_obj, '^[A-Z]+')) |>
  dplyr::filter(env_group == 'EF' & !(env_obj %in% c('EF3a', 'EF3b'))) |>
  dplyr::filter(ewr_code %in% c('BF1' ,'CF' ,'LF1' ,'OB-WL' ,'SF1' ,'BK1' ,'VF' ,'AC1', 'OB1'))|>
  distinct(ewr_code, gauge, scenario, .keep_all = TRUE)

ef_EWR_gauges <- agged_EWRs_gauges |>
       dplyr::filter(scenario %in% scenarios_to_plot) |>
  # clean names
    mutate(scenario = paste0(climate_code, adapt_code)) |> 
  plot_outcomes(outcome_col = 'ewr_achieved',
                outcome_lab = 'Proportion\nEWR achieved',
                plot_type = 'map',
                colorset = 'ewr_achieved',
                pal_list = achieve_pal,
                facet_row = 'scenario',
                facet_col = 'ewr_code',
                underlay_list = list(list(underlay = sdl_units |> 
                                            filter(SWSDLName %in%
                                                     unique(obj_sdl_to_plot$SWSDLName)),
                                         pal_list = 'gray')),
                setLimits = c(0,1)) 

ef_EWR_gauges <- ef_EWR_gauges + 
  scale_y_continuous(sec.axis = sec_axis(~ . ,
                                         name = "Climate & Adaptation Option Scenario", 
                                         breaks = NULL, labels = NULL)) +
    scale_x_continuous(sec.axis = sec_axis(~ . , 
                                           name = "EWR",
                                           breaks = NULL, labels = NULL)) +
  theme(axis.ticks = element_blank(), 
                         axis.text=element_blank())
```

::: {#suppfig-gauge-to-sdl-map-all-0}
```{r}
#| message: false
#| warning: false
# suppressMessages(print(ef_EWR_gauges))
ef_EWR_gauges
```

Outcomes for gauges for a subset of EWRs that contribute to priority ecosystem function. Points may not appear for each EWR if they are not defined at a gauge.
:::

::: {#suppfig-gauge-to-sdl-map-all-1}
```{r}
#| message: false
#| warning: false
agged_gauges <- agged_data$ewr_code |> 
  theme_aggregate(from_theme = 'ewr_code', to_theme = 'env_obj',
                  groupers = c('scenario', 'gauge', 'climate_code', 'adapt_code'),
                  aggCols = 'ewr_achieved',
                  funlist = ArithmeticMean,
                  causal_edges = causal_ewr,
                  auto_ewr_PU = FALSE) |> 
  agg_names_to_cols(aggsequence = 'env_obj', 
                    funsequence = 'ArithmeticMean', 
                    aggCols = 'ewr_achieved')

agged_gauges <- agged_gauges |>
  dplyr::mutate(env_group = stringr::str_extract(env_obj, '^[A-Z]+')) |>
  dplyr::filter(env_group == 'EF' & !(env_obj %in% c('EF3a', 'EF3b')))

 ef_gauges <- agged_gauges |>
       dplyr::filter(scenario %in% scenarios_to_plot) |>
  # clean names
    mutate(scenario = paste0(climate_code, adapt_code)) |> 
  plot_outcomes(outcome_col = 'ewr_achieved',
                outcome_lab = 'Proportion\nEWR achieved',
                plot_type = 'map',
                colorset = 'ewr_achieved',
                pal_list = achieve_pal,
                facet_row = 'scenario',
                facet_col = 'env_obj',
                underlay_list = list(list(underlay = sdl_units |> 
                                            filter(SWSDLName %in%
                                                     unique(obj_sdl_to_plot$SWSDLName)),
                                         pal_list = 'gray')),
                setLimits = c(0,1)) 

ef_gauges <- ef_gauges + 
  scale_y_continuous(sec.axis = sec_axis(~ . ,
                                         name = "Climate & Adaptation Option Scenario", 
                                         breaks = NULL, labels = NULL)) +
    scale_x_continuous(sec.axis = sec_axis(~ . , 
                                           name = "Environmental objective",
                                           breaks = NULL, labels = NULL)) +
  theme(axis.ticks = element_blank(), 
                         axis.text=element_blank())

 ef_gauges_target <- agged_gauges |>
  dplyr::group_by(scenario,env_group, climate_code, adapt_code, gauge, geometry)|>
  dplyr::summarise(ewr_achieved = mean(ewr_achieved)) |>
  dplyr::filter(scenario %in% scenarios_to_plot) |>
  dplyr::filter(env_group == 'EF') |> 
  # clean names
    mutate(scenario = paste0(climate_code, adapt_code)) |> 
  plot_outcomes(outcome_col = 'ewr_achieved',
                outcome_lab = 'Proportion\nEWR achieved',
                plot_type = 'map',
                colorset = 'ewr_achieved',
                pal_list = achieve_pal,
                facet_row = 'scenario',
                facet_col = 'env_group',
                underlay_list = list(list(underlay = sdl_units |> 
                                            filter(SWSDLName %in%
                                                     unique(obj_sdl_to_plot$SWSDLName)),
                                         pal_list = 'gray')),
                setLimits = c(0,1)) 

ef_gauges_target <- ef_gauges_target + 
  scale_y_continuous(sec.axis = sec_axis(~ . ,
                                         name = "Climate & Adaptation Option Scenario", 
                                         breaks = NULL, labels = NULL)) +
    scale_x_continuous(sec.axis = sec_axis(~ . , 
                                           name = "Ecological value",
                                           breaks = NULL, labels = NULL)) +
  theme(axis.ticks = element_blank(), 
                         axis.text=element_blank())

ef_gauges + ef_gauges_target + plot_layout(guides = "collect", heights = c(1,1), widths = c(10,2), nrow = 1)
```

Outcomes for gauges for all ecological objectives contributing the priority ecosystem function. Points may not appear for each environmental objective if it is not defined at a gauge.
:::

::: {#suppfig-gauge-to-sdl-map-all-2}
```{r}
#| message: false

ef_maps <- obj_sdl_to_plot |>
    dplyr::filter(scenario %in% scenarios_to_plot) |>
  # Need to reduce dimensionality
    dplyr::filter(env_group == 'EF' & !(env_obj %in% c('EF3a', 'EF3b'))) |> 
  # clean names
  mutate(scenario = paste0(climate_code, adapt_code), 
         SWSDLName = stringr::str_replace(SWSDLName, '–', '-\n')) |> 
  plot_outcomes(outcome_col = 'ewr_achieved',
                outcome_lab = 'Proportion\nEWR achieved',
                plot_type = 'map',
                colorset = 'ewr_achieved',
                pal_list = achieve_pal,
                facet_row = 'scenario',
                facet_col = 'env_obj',
                # underlay_list = list(underlay = basin,
                #                      pal_list = 'azure'),
                setLimits = c(0,1)) 

ef_maps <- ef_maps + 
  scale_y_continuous(sec.axis = sec_axis(~ . ,
                                         name = "Climate & Adaptation Option Scenario", 
                                         breaks = NULL, labels = NULL)) +
    scale_x_continuous(sec.axis = sec_axis(~ . , 
                                           name = "Environmental objective",
                                           breaks = NULL, labels = NULL)) +
  theme(axis.ticks = element_blank(), 
                         axis.text=element_blank())

ef_maps_target <- obj_sdl_to_plot |>
  dplyr::group_by(scenario,env_group, climate_code, adapt_code, SWSDLName, geometry)|>
  dplyr::summarise(ewr_achieved = mean(ewr_achieved)) |>
  dplyr::filter(scenario %in% scenarios_to_plot) |>
  dplyr::filter(env_group == 'EF') |> 
  # clean names
    mutate(scenario = paste0(climate_code, adapt_code)) |> 
  plot_outcomes(outcome_col = 'ewr_achieved',
                outcome_lab = 'Proportion\nEWR achieved',
                plot_type = 'map',
                colorset = 'ewr_achieved',
                pal_list = achieve_pal,
                facet_row = 'scenario',
                facet_col = 'env_group',
                underlay_list = list(list(underlay = sdl_units |> 
                                            filter(SWSDLName %in%
                                                     unique(obj_sdl_to_plot$SWSDLName)),
                                         pal_list = 'gray')),
                setLimits = c(0,1)) 

ef_maps_target <- ef_maps_target + 
  scale_y_continuous(sec.axis = sec_axis(~ . ,
                                         name = "Climate & Adaptation Option Scenario", 
                                         breaks = NULL, labels = NULL)) +
    scale_x_continuous(sec.axis = sec_axis(~ . , 
                                           name = "Ecological value",
                                           breaks = NULL, labels = NULL)) +
  theme(axis.ticks = element_blank(), 
                         axis.text=element_blank())

ef_maps + ef_maps_target + plot_layout(guides = "collect", heights = c(1,1), widths = c(10,2), nrow = 1)

```

Outcomes for SDL units for all ecological objectives contributing the priority ecosystem function. Environmental water requirements (EWRs) are defined by hydrographs at gauges and apply to Planning Units. The outcomes at these scales of definition can then be aggregated to larger spatial areas, such as SDL units, which we do here with an area-weighted mean. Missing SDL units in EF7 are because EF7 is not defined in that unit (Lachlan).
:::

::: {#suppfig-gauge-to-sdl-map-all-3}
```{r}
#| message: false

 ef_basin_data <- obj_sdl_to_plot |>
   dplyr::group_by(scenario, env_obj, climate_code, adapt_code)|>
   dplyr::reframe(ewr_achieved = mean(ewr_achieved)) |>
   dplyr::filter(scenario %in% scenarios_to_plot) |>
   dplyr::mutate(OBJECTID = as.double(1))|>
   dplyr::right_join(basin, by = join_by(OBJECTID))|>
   st_sf()|>
   dplyr::mutate(env_group = stringr::str_extract(env_obj, '^[A-Z]+')) |>
   dplyr::filter(env_group == 'EF' & !(env_obj %in% c('EF3a', 'EF3b'))) 
 
ef_basin <- ef_basin_data |> 
  # clean names
  mutate(scenario = paste0(climate_code, adapt_code)) |> 
  plot_outcomes(outcome_col = 'ewr_achieved',
                outcome_lab = 'Proportion\nEWR achieved',
                plot_type = 'map',
                colorset = 'ewr_achieved',
                pal_list = achieve_pal,
                facet_row = 'scenario',
                facet_col = 'env_obj',
                setLimits = c(0,1)) 

ef_basin <- ef_basin + 
  scale_y_continuous(sec.axis = sec_axis(~ . ,
                                         name = "Climate & Adaptation Option Scenario", 
                                         breaks = NULL, labels = NULL)) +
    scale_x_continuous(sec.axis = sec_axis(~ . , 
                                           name = "Environmental objective",
                                           breaks = NULL, labels = NULL)) +
  theme(axis.ticks = element_blank(), 
                         axis.text=element_blank())

ef_basin_target <- ef_basin_data |>
  dplyr::group_by(scenario, env_group, climate_code, adapt_code, geometry)|>
  dplyr::summarise(ewr_achieved = mean(ewr_achieved)) |>
  dplyr::filter(scenario %in% scenarios_to_plot) |>
  dplyr::filter(env_group == 'EF') |> 
  # clean names
    mutate(scenario = paste0(climate_code, adapt_code)) |> 
  plot_outcomes(outcome_col = 'ewr_achieved',
                outcome_lab = 'Proportion\nEWR achieved',
                plot_type = 'map',
                colorset = 'ewr_achieved',
                pal_list = achieve_pal,
                facet_row = 'scenario',
                facet_col = 'env_group',
                setLimits = c(0,1)) 

ef_basin_target <- ef_basin_target + 
  scale_y_continuous(sec.axis = sec_axis(~ . ,
                                         name = "Climate & Adaptation Option Scenario", 
                                         breaks = NULL, labels = NULL)) +
    scale_x_continuous(sec.axis = sec_axis(~ . , 
                                           name = "Ecological value",
                                           breaks = NULL, labels = NULL)) +
  theme(axis.ticks = element_blank(), 
                         axis.text=element_blank())

ef_basin + ef_basin_target + plot_layout(guides = "collect", heights = c(1,1), widths = c(10,2), nrow = 1)
```

Outcomes for the basin for all ecological objectives contributing the priority ecosystem function.
:::

### Quantitative fits with multiplicative and additive scenarios

Here, we show the full set of SDL units and ecological values that are shown in part in @fig-smooth-climate-adapt panel b.

::: {#suppfig-smooth-all}
```{r}
#| message: false
#| warning: false

# sdl_smooth_groups / sdl_smooth_clim +
#   plot_layout(guides = 'collect', heights = c(3,1))
# Lots of loess warnings, we don't really care here.
# suppressMessages(suppressWarnings(print(sdl_smooth_groups))) 
# + coord_cartesian(ylim = c(0.5, 2)) # + geom_abline(slope = 1, intercept = 1)


sdl_smooth_groups
```

Smoothed fits to assess change in performance across the 'climate' scenarios. Points are individual ecological objectives, fitted lines are loess smooths. Separate fits are done for each adaptation option, and so differences between lines of different colors represent the impact of those adaptations. Rows are ecological values groupings, columns are SDL units. Note the different scales of the y-axis. There are no EWRs contributing to 'Other species' in the Namoi.
:::

### Heatmaps

There are a number of ways surfaces can be visualized with HydroBOT, with Figure 9 in the text being one example. Several others are possible, including heatmaps, (e.g. @suppfig-heatmap).

::: {#suppfig-heatmap}
```{r}

qual_heatmap
```

Condition results visualized as a heatmap with the two scenario definitions on the axes. This approach allows visualising changes in outcome as the result of multiple axes on which scenarios might differ. These axes might be different aspects of scenario creation (as here), or they might be different axes describing the outcome of scenarios (e.g. two different hydrometrics such as mean flow and flow variance). There are no EWRs contributing to 'Other species' in the Namoi.
:::

### Small to large detail

In the text, we show an overview giving a sense of the contribution of proximate ecological outcomes to the overall outcomes for each larger ecological grouping (@fig-obj-in-groups). Here, we illustrate how that might be broken down to examine those

::: {#suppfig-obj-detail}
```{r}
#| label: complex-obj-detail
#| warning: false
#| message: false
env_pals_complex <- list(EB = 'grDevices::Grays',
  EF = 'ggsci::default_uchicago',
                NF = 'ggthemes::Nuriel_Stone',
                NV = 'ggsci::lanonc_lancet',
                OS = 'rockthemes::secondlaw',
                WB = 'calecopal::superbloom1')


obj_detail <- obj_sdl_to_plot |>
  filter(env_group != 'EB') |> # There's only one, this is just distracting.
  # filter(env_group == 'WB') |> 
  filter(scenario %in% scenarios_to_plot) |> 
  # clean the names
  mutate(scenario = paste0(climate_code, adapt_code), 
         SWSDLName = stringr::str_replace(SWSDLName, '–', '-\n'),
         Target = stringr::str_replace(Target, 'Priority e', 'E'),
         Target = stringr::str_wrap(Target, width = 12)) |> 
  plot_outcomes(outcome_col = 'ewr_achieved',
                outcome_lab = "Proportion\nEWR achieved",
                x_col = 'scenario',
                x_lab = "Climate & Adaptation Option Scenario",
                colorgroups = 'env_group',
                colorset = 'env_obj',
                pal_list = env_pals_complex,
                color_lab = "Ecological\nobjectives",
                facet_col = 'SWSDLName',
                facet_row = 'Target',
                # scales = 'free_y',
                position = 'dodge',
                sceneorder = rename_sceneorder
                )


obj_detail + theme(legend.key.size = unit(0.5, 'cm'))

```

Visualisation of same data in @fig-obj-in-groups in the text, but here accentuating the lower-level values rather than the overall ecological objectives. Rather than stacking the bars, here they are next to each other so it is clear how close each value is to the maximum of 1.0, and the colors are more distinct, allowing easier identification of particular lower-level values. There are no EWRs contributing to 'Other species' in the Namoi.
:::

In practice, that is quite complex and hard to interpret. A better solution is probably to examine the small scale ecological objectives within each ecological group separately, shown here for waterbirds.

::: {#suppfig-obj-waterbirds}
```{r}
#| label: waterbirds-obj-detail
#| warning: false
#| message: false
obj_detail_wb <- obj_sdl_to_plot |>
  filter(env_group == 'WB') |> # There's only one, this is just distracting.
  # filter(env_group == 'WB') |> 
  filter(scenario %in% scenarios_to_plot) |> 
  # clean the names
  mutate(scenario = paste0(climate_code, adapt_code), 
         SWSDLName = stringr::str_replace(SWSDLName, '–', '-\n'),
         Target = stringr::str_replace(Target, 'Priority e', 'E'),
         Target = stringr::str_wrap(Target, width = 12)) |> 
  plot_outcomes(outcome_col = 'ewr_achieved',
                outcome_lab = "Proportion\nEWR achieved",
                x_col = 'scenario',
                x_lab = "Climate & Adaptation Option Scenario",
                colorset = 'env_obj',
                pal_list = 'calecopal::superbloom1',
                color_lab = "Ecological\nobjectives",
                facet_col = 'SWSDLName',
                # facet_row = 'Target',
                # scales = 'free_y',
                position = 'dodge',
                sceneorder = rename_sceneorder
                )


obj_detail_wb +
  geom_hline(mapping = aes(yintercept = 1),
             linetype = 'dashed', color = 'grey30') + 
  theme(legend.key.size = unit(0.5, 'cm'))


```

The waterbirds-related values from @fig-obj-in-groups and @suppfig-obj-detail. Each bar has a maximum value of 1 (all constituent EWRs met). We have included an illustrative line at 1, but in practice, it might be beneficial to include a line at some lower threshold where achievement was deemed to be 'acceptable', i.e. if 95% of constituent EWRs was good enough.
:::

### Causal networks and scenarios {#sec-causal-scenarios}

In the text, we show the causal network for a single scenario for clarity and space. Despite their complexity, these networks can be invaluable for comparing scenarios (@suppfig-causal-all) and identifying nodes that are particularly sensitive or resilient to changes among scenarios (@suppfig-causal-relative) and how those effects propagate through the network.

For example, the small fresh EWR indicators SF1 and SF2 are much more sensitive to reductions in flow than the other EWRs (darker pink), while OB4, OB5, and LF2 are sensitive to increases in flow (darker green, @suppfig-causal-relative). The raw condition scores (@suppfig-causal-all) show where these changes arise, with SF1 and SF2 having condition near 1 in scenario E1 (the unchanged historical hydrograph) and so, while they can have lower condition with lower flow, they cannot improve as conditions increase. The opposite happens with OB4, OB5, and LF2, which have poor condition in scenario E1. These EWRs are thus little changed with reductions in flow, while increases in flow allow their requirements to be met. Similar outcomes occur for lower-scale ecological values in the middle column, with those near the top tending to be poor in scenario E1, and so have little room to decline as flows halve, but improve with doubling and those in the bottom tending to have better condition in the baseline E1 scenario, and so more room to decline with reductions in water than to improve with increases. Finally, we see that Waterbirds tend to be relatively unchanged as flows decline because they start out poor, but are the group with the largest increases as flows increase, while Native Fish show nearly the opposite pattern.

![Causal networks with condition values for the halving (left, A1), historical flows (middle, E1) and doubling (right, I1) 'climate' scenarios. colors in each node are the mean of the conditions in each constituent node. The network here for the historical flows (E1, middle) is the same as @fig-causal-results in the text. @suppfig-causal-relative shows the relative change between these scenarios, using the historical flows (E1) as the baseline.](images/causal_combined.png){#suppfig-causal-all}

![Causal networks with relative condition values (compared to the the historical flows with no additional 'adaptation' water \[E1 scenario\] as the baseline) for the halving (left, A1) and doubling (right, I1) scenarios. These are calculated from the values in @suppfig-causal-all for each node, with colors showing the relative change in condition. Note in particular that a lack of change can occur for any value of the node in the baseline E1 scenario, but often occurs when there is little scope for conditions to improve or decline, i.e we tend to see improvements in nodes with low condition in the E1 scenario, and declines in nodes with high condition in the E1 scenario.](images/causal_rel_combined.png){#suppfig-causal-relative}

# References

::: {#refs-supp}
:::
