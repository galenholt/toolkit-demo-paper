---
title: "HydroBOT: an integrated toolkit for assessment of hydrology-dependent outcomes"
author: 
 - name: Galen Holt
   orcid: 0000-0002-7455-9275
   corresponding: true
   email: galen@deakin.edu.au
   affiliation:
    - ref: du
 - name: Georgia Dwyer
   orcid: 0000-0002-3579-3819
   corresponding: false
   affiliations:
     - ref: du
 - name: David Robertson
   orcid: 0000-0003-4230-8006
   corresponding: false
   affiliations:
     - CSIRO
 - name: Martin Job
   orcid: 
   corresponding: false
   affiliations:
     - MDBA
 - name: Rebecca E Lester
   orcid: 
   corresponding: false
   affiliations:
     - ref: du

affiliations:
  - id: du
    name: Deakin University
    city: Waurn Ponds
    state: Victoria
        
keywords: 
 - Murray-Darling Basin
 - Holistic modeling
 - Management modeling
 - Climate change
 - Climate adaptation
 
date: last-modified

bibliography: references.bib
csl: ecology.csl

number-sections: true

echo: false

crossref:
  custom:
    - kind: float
      key: suppfig
      latex-env: suppfig
      reference-prefix: Figure S
      space-before-numbering: false
    - kind: float
      key: supptbl
      latex-env: supptbl
      reference-prefix: Table S
      space-before-numbering: false
      caption-location: top

format:
  # html:
  #   embed-resources: true
  #   toc: true
  #   comments:
  #     hypothesis: true
  docx:
    toc: false
    prefer-html: true
    # 7 and 5 are html defaults and look better, but 6.3 is 16cm and so full-page width in word and usually submissions
    fig-width: 6.2 # 7
    fig-height: 4.5 # 5
    reference-doc: ../default_word_template.docx
---

```{r}
options(knitr.kable.NA = '')
```

```{r}
#| eval: false

# This should not be run, except to make a simple quarto
make_simpleyml <- function(renderfile = 'auto') {
  
  if (renderfile == 'auto') {
    projpath <- rstudioapi::getActiveProject()
    docpath <- rstudioapi::documentPath()
    projdir <- sub(".*/([^/]+)$", "\\1", projpath)
    reldocpath <- sub(paste0(".*", projdir, "/"), "", docpath)
    renderfile <- reldocpath
  }
    
  
  simple_yaml <- list()
  simple_yaml$project <- list()
  simple_yaml$project$render <- list(renderfile)
  yaml::write_yaml(simple_yaml, '_quarto-singlefile.yml')
}

make_simpleyml(rstudioapi::documentPath())
```

```{r}
#| label: packages
#| include: false

library(HydroBOT) 
library(dplyr)
library(sf)
library(huxtable)
library(ggplot2)
library(patchwork)
```

```{r}
#| label: directories
#| include: false

# This depends on the same scenarios as the demo website, so give it the path to that. This will likely be user-specific. Everything else is relative.

#demo_webdir <- file.path('../WERP_toolkit_demo')
demo_webdir <- file.path('~', '../Deakin University/QAEL - WERP in house - WERP/Toolkit/Writing/Demonstration paper')

# Why is the execute-dir not working?
# Outer directory 
project_dir = file.path(demo_webdir, 'demo_scenarios')  # '..', 

# Hydrographs
hydro_dir = file.path(project_dir, 'hydrographs')  

# EWR outputs
ewr_results <- file.path(project_dir, 'module_output', 'EWR')  

# outputs of aggregator
agg_results <- file.path(project_dir, 'aggregator_output', 'sdl_target') 

# outputs of aggregator
agg_results_gauge <- file.path(project_dir, 'aggregator_output', 'gauge_target') 

```

```{r}
#| label: data-subsets
#| include: false

gauges_to_plot <- c('412002', '419001')#, '422028', '421001')

scenarios_to_plot <- c("climatedown2adapt0", 
                       "climatedown2adapt250",
                      "climatedown2adapt6500",
                      "climatebaseadapt0",
                      "climatebaseadapt250", 
                      "climatebaseadapt6500",
                      "climateup2adapt0",
                      "climateup2adapt250",
                      "climateup2adapt6500")

scenarios_to_plot2 <- c("climatedown2adapt0", 
                      "climatebaseadapt0",
                      "climateup2adapt0")
```

```{r}
#| label: scenario-info
#| include: false
print(file.path(hydro_dir,'scenario_metadata.yml'))

scenarios <- yaml::read_yaml(file.path(hydro_dir,                                     
                                       'scenario_metadata.yml'))


```

```{r}
#| label: scenario-info2
#| include: false
scenarios <- scenarios |>  
  tibble::as_tibble() |> 
  dplyr::rename('scenario' = "scenario_name")

# Add Georgia's scenario codes
scenarios <- scenarios |> 
  arrange(flow_addition, flow_multiplier) |> 
  group_by(flow_addition) |>
  mutate(climate_code = LETTERS[1:n()]) |>
  ungroup() |> 
  group_by(flow_multiplier) |> 
  mutate(adapt_code = 1:n()) |> 
  ungroup()

# set a sceneorder
sceneorder <- forcats::fct_reorder(scenarios$scenario,
                                   (scenarios$flow_multiplier +
                                      scenarios$flow_addition/100000))

# But we usually use the codes, so we need to order them too.
rename_sceneorder <- scenarios  |> 
  mutate(scenario = ifelse(scenario == 'MAX', 'MAX', 
                           paste0(climate_code, adapt_code))) |> 
  pull(scenario) |> 
  forcats::fct_reorder((scenarios$flow_multiplier +
                          scenarios$flow_addition/100000))
```

```{r}
#| label: data-import
#| include: false

# Now that the data is in, deal with the extra junk associated with unique scenario names, hence the str_remove_all

#Hydrographs- just read in the ones we use
scenehydros <- read_hydro(hydro_dir, 
                          scenariofilter = stringr::str_c(scenarios_to_plot), 
                          long = TRUE, format = 'csv') |> 
  mutate(scenario = stringr::str_remove_all(scenario, '.*0_')) |> 
  left_join(scenarios, by = 'scenario') |>
  rename(gauge_flow = gauge)|>
  tidyr::separate(gauge_flow, into = c("gauge", NA), sep = "_", remove = FALSE)

#Agg data (1.2 GB)
agged_data <- readRDS(file.path(agg_results, 'achievement_aggregated.rds')) |>
  purrr::map(\(x) mutate(x, 
                         scenario = stringr::str_remove_all(scenario, '.*0_'))) |> 
  purrr::map(\(x) left_join(x, scenarios, by = 'scenario'))

# because we use '_' for the 1.0 etc, it messes up some of the directories. Clean that up
agged_data <- purrr::map(agged_data,
                         \(x) dplyr::mutate(x, 
                                            scenario = stringr::str_remove_all(scenario, '_clim.*')))


#Agg data (1.2 GB)
agged_data_gauge <- readRDS(file.path(agg_results_gauge, 'achievement_aggregated.rds')) |>
  purrr::map(\(x) mutate(x, 
                         scenario = stringr::str_remove_all(scenario, '.*0_'))) |>
  purrr::map(\(x) left_join(x, scenarios, by = 'scenario'))

# because we use '_' for the 1.0 etc, it messes up some of the directories. Clean that up
agged_data_gauge <- purrr::map(agged_data_gauge,
                         \(x) dplyr::mutate(x, 
                                            scenario = stringr::str_remove_all(scenario, '_clim.*')))

```

```{r}
#| label: flow-differences


# To get a single dimension for the scenarios, we can use the overall difference in flow volumes. It's crude, but likely the only thing that works when we have an addition over part of the year and a multiplicative change. Those are fundamentally different, so we'll do our best

# This is baselining the *inputs*- the amount of flow. And so we have to do it here, not in plot_outcomes where we use it, since that baselines the *outputs* (EWR achievement)
dif_flow <- baseline_compare(scenehydros, compare_col = 'scenario',                                             base_lev = "climatebaseadapt0",
                             values_col = 'flow',                               
                             comp_fun = c("difference"),
                             group_cols = c('Date', 'gauge')) |> 
  group_by(scenario) |> 
  summarise(scenario_difference = mean(difference_flow)*0.001)

scenarios <- left_join(scenarios, dif_flow, by = 'scenario')

```

```{r}
#| label: palettes
#| include: false

# Qualitative
SDL_pal <- make_pal(unique(agged_data$sdl_units$SWSDLName), 
                    palette = "impressionist.colors::la_recolte_des_foins_eragny")

gauge_pal <- make_pal(unique(gauges_to_plot),                       
                      palette = 'ggsci::nrc_npg')

adapt_pal <- make_pal(as.character(unique(scenarios$adapt_code)),
                      palette = 'nationalparkcolors::Redwoods')

# descriptive networks
net_pal <- list(NodeType = 'nationalparkcolors::MtRainier')

# these have to use quantitative even though they're not, or we run out of colors.
env_pals <- list(EB = 'grDevices::Grays',
  EF = 'grDevices::Purp',
                NF = 'grDevices::Mint',
                NV = 'grDevices::Burg',
                OS = 'grDevices::Blues 2',
                WB = 'grDevices::Peach')

# easier printing if they have the class
make_colors <- function(x){
  class(x) <- 'colors'
  return(x)
  }

# use the first level of each of those to make a named pal. I wish there were an easier way
envgroup_pal <- purrr::imap_chr(env_pals,
                                \(x,y) make_pal(levels = y, palette = x)) 


Target_pal <- stats::setNames(envgroup_pal, 
            c(NA, 'Priority ecosystem function', 'Native fish', 'Native vegetation', 'Other species', 'Waterbirds')) |> 
  make_colors()

# Quantitative- sequential achievement
achieve_pal <- 'grDevices::Blue-Yellow'

# quantitative- diverging achievement (e.g. relative to baseline)
compare_pal <- 'scico::bam'

# We don't end up using scene_pal, I don't think. 
# But I also think we should
# Since there are two dimensions, maybe use faded colors? Should be able to bring that function over.
# But do that later
scene_pal <- make_pal(unique(scenehydros$scenario),                       
                      palette = "viridis::mako", #'ggsci::nrc_npg', 
                      refvals = 'base', refcols = 'black')


climate_code_pal <- stats::setNames(scene_pal[c(1, 4, 7)],
                                    unique(scenehydros$climate_code))

sceneTarget_pal <- stats::setNames(c(envgroup_pal, climate_code_pal), 
            c(NA, "Priority ecosystem function", 'Native fish', 'Native vegetation', 'Other species', 'Waterbirds', names(climate_code_pal))) |> 
  make_colors()

#Target Palette
sceneTarget2_pal <-  stats::setNames(c("#5F9776", "#5F9776", "#5F9776", "#5F9776", "#5F9776", "#4873B8", "#B7A447", "#FDC010", "#f47f51", "#2e3d5a", "#bf3729"), 
            c("Native fish", "Native vegetation", "Waterbirds", "Other species", "Priority ecosystem function", "End of system flows", "Water allocation", "Agricultural benefits", "Social benefits", "I", "E")) |> 
  make_colors()

sceneTarget2_pal
```

```{r}
#| label: move figs
#| include: false
file.copy(file.path(demo_webdir, 'images', 'GraphicalAbstract-01.png'), 
          file.path('images', 'graphical_abstract.png'),
          overwrite = TRUE)

file.copy(file.path(demo_webdir, 'images', 'Conceptual_fig_demopaper2.png'), 
          file.path('images', 'conceptual.png'),
          overwrite = TRUE)

file.copy(file.path(demo_webdir, 'images', 'Aggregations.png'), 
          file.path('images', 'aggregations.png'),
          overwrite = TRUE)

file.copy(file.path(demo_webdir, 'images', 'architecture.png'), 
          file.path('images', 'architecture.png'),
          overwrite = TRUE)

file.copy(file.path(demo_webdir, 'images', 'aggNetworkdown_sub_rel_illus.png'), 
          file.path('images', 'causal_results.png'),
          overwrite = TRUE)

file.copy(file.path(demo_webdir, 'images', 'network_structure_illus.png'), 
          file.path('images', 'all_causal.png'),
          overwrite = TRUE)
# This is a placeholder to move conceptual figs, since it HATES spaces in names of the raw {fig} divs

```

# Highlights {.unnumbered}

-   The HydroBOT toolkit provides new management modelling capability for data and model integration, demonstrated for the Murray-Darling Basin.

-   HydroBOT synthesizes and assesses outcomes across disparate target values.

-   Scaling and synthesis of outcomes in space, time, and groups of values unlocks improved interpretation and decision making.

-   Scenario comparison, particularly impacts of climate and management adaptation, are primary uses.

-   HydroBOT emphasizes automation, transparency, and error detection for consistent repeatable analyses.

# Graphical abstract {.unnumbered}

![](../images/graphical_abstract.png){#graphab width="16cm"}

# Abstract {.unnumbered}

Water management rarely focuses only on water itself; instead, management targets myriad values held by multiple stakeholders across many types of responses that depend on that water. To assess past performance and plan future actions, water managers need tools to understand how changes to hydrology (over which they typically have most control) affect these water-dependent values. Climate change accentuates the need to understand how values might shift and assess potential options for addressing those impacts. However, models relating values to hydrology and management levers can be difficult to usefully integrate into management processes. These models are often developed for other uses and are not easily integrated across many disparate values. Economic and ecological models, for example, might differ in language, approach, goals, scale, *et cetera*. Here, we describe and demonstrate HydroBOT (Hydrology-dependent Basin Outcomes Toolkit), a holistic modelling toolkit co-designed from the ground up with the primary federal water management agency in the Murray-Darling Basin, Australia. HydroBOT uses a modular, open-source architecture to integrate disparate models of response to hydrology into a consistent, repeatable framework. It scales and and synthesizes those results across space, time, and groups of values, targeting outputs relevant to water managers. Analyses and syntheses can be tailored to a range of questions, from local, short-term evaluation to longer-term basin-scale assessments of climate response across thousands of values. HydroBOT provides fundamentally new capacity to move beyond hydrology to assess outcomes across a range of target values, and its modularity and flexibility provides capacity for continual upgrades and improvements as new models are developed and new needs are identified. *GALEN cut 11 words*.

# Key words {.unnumbered}

1\) Environmental flows; 2) Water management; 3) Hydrology; 4) Integrated management; 5) R package; 6) Synthesis

# Software availability {.unnumbered}

Software name: HydroBOT (Hydrology-dependent Basin Outcomes Toolkit). Developer: QAEL (Quantitative Aquatic Ecosystem Laboratory) led by Galen Holt. First year available: 2023. Program language: R, Python. Program size: 16 MB. Operation system: Linux, macOS, Windows. Availability: https://github.com/MDBAuth/HydroBOT License: MIT

# Introduction

Water management in large river systems typically targets a wide range of desired values [@brown2009; @holling2001; @jones2016]. For example, in the Murray-Darling Basin (MDB), Australia, the objective of water management is to maintain a healthy working river that supports productive and resilient water-dependent industries, healthy and resilient ecosystems, and communities with access to sufficient and reliable water supplies [@murray-darlingbasinauthority2011]. These values, defined here as any social, economic, environmental or cultural asset or function of significance, importance, worth, or use, are not unique to Australia; water is managed to protect a diverse range of values worldwide [e.g. @stern2019; @kaye-blake2014; @ziolkowska2016; @connor2015]. That these values are the target of water management implies that each value depends on water in some way but, in many cases, these dependencies are not well defined and so management targets water volumes and flow characteristics under the assumption dependent values will follow [e.g. @arthington2018; @mentzafou2023].

Water managers typically have a limited range of levers at their disposal. While the particular levers vary across jurisdictions, those that directly affect hydrology dominate [e.g. flow releases from dams or inundation of wetlands, @murray-darlingbasinauthority2011; @holt2024]. When non-hydrologic levers are available, such as water trading rules in the Murray-Darling Basin, their impact is still often assessed by how they alter hydrologic conditions – their impact on the spatio-temporal patterns of flow in the system [e.g. @nswdpiemacq2020; @delwp2022]. Hydrologic modelling is often better-integrated with management workflows than models of other values [e.g. @tharme2003; @king2000; @shenton2012]. In part, this is due to the availability of large-scale physically-based numerical models that provide robust ability to simulate flows as they arise from natural drivers, such as rainfall, and capture infrastructure such as dams and diversions [e.g. @yang2017]. While complex, these models have relatively high precision and relatively few outcomes compared to models of ecological or economic responses, for example [@robson2014]. The impact of given management actions (e.g. dam releases) on hydrology is well understood and captured by the hydrograph, allowing accurate targeting of particular aspects of the flow regime by management actions [e.g. @singer2007; @loire2021]. While these proximate models of system state and the impact of management actions are invaluable, they do not provide the necessary information to directly assess the status of the range of flow-dependent values.

Assessing values as they respond to flow and management actions requires models of these relationships. Such models exist, though their quality and extent vary widely, ranging from unstated mental models to highly-detailed population dynamics or economic models [@lester2019; @holt2024]. Quantitative computational models are often written in various languages by subject-matter experts, focus on one or a limited suite of target values and return disparate outputs depending on their particular goals and approaches [@ryder2010]. These models are often designed with the goal of studying the dynamics of highly specific variables [e.g. fish population responses to anthropogenic change, @scheuerell2021], not to produce the most useful analysis for management questions or to capture the breadth of target values. Moreover, such targeted models typically cannot individually provide information about larger-scale values; single-species models are insufficient to assess the condition of all fish or the whole ecosystem, for example [@olden2014; @gawne2018]. Integrating disparate quantitative models into a holistic modelling approach is necessary to assess management-relevant outcomes of disparate, typically broad-scale, values under different hydrologic conditions and management actions. Integrating diverse response models gives each response model utility beyond its original purpose and identifies where new work is needed (e.g. where response models are limited or non-existent) [@holt2024]. The creation of an integrated toolkit provides the opportunity for robust decision-making [@harrison2023] and the ability to prioritize water planning across a range of values and identify conditions that achieve disproportionately large (or small) impacts, as well as the explicit consideration of synergies and trade-offs among different values.

Exemplifying these issues, the Murray-Darling Basin is centrally important to the economic, cultural, social and environmental wellbeing of Australia. Within the MDB, 70% of water is utilized for agricultural purposes [@hart2021]. Agriculture and tourism in the MDB contribute nearly 2% to Australian gross domestic product [@hart2021]. The MDB is home to 2.2 million people, including more than 50 Aboriginal Nations, and contains approximately 500,000 mapped water-dependent habitats [@hart2021; @brooks2021; @murray-darlingbasinauthority2023]. While balancing this range of values is difficult in any highly-utilized basin, the Murray-Darling is unusually dry and variable compared to other systems of similar importance [@bond2021].

Modern management of the MDB arises from the Commonwealth [@commonwealthofaustralia2007], which established the Murray-Darling Basin Authority (MDBA) with requirements to develop and implement a Basin Plan governing water resource management [@hart2021; @murray-darlingbasinauthority2011]. The MDBA has obligations to manage water to maintain a "healthy working river" [@murray-darlingbasinauthority2011]. The state of the MDB is required to be assessed annually, with a major review of, and updates to, the Basin Plan made at legislated intervals [e.g. 15 years between development and first review, @hart2021]. The MDBA does not itself deliver water; instead states within the basin have primary responsibility for water delivery and integrated catchment management, with the MDBA providing coordination and an overarching policy framework [@hart2021; @murray-darlingbasinauthority2019]. Other stakeholders (e.g. the Commonwealth Environmental Water Holder) have additional responsibilities for water management and coordination in the MDB.

The MDBA and other water managers in the Murray-Darling basin have an increasing focus on assessing system response to climate change and management actions including climate adaptations that may be taken by the MDBA itself or other stakeholders in the MDB [@neave2015]. Taken together, the need for collaborative management across jurisdictions to deliver legislated requirements and manage into the future for a healthy working basin require a holistic modelling approach that integrates across values and is adaptable to these various management needs while also simplifying repeated, ongoing use. These needs are not unique to the MDBA; other water management groups, researchers and stakeholders have similar complex and competing needs [@campbell2016].

The MDBA has access to robust hydrologic models describing flows in the system and responses to current management practices and these models are under continual use, development, and improvement [e.g. @yang2017]. Despite the need for ongoing assessment and forward planning across a range of values, models of the responses to those hydrologic conditions are patchy, only represent some values, and have been developed and used in a more *ad hoc* approach rather than integrated with each other or the hydrologic models [@olden2014; @gawne2018; @holt2024]. In this paper, we describe an integrated modelling 'toolkit', hereafter referred to as *HydroBOT* (Hydrology-dependent Basin Outcomes Toolkit), to integrate these disparate models and assess the response of a wide range of water-dependent values. Decision making for water management in a complex basin such as the Murray-Darling requires multiple lines of evidence and balancing competing values and sources of information. HydroBOT brings a more consistent and rigorous capacity to include the responses of water-dependent values into that comprehensive assessment.

HydroBOT greatly improves the capacity of the relevant manager (here, demonstrated for the MDBA) to assess outcomes across a range of values, provides the structure to adapt and include additional values as additional component models become available, and addresses a number of issues with current assessment practices and modelling approaches. By providing a single consistent interface to a range of response models, we avoid the need to manually run models separately and we abstract their different interfaces, languages, and idiosyncrasies. Moreover, the design is highly modular, built to allow the integration of new response models with limited additional updates to HydroBOT itself. Continuing with this consistency, HydroBOT provides a standard set of synthesis approaches and functions that target management-relevant analysis and interpretation of outcomes from these disparate models with a common approach and design language. Because the need for assessing outcomes is nearly universal in water management and not limited to a particular scenario or project [@medema2008], HydroBOT is designed with strong scenario-comparison capabilities but is agnostic to what those scenarios represent. For a similar reason, the standardised synthesis and outputs are highly flexible, allowing the user to choose the most relevant outputs for different management needs.

One common issue with modelling in general, and particularly integrated models spanning several tools, is that such tools can become a black box where the relationships modelled are opaque. This can yield mistrust by the public and other stakeholders influenced by the model, but also mistrust and misunderstanding by users and developers of the model [@ascough2008]. To avoid these issues, HydroBOT has been continuously co-designed with the relevant management agency, the MDBA, and an emphasis is put on public code, reproducibility, self-documentation and production of outputs that describe the model itself in addition to its results (e.g. causal relationships).

To demonstrate HydroBOT, we develop a set of example scenarios capturing some qualitative aspects of one intended use: the assessment and comparison of outcomes under different climate scenarios and different management adaptations to those changes. These scenarios represent changes to the system due to processes over which managers have no control (i.e. a changing climate), and management actions which would typically be targeted interventions. We use this demonstration to illustrate the problem space and show how HydroBOT can aid in assessing potential system change and prioritising management actions to mitigate impacts.

# HydroBOT description

HydroBOT provides a flexible architecture with distinct components that can be run separately (in a modular fashion) or together to assess how various scenarios, such as climate change or management options, affect multiple sets of values spanning many scales and disciplines. This modularity enhances the iterative nature of decision making for water planning and policy and allows tuning for a particular set of management questions @fig-tktomgmt). Scenarios are typically represented by their effect on the hydrograph, though other inputs could be included if relevant (e.g. time series of variables such as temperature). HydroBOT then synthesizes a wide range of outputs from individual response models into results that directly compare scenarios and are digestible and useful for management decision making (@fig-tktomgmt). A co-design process including scientists, software developers, and managers was developed to ensure HydroBOT achieved its goal of producing scientifically robust results that are also management-relevant. *GALEN Lara really wants the quad bottom line out of this figure. I changed the caption a bit to try to address it, but I think we want to make the point that the response models can range across types of values. Should we tweak that box somehow to make that point and be less quad-bottom-line, or leave it?*

![Conceptualisation of HydroBOT architecture (blue arrows) and links to management decision making (yellow arrows). Scenarios, represented by hydrographs, reflect observed flows or modeled scenarios (produced via hydrological modelling outside HydroBOT). These hydrographs are fed in a consistent way to various response models via the HydroBOT Controller. These response models could assess response of any values of interest, here illustrated as a range of value types across environmental and human dimensions. Additional inputs of spatial data and causal networks provide grouping information for scaling via the HydroBOT Aggregator. The HydroBOT Comparer synthesizes the results into management-relevant outputs that aid decision making. This decision making process is also supported by feedback from stakeholders, other expert advice and the social and political landscape. Water planning and policy decisions can then guide the development of scenarios to assess potential management options, which in turn can be assessed with HydroBOT.](../images/conceptual.png){#fig-tktomgmt}

## Architecture

Taken holistically, the HydroBOT architecture comprises five primary components and the links between them (@fig-tktomgmt). The processing flow through HydroBOT is represented by the boxes along the top of @fig-tktomgmt, and in more detail in the Supplement (@suppfig-architecture). Input data (hydrographs) are ingested by the Controller, which packages and runs Response Models. Results from the Response Models are then processed by the Aggregator, and the analysis and final outputs are prepared by the Comparer. HydroBOT provides coordination of analyses through this workflow, as well as the algorithms within each component that provide needed functionality that can be tuned by the user with parameters for a particular analysis.

HydroBOT provides the tools and capacity to integrate disparate response models, which may be developed elsewhere, typically by subject-matter experts or for other purposes. Thus, the Response models is depicted as being defined externally to HydroBOT (@fig-tktomgmt; @suppfig-architecture), and new response models require development to integrate them into compatible, modular HydroBOT components. Causal networks and Spatial units are also typically sourced elsewhere and sit outside the data flow. These components provide groupings and relational information necessary for the Aggregator and Comparer. Causal networks define the complex inter-relationships defined in the response models and subsequent impacts on larger-scale values, while Spatial units define relevant spatial scales. As such, they are typically chosen and sourced based on the response models used and desired spatial scales and locations of analysis.

The HydroBOT architecture emphasizes modularity. Outputs can be saved at each step in the processing flow, allowing users to run HydroBOT as a whole or re-run only needed components to update analysis. For example, if a user wished to change how they aggregate the results of the modules, they could re-run the aggregation step and the subsequent comparison step to match without re-running earlier steps. This ability to adjust intermediate steps allows rapid iteration of results to address a given management question, or adaptation of preexisting results to new questions. Modularity also allows rapid, iterative development of HydroBOT itself. Any HydroBOT component can be updated, e.g. new aggregation functionality added, without affecting others. Obtaining new results utilising new capacity simply requires parameterising that capacity for a given analysis and re-running HydroBOT from that point forward.

Each step in HydroBOT is parameterised for a given analysis with arguments to a set of relevant functions. As each stage of HydroBOT runs it produces metadata files including the full set of parameters for that stage and all preceding stages. These files can be used as parameter files for subsequent runs to support reproducibility.

Here we describe the specific implementation of each component of HydroBOT (@fig-tktomgmt), with additional detail in Supplement. Each component of HydroBOT is distinct, allowing modular changes to be made without altering the function of other components.

### HydroBOT Controller {#sec-controller}

The HydroBOT 'Controller' is the interface between the externally generated input data (i.e. scenarios), the chosen response model, and other external and internal HydroBOT components (SI @suppfig-architecture). This component initiates the downstream processing steps according to user-defined settings for a particular run. It includes arguments for locating the input data and the response model(s) to use along with any necessary parameters for those models. The Controller can also control later components, allowing the full HydroBOT workflow to be run at once. These include defining aggregation steps as discussed in @sec-aggregator and analysis of the results with the Comparer (@sec-comparer). The Controller determines whether and where outputs are returned at each step. Having control over the full workflow enables large batched runs using parameter files to specify the control arguments in yaml files. This core functionality of the Controller is delivered via simple functions that apply to the input data for each scenario and can be parallelised over scenarios. The Controller can be accessed by the user by using Quarto notebooks to work interactively, R scripts, via the command line, or with yaml parameter files, depending on the use case.

### Causal networks {#sec-causal_networks}

Causal networks are models that describe the topology of dependence among many drivers and outcomes of different type [@peeters2022; @martínez2019]. The structure of the links (relationships) and nodes (state variables) can be derived from many sources, including empirical studies defining the existence of causal relationships or expert opinion. Causal networks define an overarching model from initial inputs (e.g. rainfall or flows or management actions) through to all values of interest (nodes), with each link defining a response model or component of a response model. The specifications of the models underlying each link are highly variable. These models range from detailed physical models linking runoff to flow, to simpler ecological models of environmental water requirements, simple averages, or leaving the model unspecified where information about the relationships is unavailable. Assessing the quality of knowledge around each link provides a powerful assessment of knowledge deficiencies and uncertainty in responses.

HydroBOT provides a causal network for included response models, where available, to describe how their outputs arise from hydrology and how they relate to various levels of management-relevant outcomes. The causal networks enable: 1) visual representation of the complex inter-relationships between scenario inputs and outcomes across a range of objectives and 2) assessment of outcomes scaled along the value dimension (see @sec-aggregator). The former aids transparency, elucidating the intentions and causal relationships behind the response models and is a useful device for communication alongside other final outputs. The latter allows outcomes to be quantified for individual (or sets of) values at different levels of complexity or groupings (e.g. fish breeding, individual fish species, native fish overall, or target fish condition), or at overarching sets of values such as environmental or economic groupings. This quantification provides a powerful assessment tool and the ability to identify synergies and trade-offs across interrelated values.

### Response models {#sec-modules}

The impacts of climate and management options on social, cultural, environmental, or economic values are estimated based on causal relationships between drivers (e.g. hydrology) and responses (e.g. the state of values). The response models may exist in many different forms, ranging from binary achievement of hydrologic indicators to fully quantitative responses. These tools are expected to be sourced from existing or in-development models developed by subject-matter experts and, as such, will be written in different languages and will target different outcomes. HydroBOT then provides a unified interface and ongoing analysis and modelling of the response model results.

Each response model has a distinct set of outputs, reflecting the captured responses and the structure of the model. When run within HydroBOT, these outputs are cleaned and processed into standard, expected formats for further processing, and metadata is saved. This enables HydroBOT to provide a consistent, unified home for disparate response models. The outputs can be saved to disk or retained in-memory for interactive use, depending on the user's needs. The outcomes of the response models are then processed by the Aggregator to provide outcomes at scales relevant for management decision making (in time, space or value dimensions; @fig-aggregation-dims).

### HydroBOT Aggregator {#sec-aggregator}

Response model output is typically very granular in many dimensions because the best response models operate near the scale of the processes being modelled [@levin1992; @holt2016; @gawne2018]. In many cases, those processes (e.g. fish breeding, crop planting) individually occur at small spatial and temporal scales. Note that this is the scale of the process itself, but may be repeated and connected over much larger scales. For example, fish may breed across a basin and migrate among breeding locations but each female breeds in only one location at a given time. Moreover, outcomes from response models are typically at small value scales as well, e.g. capturing portions of the life cycle of fish species, rather than an overall outcome for all fish, or representing planting of particular crops, rather than overall agricultural output. The consequence is that there are potentially thousands of different modeled outcomes across time, locations, and values. This plethora of outcomes must then be aggregated to extract meaning at larger scales and condense the information for digestibility in management decision making.

The HydroBOT aggregator aggregates and scales information to resolutions useful for interpretation and planning or that capture larger-scale processes. Depending on the use, the desired resolution(s) may range from local, short-term responses of fine-grained outcomes to large spatial scales over longer time periods for high-level outcomes such as environmental condition (@fig-aggregation-dims). For example, a response model might assess a suite of hydrologic indicators at individual gauges, but outcomes may be desired for a range of ecological groups within larger management units or at the basin scale. Likewise, multiple indicators are typically required to meet objectives for proximate ecological values, such as fish breeding, of which many are required for each larger ecological value (such as native fish diversity).

The HydroBOT Aggregator provides a robust, consistent aggregation approach along three dimensions (time, space, and value), while maintaining the ability to define those aggregation steps flexibly to meet the needs of the specific analysis. The aggregator consists of a set of functions that scale along each of the three dimensions while handling dimensional idiosyncracies, such as time arithmetic, spatial awareness, and many-to-many links in the causal network. Overarching functions coordinate these dimensional scaling functions, allowing stepwise aggregation along a sequence of dimensions and scales (@fig-aggregation-dims). These coordination functions maintain awareness of all dimensions; e.g. they ensure scaling in the spatial dimension does not accidentally collapse the value or temporal scale. The structure of the aggregator functions provides these safeguards and capability for sequential multidimensional scaling, while giving the user control over the sequence of those steps and the scaling functions used at each step.

The primary arguments to the aggregation functions are lists of the sequence of aggregation steps and the function(s) to apply at each step. The choice of aggregation sequence and scaling functions will change depending on the question being asked and the nature of the processes being modeled. Each step can be along any dimension and multiple functions can be assigned at each step. The sequence of aggregation steps can interleave the dimensions, e.g. aggregate first through time to cover the period of the hydrograph, then along the value dimension to an intermediate level, then aggregate in space, then value again. For example, following @fig-aggregation-dims, the user might want to aggregate from hydrologic indicator (EWR) to life-cycle values, such as waterbird fledging, to species at each gauge, then aggregate those gauges into a management unit or catchment to assess performance of each species over a larger area, followed by aggregating to values comprising ecological groups, e.g. native fish, waterbirds, native vegetation, or ecosystem function.

HydroBOT provides a standard set of MDB-relevant spatial units for aggregation but can also accept any user-supplied polygons (@fig-aggregation-dims). Aggregation along the value dimension follows the causal network, which is supplied by HydroBOT for included response models, though the user can specify other causal relationships if required. Supplied spatial units and causal networks are discussed in SI @sec-component-details. Whatever the spatial and causal relationships, HydroBOT provides the capacity to scale along them; it is the responsibility of the user to ensure those links and scaling functions are scientifically sound for the question at hand.

![Aggregation along multiple dimensions. HydroBOT provides flexible capability to aggregate along spatial, temporal and value scales. Boxes here show example scales, which may not all be used and which can be user-defined if others are needed. Users can control the sequence of steps along these axes, with the capability to switch between axes at different steps. Example spatial and value steps from demonstration in Murray-Darling basin, see SI @sec-glossary for definitions.](../images/aggregations.png){#fig-aggregation-dims width="16cm"}

The Aggregator allows the user to choose any aggregation function at each step. These aggregation functions should be considered carefully, as they should be appropriate to the processes being scaled and the outputs needed for management decision making. For example, in some situations the user might want to know the proportion of indicators that pass across some area, or perhaps the average value of an abundance measure. In this case, a mean would be appropriate. In other situations, however, a single failure may be disproportionately important (e.g. 'no loss' requirements), or perhaps a single passing value is sufficient for an ecological process to occur (e.g. bird breeding can occur anywhere in a catchment). These might be captured with a minimum and maximum, respectively. HydroBOT provides a standard set of functions (e.g. mean, max, min, and spatially-weighted mean), but the user can also specify any other aggregation function, including custom-written functions tailored to particular analyses.

The Aggregator self-documents into a yaml file, and its output datasets retain the full sequence and functions alongside each value, ensuring that values are always paired with their provenance and meaning.

### HydroBOT Comparer {#sec-comparer}

The HydroBOT Comparer is designed primarily to make comparisons between scenarios, including assessment and visualization of their differences. This component also provides generalized capacity to produce plots and other outputs such as tables using a consistent approach, even when not directly comparing scenarios. While the primary use of the comparer is comparing Aggregator output, hydrographs and direct Response model output can also use this functionality.

The functions within the Comparer can be divided into two main categories, those for analysis and those for plotting. Although in some instances presenting the absolute outcome values can be useful across scenarios, explicitly calculating comparisons (e.g. the absolute or relative difference between scenarios) provides distinct advantages. Difficulty in accurately simulating a complex system means that comparisons between scenario outcomes can be more useful and accurate because any bias in the baseline assumptions applies to all outcomes and the focus moves from the total level to the change between scenarios [@holt2024]. The best method for comparing will vary depending on the quantities being compared and the intended use of the comparison, so several common default options (e.g. differences, relative change) have been developed along with the flexibility for the user to define alternatives.

The comparison functions provide the ability to choose a baseline level for comparison, which may be one of the scenarios, but also may be a reference dataset or a scalar value. For example, we might want to compare a set of outcomes for climate scenarios to a 'no change' climate scenario, to historical observations, or to a mean value. Output values are calculated relative to the defined baseline using either default functions for the absolute or relative difference, or any other user-supplied function. These functions can be applied to any dataframe, but a major advantage of HydroBOT is including them within the plotting functions. This allows the generation of comparison plots from raw Aggregator outputs without the need for subsequent data calculations by the user and avoids potential errors that arise from repeated or forgotten data transformations in an analysis workflow.

The plotting functions in the Comparer provide capability to present and visualize comparisons using standardized procedures for all outputs within a project. Different purposes require different sets of outputs; for instance, maps are particularly useful for visualizing geographic patterns, tables and graphs typically provide more precise ability to assess impacts on values, and timeseries plots are useful for visualizing climate trajectories. While potential visualizations and comparisons vary widely depending on the intended use, the Comparer standardizes data cleaning and processing for each plot, as well as aesthetics and plotting approaches. This standardization ensures consistency across plot types and through the project, ensuring values plotted are robust and interpretable. Key to this standardization is the internal data cleaning, which allows the raw outputs of the Aggregator and arguments for the comparisons to be provided to the plotting functions. By standardizing data cleaning within the Comparer, we avoid losing information or performing unsupported data manipulations and so ensure the quality and meaning of the outputs. For example, because the plotting function was designed to incorporate temporal, spatial, and value dimensions, it identifies and prevents accidental overplotting or misleading lumping of data across dimensions.

## Implementation

HydroBOT is available as an R package (github.com/MDBAuth/HydroBOT), which provides a suite of functions representing the steps in the architecture. These functions are designed to be general, allowing users much flexibility in how they run HydroBOT for a particular set of analyses while retaining a consistent structure and outputs. Because translating from hydrologic scenarios to various responses is a general problem in water management, we expect the ways in which HydroBOT is used will be highly variable. Thus, by providing a general structure, users can target the particular questions and analyses needed for a given question. Although the initial impetus for creating HydroBOT was to assess climate scenarios, its use in practice can be far more general. Any hydrograph can be assessed, and any set of scenarios represented by hydrographs can be compared, provided a response model exists.

As a result of an initial scan of available response models in the Murray-Darling Basin, HydroBOT development proceeded with the EWR tool as a single response model, but with an architecture designed to allow modular integration of additional response models as they become available. The scan accentuated a critical feature of this modularity; HydroBOT is designed to incorporate and standardise models written in various languages and with a wide range of input needs and outputs. HydroBOT achieves this by wrapping those other tools so as to make their differences as hidden from the user as possible. In the case of Python modules, HydroBOT uses the *reticulate* R package [@ushey2023] in combination with small amounts of internal Python code to call Python modules directly. The Python code internal to HydroBOT performs limited cleaning and translation to prevent passing large objects between languages while ensuring that any idiosyncrasies in module inputs and outputs are handled consistently. Python dependencies (and Python itself) are automatically installed on first use of Controller functions that call Python modules unless they already exist on the user's system. This approach provides essentially invisible Python for most users, while providing flexibility for the user to provide their own Python environment if desired. Modules in other languages are not yet available, but the key requirement is that they be available in a format that is scriptable. In that case, HydroBOT will provide small setup and cleanup functions as with the Python modules and wrapper functions to call these modules.

The modularity of HydroBOT means it can be run stepwise, with the user calling the relevant functions at each step (@suppfig-architecture). The outputs of each step can be saved or returned directly to an interactive session or both. Typically, sufficient selected outputs would be saved for reproducibility and speed unless the project is small enough to retain a comprehensive set in memory or re-run quickly in a notebook. There are also wrapper functions that allow running the HydroBOT flow from Controller through Aggregator, which are extremely useful for large runs or remote runs on batching services. One particularly useful wrapper provides the ability to run from a yaml parameter file providing function arguments. This function allows the use of a default file and a 'modified run' file, making it ideal for holding many parameters constant at a default for a particular set of analyses and only changing some on a per-run basis in a smaller file. It also takes command-line or R list arguments, making it a flexible solution to run HydroBOT from the command line, in scripting contexts, or notebooks including Databricks and Quarto [@allaire2022].

The metadata saved at each step in the process is a yaml file with parameters that are a superset of those needed to run HydroBOT. Thus, an identical run can be produced by running HydroBOT using an output metadata file as an input parameter file, supporting reproducibility. Additional information is included in these exported yaml files documenting versions of HydroBOT and response models, as well as capturing any available metadata pertaining to the input scenarios. Even if a run is started in the middle, such as to re-run aggregation in a different way, the metadata for that run captures the metadata for the previous steps, ensuring that outputs at every stage are tagged with full provenance information.

In practice, HydroBOT functions are primarily run in one of two ways. Interactive investigation of relatively small sets of hydrographs and small numbers of scenarios can be done in notebooks (typically Quarto) or simple R scripts. Larger investigations typically would be run on remote computers as part of batching systems, whether HPC, Azure, AWS, Databricks, or other, with the outputs at the end of the aggregation (and potentially each step) returned. The Comparer step would usually not be run as part of this larger batching, but considered interactively for two reasons. First, through the aggregation step, all operations can proceed in parallel over scenarios, and HydroBOT provides internal capacity for this using futures [@bengtsson2021]. In some cases parallelizing over gauges is also possible. The Comparer necessarily looks across scenarios, and so breaks this parallelisation. Conducting comparisons interactively is typically not excessively CPU- or memory-intensive, provided the Aggregator step has been well thought through. If there are enough data to require high processing or memory, it is unlikely to be simplified enough to make interpretable figures and additional aggregation should be undertaken. Second, the primary goal of the Comparer is to produce usable, interpretable outputs. Arriving at a set of meaningful outputs is an iterative process that rarely will be precisely known *a priori*, and so working through this step interactively is necessary. If, however, HydroBOT is being used for ongoing monitoring of the same analyses (e.g. a 'dashboard'), then the first iteration could be done interactively, with subsequent uses incorporating those settings written into a script to auto-generate the same figures.

HydroBOT was originally designed for analyses of management questions in the Murray-Darling Basin and so, along with the functions to perform the analyses, it also provides a standard set of spatial data comprising the MDB itself, river lines and gauges within the MDB (at which hydrographs may be available), and various management units (see SI @sec-component-details). Some example hydrograph data are also included for testing and demonstration. HydroBOT provides a clean causal network for included modules, described in more detail in @sec-causal_networks and SI @sec-component-details. Analogous elements can be constructed for other spatial units or responses to extend functionality within or outside the Murray-Darling Basin.

## Co-design and scoping for management relevance

To ensure HydroBOT meets management needs and is trusted by management users, a team was created at project inception econsisting of primary HydroBOT developers, ecologists, hydrologic modelers, and managers. Collaboration among this team ensured decisions about HydroBOT construction reflected the needs of the end-user. As implementation proceeded, the collaboration provided a mechanism by which goals could be adjusted or the implications of decisions discussed and understood. By having this window into HydroBOT development, the managers obtained a much more granular view of how it operates, along with its capabilities and limitations. This view into HydroBOT development and reasoning was crucial to avoid the toolkit becoming a 'black box', and enhances trust, interpretability and usability of the HydroBOT outputs.

Key to the collaborative development was identification of the response models to include. These models needed to provide information about values relevant to water management decisions as those values respond to hydrology. Early in the development process, a wide scan was taken to identify candidate response models. This scan considered models being used or developed within the MDBA itself, other government agencies (both federal and state), and externally. A number of response models were found to be available, but many were outdated or highly manual, and their use was patchy both within and across management agencies [@holt2022]. Ultimately, only one was suitably modern and well-developed to include in HydroBOT, the Environmental Water Requirements (EWR) Tool [@murray-darlingbasinauthority2024]. Other in-development modules were identified as candidates to include during the development of HydroBOT, including economic and social models. Further, this scan identified values that are mandated management targets for which there were no available or in-development response models, highlighting areas needing future work.

# HydroBOT demonstration

Here, we present example results produced using HydroBOT, a set of demonstration scenarios, and the EWR tool for the response model (see @sec-ewr for a description of the EWR module and its associated causal network). These results demonstrate the flexibility and robustness of HydroBOT, which give it the capability to produce rigorous but interpretable and management-relevant results in a reproducible way.

## Demonstration scenarios

Our input data consists of hypothetical flow timeseries generated from historical hydrographs at `r length(unique(agged_data$ewr_code$gauge))` gauges. These gauges fall within the Lachlan, Macquarie--Castlereagh, and Namoi Sustainable Diversion Limit (SDL) units of the Murray-Darling Basin, Australia (@fig-sdl-comparison A). These SDL units have detailed Long Term Watering Plans (LTWPs), and so well-specified EWRs and causal networks [@nswdpiemacq2020; @nswdpielachlan2020; @nswdpienamoi2020].

We develop a set of simple scenarios that capture two sorts of changes that may be commonly represented in management analyses. First, we consider scaled flow throughout the period of the hydrograph, representing overall increases or decreases in flow as might occur from large-scale climate patterns. Second, we consider short-duration additions to flow, representing periodic pulses of change as might happen from targeted interventions. Each scenario characterizes all water in the system including natural inflows, extraction, and release of environmental water, yielding a complete hydrograph (SI @sec-scenarios shows a selected subset). These do not reflect realistic future scenarios but provide an avenue to test and illustrate the capabilities of HydroBOT.

To scale flow, we apply nine flow multipliers, ranging from 0.5 to 2.0, to the historical hydrographs (SI @supptbl-scenarios). We refer to these as 'climate' scenarios, reflecting a common representation where entire hydrographs might shift to represent climate change, though these scenarios are not derived from climate models and do not represent hypothesized climate change. To achieve pulsed change for each of the 'climate' scenarios, four flow additions were applied including 1) no addition (baseline), 2) addition of 250 ML/d, 3) addition of 6500 ML/d, and 4) addition of 12000 ML/d (SI @supptbl-scenarios). These additional flows were added throughout the period of September to December. We refer to these scenarios as 'climate adaptations' because management options are often available in the form of altering water availability for short time periods through mechanisms like water releases, though the options here do not represent proposed actions.

## EWR (Environmental Water Requirements) Tool {#sec-ewr}

The EWR tool, which forms the core of this demonstration, is a response model for hydrologic indicators of ecological outcomes. The EWR tool is written in Python and in use by the MDBA internally, the states of New South Wales and Queensland for water planning, and other interested stakeholders [@murray-darlingbasinauthority2024]. It models the response of hydrologic indicators in the Murray-Darling Basin chosen to indicate ecological values according to links established in Long Term Watering Plans and Environmental Water Management Plans [e.g. New South Wales, @nswdpiemacq2020; Victoria, @delwp2022; Queensland, @drdmw2022, South Australia, @dew2020]. The EWR tool holds databases of the environmental water requirements (EWRs; the indicators) and the volume, frequency, timing and duration of flows or inundation required to meet those indicators (SI @supptbl-ewrs). These indicators were developed based on hypothesized relationships to the ecological objectives of the MDB, which protect or enhance environmental assets and ecosystem functions that are valued based on ecological significance [@sheldon2024; @nswdpiemacq2020]. The EWR tool itself only assesses hydrologic indicators, determining whether spatially explicit flow timeseries data meets each EWR (indicator) at each gauge (illustrated in @fig-ewr-example). The precise definitions for each EWR differ at each gauge, due to the unique hydrology and channel morphology. For example, a small fresh for 10 days is required every year, ideally between October and April to meet indicator EWR SF1 (small fresh 1), but the flow volume defined as a 'small fresh' differs between gauges. Moreover, the expected ecological outcome for achieving SF1 might vary between gauges or catchments due to different impacts of small freshes on local species or ecological processes, as defined in the LTWPs.

```{r}
#| label: fig-ewr-example
#| fig-cap: !expr glue::glue("The flow levels of various EWRs are illustrated at two example gauges ({paste0(gauges_to_plot, collapse = ' and ')}) on historical hydrographs. This does not illustrate the required frequency, duration or timing for these EWRs; some of the lines crossed by the hydrograph here would not count as achieving the EWR if the flows did not stay above the relevant EWR line long enough or did not cross it again within the defined timeframe. See SI @supptbl-ewrs.")

ewrs_in_pyewr <- get_ewr_table() |> 
  rename(gauge = Gauge)

NSWEWR_gauge <- filter(ewrs_in_pyewr, gauge %in% gauges_to_plot) |>
  tidyr::separate_wider_delim(cols = Code, delim = '_', 
                              names = c("Code", "Timing"),
                              too_few = 'align_start',
                              too_many = 'merge') |>
  group_by(gauge) %>%
  distinct(Code, .keep_all = TRUE) |>
  mutate(FlowThresholdMin = as.numeric(FlowThresholdMin)) |>
  arrange(FlowThresholdMin) %>%
  mutate(Date = seq(from = max(scenehydros$Date), 
                    to = min(scenehydros$Date), 
                    length.out = n())) %>%
  ungroup()

hydro_plot_EWRs <- scenehydros |>
    dplyr::filter(scenario == 'climatebaseadapt0' & gauge %in% gauges_to_plot) |>
    ggplot2::ggplot(ggplot2::aes(x = Date, y = (flow/1000) + 1)) +
    ggplot2::geom_hline(data = NSWEWR_gauge, 
                        mapping = aes(yintercept = (FlowThresholdMin/1000) + 1),
                        colour = "red")+ #
    ggplot2::geom_line() +
    ggplot2::facet_grid(gauge ~ . , scales = 'free') +
    ggplot2::labs(y = paste0("Flow (GL/day +1)")) +
    theme_werp_toolkit(legend.position = "bottom") +
      guides(colour=guide_legend(nrow=2,byrow=TRUE)) +
    ggplot2::geom_label(data = NSWEWR_gauge, 
                        mapping = aes(x = Date, y = (FlowThresholdMin/1000)+1,
                                      label = Code), size = 3, colour = "black") +
  # tempted to use 'pseudo_log' and not add 1, but the ticks aren't as nice
  ggplot2::scale_y_continuous(trans = 'log10',
                              sec.axis = sec_axis(~ . , name = "Gauge ID", 
                                                  breaks = NULL, labels = NULL))

hydro_plot_EWRs
```

The EWR tool returns binary responses of hydrologic indicators and so, to link these to expected ecological responses, we extracted and cleaned causal networks from the relationships implied in the Long-Term Watering Plans (LTWPs), where the EWRs are defined [e.g. @nswdpiemacq2020]. These plans describe how the hydrologic indicators are expected to influence both proximate and larger-scale ecological outcomes according to the best available information from water managers, ecologists, scientific publications, and analysis of gauged and modelled flows [e.g. @nswdpiemacq2020; @lobegeiger2022]. Some links are provided as data in the EWR tool, while most were extracted for HydroBOT from the LTWPs. Clean causal networks incorporating both sets of links are provided in HydroBOT (all links for a single gauge in SI @suppfig-causal-example). Work is ongoing to improve these networks and extend their support across all basin states.

Causal networks expand the utility of the EWR driver-indicator model by linking its hydrologic indicators to the values for which the system is being managed, from components of the life cycle of single species to whole-community outcomes at 10- or 20-year target dates (see supplement for glossary [@sec-glossary]). This increases the transparency in the causal relationships that underpin the model and builds understanding and trust in the outcomes. For example, for the SF1 indicator described above might contribute to multiple ecological objectives pertaining to native fish (ecological objectives NF1-9; e.g. NF1 = No loss of native fish species), native vegetation (NV1), and ecosystem functions (EF1-5). These ecological objectives are defined to support the completion of all elements of a life cycle of an organism or group of organisms (taxonomic or spatial) to achieve a "defined goal for a state, condition or characteristic of an ecological asset or function" [@nswdpiemacq2020 p.x--glossary]. Outcomes for ecological objectives are then linked in the causal network to five large-scale ecological 'theme' groups [native fish, native vegetation, waterbirds, other species, and priority ecosystem functions, @murray-darlingbasinauthority2019] and are associated with long-term targets (5, 10, and 20 year). This structure not only provides a visual definition of the links in the LTWP, it also enables assessment of outcomes that are directly equivalent to the LTWP management strategies.

### EWR aggregations for demonstration

For simplicity for this demonstration, we use arithmetic means for all aggregations except the initial step along the value dimension, though we typically present results only after this first step. In the EWR tool, the returned outcomes (and so finest scale on value dimension) gives achievement of multiple versions of EWR indicators, typically representing different leniency in flow conditions required to pass. Here, we consider that if an EWR is achieved for any of its possible definitions, it is achieved. We thus use a maximum for that first aggregation step. Though we use means throughout, their meaning changes depending on the level of aggregation. For simplicity, we assume the value of each outcome represents some 'condition', and the 'condition' at a particular level can be assessed as the mean of the conditions contributing to it. For example, the condition of detailed ecological values such as fish spawning or bird fledging might simply be the proportion of EWRs that contribute to each value that are achieved. Then, the condition of ecological groups, e.g. native fish, might be the mean condition over all the NF1...n values, despite those depending on different numbers and sets of EWRs. This captures the idea that native fish condition improves when the life-cycle components captured by those lower-level values are met, whether it takes 1 or 10 EWRs.

```{r}
#| label: simplfy-for-plots
#| include: false

# Create a grouping variable
obj_sdl_to_plot <- agged_data$sdl_units |>
  dplyr::mutate(env_group = stringr::str_extract(env_obj, '^[A-Z]+')) |>
  dplyr::filter(!is.na(env_group)) |>
  dplyr::arrange(env_group, env_obj)

obj_sdl_to_plot <- obj_sdl_to_plot |>
  mutate(Target = case_when(env_group == "NF" ~ "Native fish",
                            env_group == "NV" ~ "Native vegetation" ,
                            env_group == "OS" ~ "Other species",   
                            env_group == "EF" ~ "Priority ecosystem function", 
                            env_group == "WB" ~ "Waterbirds",
                            env_group == NA ~ NA))


# We can use spatial_aggregate directly to go straight to sdl from EWR without first averaging over env_obj or gauges. This gives a pure measure of the proportion ewr met in each sdl without issues of uneven contributions.
agg_ewr_sdl <- agged_data$ewr_code |> 
  spatial_aggregate(to_geo = sdl_units, 
                    groupers = c('scenario', 'climate_code', 'adapt_code'),
                    aggCols = ewr_achieved,
                    funlist = 'ArithmeticMean') |> 
  rename(ewr_achieved = spatial_ArithmeticMean_ewr_achieved)


```

## Demonstration results

Comparison of the direct outputs from the response model (in this example, pass/fail of EWRs) without any aggregation along the value dimension gives an overview of ecologically-relevant hydrologic outcomes at different locations (e.g. gauges) or areas (e.g. SDL units) to different scenarios (@fig-sdl-comparison). Three focal climate scenarios (A, E and I; 0.5x, no change and 2x the historical base level, respectively) and three adaptation options (1, 2 and 3; additions of 0, 250 and 6500 ML/d, respectively) affect each SDL unit differently, with each catchment having some scenarios in which they have higher EWR achievement than the others. In all situations, the 'climate' scenarios have less of an impact than the 'adaptation' scenarios, though neither is reflective of expected change in these dimensions. These outcomes are not linked to ecological values here (e.g. priority ecosystem functions or environmental assets) and so each hydrologic indicator (EWR) at each gauge is represented with equal importance, whether it is required for all ecological values or just one.

```{r}
#| label: fig-gauges
#| include: false

relevant_gauges <- filter(bom_basin_gauges,
                          gauge %in% unique(scenehydros$gauge))

relevant_sdl_units <- agged_data$sdl_units |>
  distinct(SWSDLName, geometry, .keep_all = TRUE)

# relevant_basin_rivers2 <- relevant_sdl_units |>
#   rename(sdl_geometry = geometry)|>
#   st_join(basin_rivers)
  
relevant_basin_rivers <-  basin_rivers |>
  st_intersection(relevant_sdl_units) |> 
  filter(ORD_STRA >= 4)

gauge_plot <- relevant_sdl_units |>
           plot_outcomes(outcome_col = 'SWSDLName',
              plot_type = 'map',
              colorset = 'SWSDLName',
              pal_list = SDL_pal,
              #underlay_list = list(list(underlay = basin,
              #                     pal_list = 'azure')),
              overlay_list = list(
                list(overlay = relevant_basin_rivers,
                                        pal_list = 'lightblue1'),
                list(overlay = relevant_gauges,
                                   pal_list = 'firebrick')
                                   )) +
theme_werp_toolkit(axis.ticks = element_blank(), 
                   axis.text=element_blank(),
                   axis.title=element_blank())+
theme(legend.position = "none")+
  scale_x_continuous(limits = c(144, 151.5)) +
  scale_y_continuous(limits = c(-35, -29.7))+
  ggspatial::annotation_scale()

gauge_plot

inset_map <- ggplot(ozmaps::ozmap_country) +
  geom_sf(fill = 'grey20') +              
  geom_sf(data = basin, fill = 'azure') +
  geom_sf(data = agged_data$sdl_units, color = 'NA', aes(fill = SWSDLName))+
  theme_werp_toolkit(axis.ticks = element_blank(), 
                     axis.text=element_blank(),
                     axis.title=element_blank())+
  scale_x_continuous(limits = c(113, 153)) +
  scale_y_continuous(limits = c(-43.63, -9.22))+
  scale_fill_manual(values = SDL_pal)+
  theme(legend.position = "none")+
  ggspatial::annotation_scale()



# # Why on earth does this print a dataframe of the corners? Islands
# overview_map <- gauge_plot +
#   patchwork::inset_element(inset_map, left = 0.01, bottom = 0.7,
#                            right = 0.4, top = 1)

```

```{r}
#| label: fig-sdl-comparison
#| fig-cap: (a) Location of the Murray-Darling basin in eastern Australia. (b) Gauge locations within three SDL units (Macquarie –- Castlereagh, Lachlan, and Namoi). (c-d) Scenario comparison for different Sustainable Diversion Limit areas emphasizing quantitative differences (c) and (d) spatial patterns. The proportion of environmental watering requirements (EWRs) that are achieved under each scenario for each SDL unit are shown. Climate scenarios and adaptation options as in SI @supptbl-scenarios.
#| message: false

# The bars
sdl_achieve_bars <- agg_ewr_sdl |> 
  filter(scenario %in% scenarios_to_plot) |> 
  mutate(scenario = paste0(climate_code, adapt_code), # This makes the names clean
         SWSDLName = stringr::str_replace(SWSDLName, '–', '-\n')) |> 
  plot_outcomes(outcome_col = 'ewr_achieved',
                outcome_lab = 'Proportion\nEWR achieved',
                x_col = 'scenario',
                x_lab = 'Climate and adaptation scenario',
                colorset = 'SWSDLName',
                color_lab = '',
                pal_list = SDL_pal |> 
                  setNames(stringr::str_replace(names(SDL_pal), '–', '-\n')),
                position = 'dodge',
                setLimits = c(0,1)) +
  # guides(fill = guide_legend(nrow=2, label.position = 'top')) +
  theme(legend.position = 'bottom')

  # if we really want facetted, this will do it, but I don't think it's needed:  
# facet_col = 'scenario',
# scales = 'free_x',

# The map
sdl_achieve_map <- agg_ewr_sdl |> 
  filter(scenario %in% scenarios_to_plot) |> 
  plot_outcomes(outcome_col = 'ewr_achieved',
                outcome_lab = 'Proportion\nEWR achieved',
                plot_type = 'map',
                facet_row = 'climate_code',
                facet_col = 'adapt_code',
                colorset = 'ewr_achieved',
                pal_list = achieve_pal,
                #underlay_list = list(underlay = basin, underlay_pal = 'azure'),
                setLimits = c(0,1))

sdl_achieve_map <- sdl_achieve_map +
  theme(legend.position = 'bottom', 
        axis.ticks = element_blank(), 
        axis.text = element_blank()) +
  scale_y_continuous(sec.axis = sec_axis(~ . , name = "Climate scenario", 
                                         breaks = NULL, labels = NULL)) +
  scale_x_continuous(sec.axis = sec_axis(~ . , name = "Adaptation option",
                                           breaks = NULL, labels = NULL))

wrap_elements(full = inset_map) + wrap_elements(full = gauge_plot) +
wrap_elements(full = sdl_achieve_bars) + wrap_elements(full = sdl_achieve_map) + 
  patchwork::plot_layout(nrow = 2, heights = c(5,10, 10)) & 
  plot_annotation(tag_levels = "a")

```

We use the causal networks to link these response model outputs to ecological outcomes and investigate how changes in flow affect ecological values at a range of detail. Thus, we can compare how native fish, native vegetation, waterbirds, other species, and ecosystem function targets are likely to respond to our hypothetical set of climates and adaptation scenarios (@fig-radar). Indeed, one of the primary purposes of HydroBOT is to provide this assessment of how high-level values respond to different scenarios. Such a summary collapses thousands of datapoints (EWR outcomes or proximate ecological responses) across many scenarios into digestible yet scientifically-robust visualisations. At a glance, we can see in @fig-radar that Priority ecosystem function outperforms Native vegetation in all scenarios, but is less sensitive to changes between them. Halving water (moving from E to A) reduces Native fish outcomes more than doubling water (E to I) improves them, while the opposite is true for Waterbirds, and Native vegetation function responds roughly proportionally.

```{r}
#| label: make-radar
#| include: false

# Names dont match
agged_data$Target <- agged_data$Target |> 
  mutate(Target = ifelse(Target == 'Waterbird', 'Waterbirds', Target))

# Pretty should work better to just feed it the data, but it's not, so do a workaround
yMax = max(filter(agged_data$Target, 
                  scenario %in% scenarios_to_plot2 & 
                    !is.na(Target) & 
                    SWSDLName == "Macquarie–Castlereagh")$ewr_achieved) |> 
  pretty() |> max()
ymin = 0 #RELATIVE VERSIONS OF THIS PLOT WILL HAVE VALUES LESS THAN ONE

line_df <- tibble(y = c(ymin, yMax/2, yMax))

# Make background
background_df <- data.frame(Order = as.factor(seq(1, length(unique(agged_data$Target$Target)))),
                            Target =  factor(unique(agged_data$Target$Target),
                                             levels = unique(agged_data$Target$Target)), 
                            y = max(agged_data$Target$ewr_achieved),
                            scenario = unique(agged_data$Target$scenario)[1])|>
    mutate(Order = as.numeric(Target))|>
  filter(!is.na(Target))


plt_2 <- agged_data$Target |>
  filter(SWSDLName == "Macquarie–Castlereagh")|> #
  mutate(Order = as.numeric(Target))|>
  filter(scenario %in% scenarios_to_plot2 & !is.na(Target))|>
  ggplot(
      aes(
      x = reorder(stringr::str_wrap(Target, 6), Order),
      y = ewr_achieved,
      fill = climate_code)) +
  #Make background colours:
    geom_col(data = background_df,
           aes(x = reorder(stringr::str_wrap(Target, 6), Order), 
               y = yMax, fill = Target), colour = NA, width = 1, alpha = 0.4)+
    geom_col(data = background_df,
           aes(x = reorder(stringr::str_wrap(Target, 6), Order), 
               y = ymin, fill = Target), colour = NA, width = 1, alpha = 0.4)+
  # Make dashed lines:
  geom_hline(data = line_df,
    aes(yintercept = y),
    color = "grey40", linetype = "longdash"
  ) +
    geom_text(data = line_df,
    aes(label = y, y = y, x = "Waterbirds", fill = "Max"),
    nudge_x = 0.5, color = "grey20"
  ) +
  # Make scenario BARS - EWR achieved
   geom_col(position=position_dodge(),width=0.65,size=0.3) +
  # Make arrows:
  geom_segment(
    aes(
      x = stringr::str_wrap(Target, 6), y = ymin, 
      xend = stringr::str_wrap(Target, 6), yend = yMax),  
    linetype = "solid", color = "gray20",arrow = arrow(length = unit(0.25, "cm"), type = "closed"), linewidth = 0.2) + 
  coord_cartesian(ylim = c(ymin, yMax))+
  # Make it circular:
  coord_polar()+
  theme_werp_toolkit(axis.ticks = element_blank(),
                     axis.text.y = element_blank(), # Leave .x, they label the arrows
                     text = element_text(size = 10), 
                     axis.title.x = element_blank(), 
                     axis.title.y = element_blank()) +
  scale_fill_manual(values = sceneTarget_pal,
                    aesthetics = "fill", breaks = c("A", "E", "I"), 
                    name = "Climate\nscenario")

```

```{r}
#| label: fig-radar
#| fig-cap: Condition results for large ecological groupings and three climate scenarios. Visualising as a radar plot allows comparing outcomes of disparate thematic variables (as illustrated in the graphical abstract) and is useful for quick broad-scale representation of the results. Outcomes here for Macquarie–-Castlereagh SDL unit. Dotted lines provide axis values, with the outer line corresponding to a condition of 0.5 and the center of the circle being a condition of 0.  

plt_2

```

High-level outcomes are essential, but managers need to drill down to understand how they arise, including comparing lower-level values, spatial areas, and the scenarios themselves. While there are many ways to display this information (See SI @sec-map-versions for spatial analysis of each step), @fig-obj_in_groups consolidates a large amount of information across scenarios, planning units, and multiple value scales. Each set of colours (and row of panels) represents outcomes at the scale of large ecological value groups. Within each bar, the different shades represent single smaller-scale ecological values (e.g. WB1; Maintain the number and type of waterbird species) contributing to the larger value group, with the heights of these shades being the proportion of the constituent hydrologic requirements that are met (EWRs). Because the overall bar heights are then a sum of these proportions, we provide a dashed line as reference that shows the situation where all EWRs are met. This reference is necessary because the number of EWRs contributing to each small-scale ecological value varies, as does the number of small-scale ecological values contributing to the larger ecological value groups and spatial units. Dividing total bar heights by this line would thus give the proportional 'condition' score for the larger groupings.

This view provides a useful overview of the impact of different scenarios on large ecological value groups across space, while also retaining the ability to assess more proximate constituent ecological values. For example, WB1 (Maintain the number and type of waterbird species) and WB2 (Increase total waterbird abundance across all functional groups) are only achieved to any appreciable extent in the Macquarie--Castlereagh in the high water addition (3) scenarios, while they are met more generally in the Namoi, and show an interaction with the 'climate' scenarios in the Lachlan (met in 'adaptation' scenarios 1 and 2 only in the doubled water 'climate' scenario). At the larger ecological value group scale, we can see that the effect of halving water (moving from the baseline E1 scenario to the A1 scenario) has a disproportionately greater impact on Native fish than doubling water (the I1 scenario) in the Macquarie--Castlereagh, while the Lachlan and Namoi show larger impacts of doubling than halving.

```{r}
#| label: fig-obj_in_groups
#| fig-cap: "EWR achievement for broader ecological values, including: priority ecosystem function (EF), native fish (NF), native vegetation (NV), other species (OS) and waterbirds (WB) (colors & rows). Columns are scaled to illustrate the number of ecological objectives that contribute to each broader ecological value, and shades of colours illustrate the proportion of EWRs that contribute to each constituent smaller-scale value, i.e. if all EWR contributing to ecological objectives for each ecological values the columns would reach the dashed horizonal lines. This view provides an assessment of the performance of individual small-scale values, as well as how those contribute to the overall sensitivity of the broader groups. Not all EWRs are applicable in all locations and there are not equal number of EWR in each category, hence different values of the dashed lines. This illustration includes three climate scenarios: A (0.5x), E (historical base level/no change), and I (2x); and three adaptation options: 1 (no adaptation), 2 (+250 ML/d), and 3 (+6500 ML/d). Columns for scenarios A1, E1, and I1 for Macquarie--Castlereagh correspond to values shown in @fig-radar." 
#| message: false
#| warning: false

obj_in_groups <- obj_sdl_to_plot |>
  filter(env_group != 'EB') |> # There's only one, this is just distracting.
  filter(scenario %in% scenarios_to_plot) |> 
  # clean the names
  mutate(scenario = paste0(climate_code, adapt_code), 
         SWSDLName = stringr::str_replace(SWSDLName, '–', '-\n'),
         Target = stringr::str_replace(Target, 'Priority e', 'E'),
         Target = stringr::str_wrap(Target, width = 12)) |> 
  plot_outcomes(outcome_col = 'ewr_achieved',
                outcome_lab = "EWR achievement\nassessed for individual EWRs (shades)",
                x_col = 'scenario',
                x_lab = "Climate & Adaptation Option Scenario",
                colorgroups = 'env_group',
                colorset = 'env_obj',
                pal_list = env_pals,
                color_lab = "Ecological\nobjectives",
                facet_col = 'SWSDLName',
                facet_row = 'Target', 
                scales = 'free_y',
                sceneorder = rename_sceneorder
                )

# ADD IN MAX: new way?
maxdata <- obj_sdl_to_plot |> 
  st_drop_geometry() |> 
  filter(env_group != 'EB') |> # There's only one, this is just distracting.
  filter(scenario %in% "MAX") |> 
  # clean the names
  mutate(SWSDLName = stringr::str_replace(SWSDLName, '–', '-\n'),
         Target = stringr::str_replace(Target, 'Priority e', 'E'),
         Target = stringr::str_wrap(Target, width = 12)) |> 
  summarise(ewr_achieved = sum(ewr_achieved), 
            .by = c(SWSDLName, Target))

obj_in_groups <- obj_in_groups +
  geom_hline(data = maxdata, 
             mapping = aes(yintercept = ewr_achieved),
             linetype = 'dashed', color = 'grey30')

obj_in_groups

```

Calculating comparisons from a baseline clarifies disproportionate impacts and thresholds where management actions could be most effective. Here, we represent both our 'climate' and 'adaptation' scenarios on a single axis by quantifying the difference in mean flow from the baseline condition (historical hydrograph, E1) using the baselining functionality provided by HydroBOT (see @sec-baselining). Plotting the proportion of EWRs achieved for each of the Native fish ecological values shows how that EWR achievement is related to changes in the overall levels of flow. One striking feature of @fig-difference-baseline is that the lines do not smoothly increase; EWR achievement is not simply a direct relationship to flow volumes. Instead, the timing matters. There are particularly steep slopes between the '1' (baseline) and '2' (+250 ML/d) adaptations. The application of water at those particular times is thus disproportionately impactful. Indeed, the 'A2' scenarios yield better outcomes than the 'E1' even though they have less water. The same is true for 'E2' compared to 'I1' in the Macquarie – Castlereagh and Namoi. Such analyses can identify highly efficacious points to add water to the system, provided they represent real responses rather than model artefacts.

```{r}
#| label: fig-difference-baseline
#| fig-cap: "Quantitative scenario comparison for Native fish objectives for three SDL units. Scenarios defined here as the difference in mean flow (GL) from the baseline historical scenario (E1). The lines are not smooth – EWR achievement is not simply a function of the amount of water. Instead, the 'adaptation' options, particularly the '2' scenarios of adding 250 ML/d of water, have disproportionately large impact (steep slopes). Shading indicates different ecological objectives within the native fish ecological value. Three climate scenarios are shown: A (0.5x), E (historical base level/no change), and I (2x) and three adaptation options: 1 (no adaptation), 2 (+250 ML/d), and 3 (+6500 ML/d). HydroBOT provides inbuilt capacity for baselining with differences, relative change, or user-defined comparison functions. Difference was used here due to some additive flow changes, though relative would be a reasonable choice as well."
#| message: false


# We use dif_flow as a join here because this is baselining the *inputs*- the amount of flow. And so we have to do it here, not in plot_outcomes where we use it, since that baselines the *outputs* (EWR achievement)

gl_difference <- obj_sdl_to_plot |>
  dplyr::filter(scenario %in% scenarios_to_plot) |>
  dplyr::filter(env_group == 'NF') |> 
  left_join(dif_flow, by = 'scenario') |> 
  # clean names
  mutate(SWSDLName = stringr::str_replace(SWSDLName, '–', '-\n')) |> 
  
  plot_outcomes(outcome_col = 'ewr_achieved',
                outcome_lab = "Proportion EWR achieved",
                x_col = "scenario_difference",
                x_lab = "Mean flow difference (GL)",
                colorgroups = 'env_group',
                colorset = 'env_obj',
                pal_list = env_pals,
                # base_lev = 'E1',
                # comp_fun = 'difference',
                # group_cols = c('env_obj', 'polyID'),
                color_lab = "Ecological\nobjectives",
                facet_row = 'SWSDLName',
                facet_col = '.') 

gl_difference <- gl_difference + 
  geom_vline(data = filter(scenarios, scenario  %in% scenarios_to_plot),
             mapping = aes(xintercept = scenario_difference))

# This gets pretty close without needing the weird extra facet
# gl_difference <- gl_difference + 
#   geom_text(gl_difference$data |> filter(SWSDLName == "Lachlan"),
#             mapping = aes(label = scenario, y = Inf),
#             vjust = 1.5, size = 3)

header_difference <-  scenarios |> 
  filter(scenario  %in% scenarios_to_plot) |> 
  mutate(scenario = ifelse(scenario == 'MAX', 'MAX', 
                           paste0(climate_code, adapt_code))) |> 
  ggplot(aes(x = scenario_difference,
             y = 1)) +
  # geom_vline(mapping = aes(xintercept = scenario_difference)) +
  # ggrepel::geom_text_repel(mapping = aes(label = scenario),
  #                          # size = 3,
  #                          angle = 90,
  #                          direction='x') +
  # This kind of works better if we get rid of vline. The repel just isnt' working very well
  geom_text(mapping = aes(label = scenario), size = 3) +
  theme_werp_toolkit(legend.position = "none", axis.title=element_blank(),
                     axis.text=element_blank(), axis.ticks=element_blank())

# put those together
header_difference + gl_difference + 
  plot_layout(ncol = 1, heights = c(1,15)) + theme(legend.position = "right")
```

```{r}
#| label: build-smooth-figs
#| include: false
sdl_smooth_groups <- obj_sdl_to_plot |>
  dplyr::filter(adapt_code %in% c(1,2,3) &
                  scenario != 'MAX') |> # max isn't really relevant here
  dplyr::filter(env_group != 'EB') |> 
  # mutate(ewr_achieved = ewr_achieved + 1) |> 
  # clean names
  mutate(scenario = paste0(climate_code, adapt_code), 
         SWSDLName = stringr::str_replace(SWSDLName, '–', '-\n'),
         adapt_code = as.character(adapt_code)) |>
  plot_outcomes(outcome_col = 'ewr_achieved',
                x_col = 'flow_multiplier',
                outcome_lab = 'Condition',
                x_lab = 'Flow relative to baseline',
                transx = 'log10',
                transy = 'log10',
                scales = 'free_y',
                
                color_lab = 'Adaptation',
                colorgroups = NULL,
                colorset = 'adapt_code',
                # point_group = 'env_obj',
                pal_list = adapt_pal,
                facet_row = 'env_group',
                facet_col = 'SWSDLName',
                position = position_jitter(height = 0, width = 0.02),                
                zero_adjust = 0.01, # needed here to make the trans work.

                base_list = list(base_lev = 'E1',
                                 comp_fun = 'relative',
                                 group_cols = c('env_obj', 'polyID')),
                smooth_arglist = list())

# This is better in some ways and worse in others, flippig the colors and facets
sdl_smooth_groups_flipped <- obj_sdl_to_plot |>
  dplyr::filter(adapt_code %in% c(1,2,3) &
                  scenario != 'MAX') |> # max isn't really relevant here
  dplyr::filter(env_group != 'EB') |> 
  # mutate(ewr_achieved = ewr_achieved + 1) |> 
  # clean names
  mutate(scenario = paste0(climate_code, adapt_code), 
         SWSDLName = stringr::str_replace(SWSDLName, '–', '-\n')) |>
  plot_outcomes(outcome_col = 'ewr_achieved',
                x_col = 'flow_multiplier',
                outcome_lab = 'Ecological objectives\nrelative to baseline',
                x_lab = 'Flow relative to baseline',
                transx = 'log10',
                transy = 'log10',
                scales = 'free_y',
                
                color_lab = 'Ecological values',
                colorgroups = NULL,
                colorset = 'env_group',
                # point_group = 'env_obj',
                pal_list = list('scico::berlin'),
                facet_row = 'adapt_code',
                facet_col = 'SWSDLName',
                position = position_jitter(height = 0, width = 0.02),
                zero_adjust = 0.01, # needed here to make the trans work.

                base_list = list(base_lev = 'E1',
                                 comp_fun = 'relative',
                                 group_cols = c('env_obj', 'polyID')),
                smooth_arglist = list())

# just native fish in the Namoi
# This is better in some ways and worse in others, flippig the colors and facets
sdl_smooth_groups_NFNamoi <- obj_sdl_to_plot |>
  dplyr::filter(adapt_code %in% c(1,2,3) &
                  scenario != 'MAX') |> # max isn't really relevant here
  dplyr::filter(env_group == 'NF' & SWSDLName == 'Namoi') |> 
  # mutate(ewr_achieved = ewr_achieved + 1) |> 
  # clean names
  mutate(scenario = paste0(climate_code, adapt_code), 
         SWSDLName = stringr::str_replace(SWSDLName, '–', '-\n'),
         adapt_code = as.character(adapt_code)) |>
  plot_outcomes(outcome_col = 'ewr_achieved',
                x_col = 'flow_multiplier',
                outcome_lab = 'Condition',
                x_lab = 'Flow relative to baseline',
                transx = 'log10',
                transy = 'log10',
                scales = 'free_y',
                
                color_lab = 'Adaptation',
                colorgroups = NULL,
                colorset = 'adapt_code',
                # point_group = 'env_obj',
                pal_list = adapt_pal,
                facet_row = 'Target',
                facet_col = 'SWSDLName',
                position = position_jitter(height = 0, width = 0.02),                
                zero_adjust = 0.01, # needed here to make the trans work.

                base_list = list(base_lev = 'E1',
                                 comp_fun = 'relative',
                                 group_cols = c('env_obj', 'polyID')),
                smooth_arglist = list())


# What if we really try to smash down what we're showing? The adaptations are blowing it out. Which is a good message, but confusing. Maybe it's a two-parter?

# First, the climate response at no adaptation
sdl_smooth_clim <- obj_sdl_to_plot |>
  dplyr::filter(adapt_code %in% c(1) &
                  scenario != 'MAX') |> # max isn't really relevant here
  dplyr::filter(env_group != 'EB') |> 
  # mutate(ewr_achieved = ewr_achieved + 1) |> 
  # clean names
  mutate(scenario = paste0(climate_code, adapt_code), 
         SWSDLName = stringr::str_replace(SWSDLName, '–', '-\n')) |>
  plot_outcomes(outcome_col = 'ewr_achieved',
                x_col = 'flow_multiplier',
                outcome_lab = 'Condition',
                x_lab = 'Flow relative to baseline',
                transy = 'log10',
                transx = 'log10',
                scales = 'free_y',
                color_lab = 'Ecological values',
                colorgroups = NULL,
                colorset = 'Target',
                # point_group = 'env_obj',
                pal_list = Target_pal,
                facet_row = '.',
                facet_col = 'SWSDLName',
                position = position_jitter(height = 0, width = 0.02),
                zero_adjust = 0.01, # needed here to make the trans work.

                base_list = list(base_lev = 'E1',
                                 comp_fun = 'relative',
                                 group_cols = c('env_obj', 'polyID')),
                smooth_arglist = list())

# Next, the adaptation response at no climate
sdl_smooth_adapt <- obj_sdl_to_plot |>
  dplyr::filter(climate_code %in% c('E') &
                  scenario != 'MAX' & 
                  flow_addition < 10000 ) |> # max isn't really relevant here, and 12,500 is a LOT
  dplyr::filter(env_group != 'EB') |> 
  # get the log to work, saying we added 1 is fine here
  mutate(flow_addition = flow_addition + 1) |>
  # clean names
  mutate(scenario = paste0(climate_code, adapt_code), 
         SWSDLName = stringr::str_replace(SWSDLName, '–', '-\n')) |>
  plot_outcomes(outcome_col = 'ewr_achieved',
                x_col = 'flow_addition',
                outcome_lab = 'Condition',
                x_lab = 'Flow addition (ML/d)',
                transx = 'log10',
                transy = 'log10',
                scales = 'free_y',
                color_lab = 'Ecological values',
                colorgroups = NULL,
                colorset = 'Target',
                # point_group = 'env_obj',
                pal_list = Target_pal,
                facet_row = '.',
                facet_col = 'SWSDLName',
                position = position_jitter(height = 0, width = 0.02),
                zero_adjust = 0.01, # needed here to make the trans work.
                base_list = list(base_lev = 'E1',
                                 comp_fun = 'relative',
                                 group_cols = c('env_obj', 'polyID')),
                smooth_arglist = list())
```

With a large number of scenarios, we can characterize how values respond along axes relevant to how those scenarios change. Here, we use smoothed fits to show trends in the performance of ecological values (and groups thereof) in response to changes in flow from both 'climate' and 'adaptation' scenarios (@fig-smooth-climate-adapt, SI @suppfig-smooth-all). We use baselining (see @sec-baselining) to show the relative change on both the x (flow) and y (response) axes. Thus, any slope other than 1:1 represents a disproportionate shift in condition. The responses seen in @suppfig-smooth-all vary between SDL unit (columns) and ecological values, indicating different sensitivity to both 'climate' and 'adaptation' flow conditions across space and among ecological groupings. For example, Waterbirds respond disproportionately positively to flow across the range in the Lachlan but approximately proportionately to flow changes in the Macquarie--Castlereagh and Namoi. Native vegetation responds disproportionately positively to both increases and decreases in flow in the Macquarie--Castlereagh, while Native fish and Ecosystem function are both more sensitive to decreases than increases. By using smoothed fits, we can identify thresholds or areas of flow change that are disproportionately more important (small changes in flow can yield large shifts in condition).

The response to 'adaptation' options (difference between the lines in @fig-smooth-climate-adapt panel b) tends to be much stronger than the response to 'climate' (slopes), even though the shift in total water may be lower (particularly for the baseline '1' and +250 ML/d '2' adaptations; see x-axis of @fig-difference-baseline). Moreover, the adaptation options are not equally sensitive to the climate scenarios; adaptation options '2' and '3' show less change in response to climate than '1' (no adaptation) (@suppfig-smooth-all b). Thus, these 'adaptations' are increasing resilience to holistic 'climate' flow changes. Although these scenarios do not represent true adaptation options or climate scenarios, this shows that such changes to resilience are possible with targeted interventions, and HydroBOT provides the capacity to investigate them.

```{r}
#| label: fig-smooth-climate-adapt
#| fig-cap: (a) Smoothed fits of shifts in condition (proportion of EWR achieved relative to the scenario with no climate or adaptation changes [E1]) of broad ecological values to relative changes in water availability (also relative to E1). All climate scenarios (without adaptation; adaptation = 1) are included. Dashed lines help visualise proportionality of outcome relative to flow changes -- the lower line is a halving of condition, upper is a doubling. (b) The full combination of scenarios (all climate and adaptations options) are shown for the example of native fish in the Namoi (with each represented as a dot). This illustrates the larger impact of the 'adaptation options' used here compared to the 'climate' shifts; differences between lines are greater than the change along the lines. Fitted lines are loess smooths. Y-axes are restricted to better visualise the majority of the data; thus, a small amount of data is not plotted but is accounted for in the loess fits. The full set of SDL units and groups as in b are shown in SI @suppfig-smooth-all.
#| message: false
#| warning: false

sdl_smooth_clim + 
  # GALEN- the transy above in the plot_outcomes isn't working, we shouldn't have to do this next line
  scale_y_continuous(trans = 'log10') +
  coord_cartesian(ylim = c(0.25, 4)) +
  labs(y = 'Condition relative\nto baseline') +
  geom_hline(aes(yintercept = 0.5), linetype = 'dashed', color = 'grey30') +
  geom_hline(aes(yintercept = 2), linetype = 'dashed', color = 'grey30') +
sdl_smooth_groups_NFNamoi +
  labs(y = 'Condition relative\nto baseline') +
  plot_layout(ncol = 1, guides = "collect")+ 
  plot_annotation( tag_levels = 'a')

```

Scenarios will often be defined along more than one axis. In this demonstration, we define a flow multiplication axis as a proxy for 'climate' shifts, and a flow addition axis as a proxy for 'adaptations'. Similarly, values often respond to several different aspects of the flow regime, for example the mean flow and the flow variance or the return interval of floods or low-flow periods. Heatmaps or contour surfaces provide a powerful tool for visualising these interacting responses (@fig-contour, SI @suppfig-heatmap). By examining multiple driver axes, such plots can highlight important interactions and identify where thresholds occur and where change along one axis (e.g. management actions) can mitigate change along the other (e.g. climate shifts). This ability to identify the axes that provide resilience or sensitivity to changes in others will be critically important for management uses of HydroBOT targeting climate change adaptation or efficient use of limited water. These assessments must also take spatial and value differences into account; the different ecological values and SDL units show very different patterns in how they respond to the interaction between the 'climate' and 'adaptation' scenarios ([@fig-contour]).

Perhaps most usefully, if scenarios are carefully developed to explore the range of potential change in the system, then the heatmap represents the response surface of values over this range. Developing the response surface can be iterative, with subsequent scenarios developed to increase resolution near areas of rapid change in outcome. This approach differs from the usual approach of assessing only a small set of scenarios targeting specific proposed actions or environmental conditions [@marchau2019; @helgeson2020]. Instead, by covering the range to generate a response surface, it can provide hypotheses about how proposed scenarios might perform and assess how sensitive the outcomes are to uncertainty in single scenarios. Specific proposed scenarios could, of course, also be assessed and mapped onto the surface. For example, we might think of the flow multipliers here as defining the entire range of plausible climate changes, and the adaptation scenarios as the entire potential range of adaptations. Then, specific proposed adaptations or climate sequences could be mapped onto these heatmaps at particular points. The reverse is also possible; identification of areas of high sensitivity in the heatmaps could be used to choose a set of potential management actions designed to increase climate resilience. This idea extends to additional dimensions, which can then be collapsed in various ways (e.g. via principal component analysis, or by identifying dominant hydrometrics) to visualise with 2d heatmaps even when the response surface itself is best defined and studied in more dimensions.

```{r}
#| label: build-heatmaps
# Use the Target here to get to the big groups

# qualitative axes
qual_heatmap <- agged_data$Target |>
  dplyr::filter(adapt_code %in% c(1,2,3, 4) &
                  scenario != 'MAX') |> # max isn't really relevant here
  dplyr::filter(!is.na(Target)) |> 
  # clean names
  mutate(scenario = paste0(climate_code, adapt_code), 
         SWSDLName = stringr::str_replace(SWSDLName, '–', '-\n'),
         Target = stringr::str_replace(Target, 'Priority e', 'E'),
         Target = stringr::str_wrap(Target, width = 12),
         adapt_code = as.character(adapt_code)) |>
  plot_outcomes(outcome_col = 'ewr_achieved',
                outcome_lab = 'Condition',
                y_col = 'adapt_code', 
                y_lab = 'Adaptation option',
                x_col = 'climate_code', 
                x_lab = 'Climate scenario',
                plot_type = 'heatmap',
                colorset = 'ewr_achieved',
                pal_list = 'grDevices::Viridis',
                facet_row = 'Target',
                facet_col = 'SWSDLName')

# Quantitative axes- it's more informative, but uglier
quant_heatmap <- agged_data$Target |>
  dplyr::filter(adapt_code %in% c(1,2,3) &
                  scenario != 'MAX') |> # max isn't really relevant here
  dplyr::filter(!is.na(Target)) |> 
  # clean names
  mutate(scenario = paste0(climate_code, adapt_code), 
         SWSDLName = stringr::str_replace(SWSDLName, '–', '-\n'),
         Target = stringr::str_replace(Target, 'Priority e', 'E'),
         Target = stringr::str_wrap(Target, width = 12),
         adapt_code = as.character(adapt_code)) |>
  mutate(flow_addition = flow_addition + 1) |> 
  plot_outcomes(outcome_col = 'ewr_achieved',
                outcome_lab = 'Condition',
                y_col = 'flow_addition', 
                y_lab = "Flow addition ('adaptation')",
                x_col = 'flow_multiplier', 
                x_lab = "Flow multiplier ('climate')",
                plot_type = 'heatmap',
                transy = 'log10',
                transx = 'log10',
                colorset = 'ewr_achieved',
                pal_list = 'grDevices::Viridis',
                facet_row = 'Target',
                facet_col = 'SWSDLName',
                setLimits = c(0,1))

# interpolated raster- just one argument different
  # THe spacing is too uneven though
quant_interp_heatmap <- agged_data$Target |>
  dplyr::filter(adapt_code %in% c(1,2,3) &
                  scenario != 'MAX') |> # max isn't really relevant here
  dplyr::filter(!is.na(Target)) |> 
  # clean names
  mutate(scenario = paste0(climate_code, adapt_code), 
         SWSDLName = stringr::str_replace(SWSDLName, '–', '-\n'),
         Target = stringr::str_replace(Target, 'Priority e', 'E'),
         Target = stringr::str_wrap(Target, width = 12),
         adapt_code = as.character(adapt_code)) |>
  mutate(flow_addition = flow_addition + 1) |> 
  plot_outcomes(outcome_col = 'ewr_achieved',
                outcome_lab = 'Condition',
                y_col = 'flow_addition', 
                y_lab = "Flow addition ('adaptation')",
                x_col = 'flow_multiplier', 
                x_lab = "Flow multiplier ('climate')",
                plot_type = 'heatmap',
                transy = 'log10',
                transx = 'log10',
                colorset = 'ewr_achieved',
                pal_list = 'grDevices::Viridis',
                facet_row = 'Target',
                facet_col = 'SWSDLName',
                setLimits = c(0,1),
                contour_arglist = list(interpolate = TRUE))

# This would be better if we had a more even and tighter set of scenarios
  contour_heatmap <- agged_data$Target |>
  dplyr::filter(adapt_code %in% c(1,2,3) &
                  scenario != 'MAX') |> # max isn't really relevant here
  dplyr::filter(!is.na(Target)) |> 
  dplyr::mutate(Target = ifelse(Target == "Waterbird", "Waterbirds", Target))|>
  # clean names
  mutate(scenario = paste0(climate_code, adapt_code), 
         SWSDLName = stringr::str_replace(SWSDLName, '–', '-\n'),
         Target = stringr::str_replace(Target, 'Priority e', 'E'),
         Target = stringr::str_wrap(Target, width = 12),
         adapt_code = as.character(adapt_code)) |>
  mutate(flow_addition = flow_addition + 1) |> 
  plot_outcomes(outcome_col = 'ewr_achieved',
                outcome_lab = "Proportion\nEWR achieved",
                y_col = 'flow_addition', 
                y_lab = "Flow addition ('adaptation')",
                x_col = 'flow_multiplier', 
                x_lab = "Flow multiplier ('climate')",
                plot_type = 'heatmap',
                transy = 'log10',
                transx = 'log10',
                colorset = 'ewr_achieved',
                pal_list = achieve_pal, #'grDevices::Viridis', #keeping consistent with pallet you used above
                facet_row = 'Target',
                facet_col = 'SWSDLName',
                setLimits = c(0,1),
                contour_arglist = list()
  )

```

```{r}
#| label: fig-contour
#| fig-cap: Condition results visualised as a surface with the two scenario definitions on the axes. This approach allows visualising changes in outcome as the result of multiple axes on which scenarios might differ. These axes might be different aspects of scenario creation (as here), or they might be different axes describing the outcome of scenarios (e.g. two different hydrometrics such as mean flow and flow variance)

contour_heatmap
```

Causal networks define the causal relationship between values at different scales. Plotting the condition of each value directly on the network shows not only the relationships among values, but how condition changes across values at different scales. This sort of visualisation shows the holistic consequences of the different scenarios across the complex and interrelated sets of values, as well as identifies nodes that are unusually resilient or sensitive to change ([@fig-causal-results]). For example, NF1 is less sensitive to reductions in flow (lighter) than EF3 (darker). Moreover, the network connections act to smooth out impacts, with a wide range of impacts from flow reductions, including increases in the EWRs themselves (leftmost nodes), combining to yield more-similar declines among the ecological groupings relative to the baseline flows. Analysis of network structure, combined with aggregated values at each node, could identify critical nodes with outsized importance for outcomes at other nodes in the network. Any such nodes should be investigated to determine whether they capture key aspects of the system or are instead an artifact of model structure (possibly resulting from the way the network was developed) that may bias results. If their sensitivity does in fact capture the system, these nodes may be ideal targets for management intervention. The edges also identify the dependence between values, where we can see that different environmental outcomes depend on not only different hydrologic indicators (EWRs), but also different numbers of those indicators.

```{r}
#| eval: false

# RERUN TO REMAKE CAUSAL NETWORK

# NETWORK 1) demonstrates steps in aggregation, some relative results, for one gauge

# # just get the theme-scale values
# # First we need the sequence lists
# 
aggparams <- yaml::read_yaml(file.path(agg_results_gauge,
                                      'agg_metadata.yml'))

themeseq <- aggparams$aggregation_sequence[
  !names(aggparams$aggregation_sequence) %in%
    c('planning_unit', 'sdl_units', 'mdb')
]

themefuns <- aggparams$aggregation_funsequence[
  !names(aggparams$aggregation_sequence) %in%
    c('planning_unit', 'sdl_units', 'mdb')
]

causal_ewr <- causal_ewr

# skip the _timing
ewr_edges <- make_edges(dflist = causal_ewr,
                        fromtos = themeseq[2:length(themeseq)],
                        gaugefilter = gauges_to_plot[2])

# get the nodes
nodes <- make_nodes(ewr_edges)

aggvals <- extract_vals_causal(agged_data,
                               whichaggs = themefuns,
                               valcol = 'ewr_achieved',
                               targetlevels = names(themeseq[2:length(themeseq)]))

# filter to a single gauge. Multiple gauges should have separate networks or otherwise split the gauge-specific nodes. And include the larger scales pertaining to that gauge.

# This takes a while (5 mins or so). Cutting to just the polygons and name-matchign gauges only saves about 30 seconds and introduces potential errors, so leaving it as-is.
system.time(gaugematch <-  st_intersects(bom_basin_gauges[bom_basin_gauges$gauge ==
                                                gauges_to_plot[2],],
                             aggvals, sparse = FALSE))

aggvals <- aggvals[as.vector(gaugematch),] |>
  st_drop_geometry()

# join to the nodes
nodes_with_vals <- nodes |>
  dplyr::filter(NodeType != 'target_5_year_2024') |>
  dplyr::left_join(aggvals) |>
  dplyr::filter(!is.na(scenario)) |>
  # Scenario metadata fell off, return it
  dplyr::left_join(scenarios, by = 'scenario') |>
  # clean up names
    dplyr::mutate(scenario = ifelse(scenario == 'MAX', 'MAX',
                           paste0(climate_code, adapt_code)),
         adapt_code = as.character(adapt_code))

# a subset of nodes so plots are readable
set.seed(17)
sampleenvobj <- nodes_with_vals |>
  filter(NodeType == 'env_obj') |>
  reframe(names = unique(Name)) |>
  pull() |>
  sample(10)

# pre-filter to make plotting simpler
basenodes <- nodes_with_vals |>
  dplyr::filter(flow_multiplier %in% c(0.5, 1, 2) & flow_addition == 0) |>
  baseline_compare(compare_col = 'scenario', base_lev = 'E1',
                   values_col = 'ewr_achieved',
                   group_cols = c('Name', 'NodeType', 'nodeorder'),
                   comp_fun = 'relative',
                   add_eps = 0.01) |>
  mutate(logrel_ewr_achieved = log(relative_ewr_achieved))
```

```{r}
#| eval: false

# RERUN TO REMAKE CAUSAL NETWORK

# #| label: make-networks
# #| include: false
# #| warning: false
# # use a subset again
aggNetworkdown_sub_rel <- basenodes |>
  dplyr::filter(flow_multiplier == 0.5 & flow_addition == 0) |>
  make_causal_plot(edges = ewr_edges,
                   focalnodes = sampleenvobj,
                 edge_pal = 'black',
                 node_pal = list(value = compare_pal),
                 node_colorset = 'logrel_ewr_achieved',
                 render = TRUE,
                 setLimits = c(min(basenodes$logrel_ewr_achieved),
                               0,
                               max(basenodes$logrel_ewr_achieved)),
                 save = TRUE,
                 savedir = file.path(demo_webdir,'images'),
                 savename = 'aggNetworkdown_sub_rel')

# GET LEGEND: THIS NEEDS TO BE INTEGRATED IN FUNCTION
lims <- c(min(basenodes$logrel_ewr_achieved),
                               0,
                               max(basenodes$logrel_ewr_achieved))

limtib <- tibble(x = seq(from = lims[1], to = lims[2], length.out = 10), y = 1) |>
  bind_rows(tibble(x = seq(from = lims[2], to = lims[3], length.out = 10), y = 1)) |>
  # make sure we have pretty options
  bind_rows(tibble(x = labeling::extended(lims[1], lims[3], 5), y = 1)) |>
  distinct()

limtib <- tibble(x = labeling::extended(lims[1], lims[3], 5), y = 1)

allcols <- limtib |>
  grouped_colors(pal_list = list(achieve_pal), colorset = 'x')

# Can I just make the legend and then steal it? using pretty breaks

pal_gg <- ggplot(allcols, aes(x = x, y = y, fill = color)) +
  geom_tile() +
  scale_fill_identity(guide = 'legend', breaks = allcols$color, labels = as.character(allcols$x))

# I guess I could also do a line and steal that, but if we've monkeyed with a dividing point, that won't work

limtc <- tibble(condition = seq(from = lims[1], to = lims[3], by = 0.1), y = 1)

pal_ggc <- ggplot(limtc, aes(x = condition, y = y, color = condition)) + geom_point() +
  paletteer::scale_color_paletteer_c(compare_pal)

net_legend <- ggpubr::get_legend(pal_ggc) |>
  ggpubr::as_ggplot()

ggsave(plot = net_legend, file.path(demo_webdir,'images', 'aggNetworkup_sub_legend.png'), width = 2, height = 4, units = 'cm')

ggsave(plot = net_legend, file.path(demo_webdir,'images', 'aggNetworkup_sub_legend.pdf'), width = 2, height = 4, units = 'cm')


```

![a) HydroBOT incorporates causal networks that describe the ecological connections between ecological values in a system. In the current example, these causal networks are extracted from the Murray-Darling Basin Long Term Watering Plans (LTWPs), which sets environmental watering requirements (EWRs), ecological objectives, and long-term targets for key water-dependent plants, waterbirds, fish and ecosystem functions. From left to right, the columns here represent EWR codes, proximate ecological values such as NF5 - Improve population structure for moderate to long-lived riverine specialist native fish species, and the larger ecological value groupings. The network shown here is for a single gauge (`r gauges_to_plot[1]`), which is the scale at which EWR codes and the small-scale values (middle column) are defined. The ecological theme value definitions (Native fish, etc) are not tied to gauges, but only those that apply to the EWRs present at this gauge are shown here. Colours represent change in condition of each value in the halving climate scenario (A), expressed as the log of condition relative to the baseline 'climate' scenario. Large reductions in condition are dark purple, large improvements are dark green, and no change is white.](images/causal_results.png){#fig-causal-results}

```{r}
#| eval: false
#| label: fig-causal-results-old
#| fig-cap: !expr glue::glue("a) HydroBOT incorporates causal networks that describe the ecological connections between ecological values in a system. In the current example these causal networks are extracted from the Murray-Darling Basin Long Term Watering Plans (LTWPs), which sets environmental watering requirements (EWRs), ecological objectives, and long-term targets for key water-dependent plants, waterbirds, fish and ecosystem functions. From left to right, the columns here represent EWR codes, proximate ecological values such as NF5- Improve population structure for moderate to longlived riverine specialist native fish species, and the ecological theme groupings. The network shown here is for a single gauge ({gauges_to_plot[1]}), which is the scale at which EWR codes and the small-scale values (middle column) are defined. The ecological theme value definitions (Native fish, etc) are not tied to gauges, but only those that apply to the EWRs present at this gauge are shown here. Colors represent change in condition of each value in the halving (panel a, scenario A) scenario, expressed as the log of condition relative to the baseline 'climate' scenario. Large reductions in condition are dark purple, large improvements are dark green, and no change is white.")

# aggNetworkdown_sub_rel_grob <- png::readPNG(file.path(demo_webdir, 'images/aggNetworkdown_sub_rel.png')) |>
#   grid::rasterGrob(interpolate = TRUE)
# # aggNetworkup_sub_rel_grob <- png::readPNG(file.path(demo_webdir, 'images/aggNetworkup_sub_rel.png')) |>
# #   grid::rasterGrob(interpolate = TRUE)
# net_legend <- png::readPNG(file.path(demo_webdir, 'images/aggNetworkup_sub_legend.png')) |>
#   grid::rasterGrob(interpolate = TRUE)
# 
# patchwork::wrap_plots(aggNetworkdown_sub_rel_grob) + inset_element(net_legend, 0.90, 0.60, 1, 1)
                      
```

# Implications

HydroBOT provides consistent, scientifically robust, and repeatable capacity to model responses to flow, producing management-relevant outcomes at multiple dimensions. This capacity provides a step change for management agencies such as the Murray-Darling Basin Authority to move beyond assessment of hydrologic outcomes and towards assessing the values that depend on that hydrology. Requirements such as those for a "healthy working basin" [@murray-darlingbasinauthority2011] that demand attention across socio-economic, cultural, and environmental values are commonly included in management plans for large basins [e.g. @deltastewardshipcouncil2013; @usdepartmentoftheinteriorbureauofreclamation2012; @ziolkowska2016; @connor2015], and reflect the interconnections of a range of values provided by these systems. Key to assessing this range of values is modelling their dependence on hydrology and other management levers, and aggregating the outcomes to management-relevant scales.

Large-scale natural resource management requires the capacity to make decisions relating to multiple spatial, temporal, and value dimensions, and is most successful when multiple scales within those dimensions are considered [@moore2021]. The HydroBOT aggregation and scaling framework navigates those dimensions for water-dependent social, economic, environmental, and cultural values, even when the underlying response models are highly detailed. Combining such disparate information in a standard and comparable manner can illuminate synergies and trade-offs, which could be critical for decision making. Moreover, the scaling provided by HydroBOT condenses and synthesizes large numbers of complex outcomes to results tailored for interpretation for management questions. Our demonstration concerns the ecological values of the Murray-Darling Basin; however, the framework is equally applicable to social, economic, and cultural values and to other locations. HydroBOT itself has a modular design to incorporate disparate response models and spatial units.

Water management faces an increasing need and expectation for scientifically-sound and interpretable modelling from a range of stakeholders [@ryder2010; @gawne2018]. These issues are magnified when facing major long-range decision making to understand the impacts of climate change and potential policy or operational adaptations management agencies might undertake [@neave2015; @tonkin2019]. Co-design of HydroBOT with a diverse team within the Murray-Darling Basin Authority yielded distinct benefits to achieving these goals, with developers and researchers better understanding and building in the needs of the management agency, while the relevant managers better understand the limitations, uses, and potential of the tool. The focus on communication both within management agencies and to external partners, including model provenance, production of tailored synthesis figures, and causal networks, is a key outcome to build trust and understanding in HydroBOT as a tool and the results it produces. HydroBOT provides new capacity to assess a wide range of target values across scenarios and exciting opportunity for continued advances and improvement with the development of new response models and climate scenarios.

# CRediT authorship contribution statement

Galen Holt\\\*: Writing -- original draft, Visualization, Validation, Software, Methodology, Investigation, Formal analysis, Data curation, Conceptualization. Georgia Dwyer\\\*: Writing -- original draft, Visualization, Methodology, Investigation, Formal analysis, Conceptualization. David Robertson: Writing -- review & editing, Supervision, Conceptualization, Funding acquisition. Martin Job: Writing -- review & editing, Supervision, Conceptualization. Rebecca E Lester Writing -- review & editing, Supervision, Investigation, Conceptualization, Funding acquisition.

\\\*Holt and Dwyer co-first authors.

# Declaration of competing interest

The authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper.

# Acknowledgements

This research was supported through funding from the Australian Government Murray–Darling Water and Environment Research Program (MD WERP).

We thank Murray-Darling Basin Authority collaborators including Lara Palmer, Elisha Freedman, Tumi Bjornsson, Matt Coleman, and Joel Bailey for their assistance and support.

# Data availability

All data and their sources have been explained in the manuscript. HydroBOT code is available at github.com/MDBAuth/HydroBOT, and code to create this manuscript is available at github.com/galenholt/toolkit-demo-paper.

# References

::: {#refs}
:::

# Supplementary material {#sec-appendix1}

## Glossary {#sec-glossary}

::: {#supptbl-glossary}
```{r}
#| message: false

gloss_tab <- readr::read_csv(file.path(demo_webdir, "definitions.csv"), show_col_types = FALSE)|>
  dplyr::filter(!is.na(Definition))

# Both huxtable and knitr are bad for word export. Probably will just have to save CSVs for submission

# if (knitr::is_html_output()) {
  knitr::kable(gloss_tab)
# } else {
#   huxtable::huxtable(gloss_tab) |> theme_article()
# }

```

Glossary adapted from the Murray-Darling Basin Long Term Watering Plans (LTWPs) [@nswdpiemacq2020].
:::

## Component details {#sec-component-details}

The HydroBOT architecture comprises three major components, the Controller, Aggregator and Comparer, that receive data and information from several input sources, including input scenarios, hydrological modelling, spatial data, causal networks and response models ([@suppfig-architecture, @supptbl-components]). Here we detail some specific details about each of these components and other input sources.

![Architecture of HydroBOT. Hydrographs representing are inputs, typically reflecting modeled scenarios or historic flows. The flow of data during a modeling run follows the bold arrows, with the additional components of the Causal network and Spatial units providing necessary grouping information for the Aggregator. Dashed lines indicate that hydrographs and direct Response model output can utilise the Comparer functionality directly. Causal networks are linked closely to each Response model and, while both are defined externally to HydroBOT, they require significant work to integrate into a compatible, modular HydroBOT component. Spatial units are typically more general, typically polygons of management interest, and require only light changes to make compatible. Each set of boxes represents a distinct component of HydroBOT, allowing changes to be made at any step in a modular way without impacting the functioning of other stages.](../images/architecture.png){#suppfig-architecture}

::: {#supptbl-components}
```{r}

comp_tab <- readr::read_csv(here::here('presentation_paper/component_table.csv'), show_col_types = FALSE)

# Both huxtable and knitr are bad for word export. Probably will just have to save CSVs for submission

comp_tab |> 
  # Too much text in the last col
  dplyr::select(-last_col()) |> 
# if (knitr::is_html_output()) {
  knitr::kable()
#   huxtable::huxtable(comp_tab) |> theme_article()
# }
# 
```

Components of HydroBOT architecture
:::

### Aggregation

Aggregation functions determine outcomes and reflect processes or values. Aggregating a set of outcomes yields a different outcome depending on the function used. Thus, function choice should be considered carefully and reflect the processes involved or management goals. HydroBOT provides default functions for the mean, compensating (e.g. max), limiting (min), and spatially-weighted versions of the same. It also provides the ability for the user to define any desired function, allowing for more complex situations.

### Included data

HydroBOT provides some datasets relevant for consistent spatial and value scaling in the Murray-Darling Basin. Spatial data includes sf objects for the Murray-Darling Basin, all gauges in the EWR tool, Sustainable Diversion Limit (SDL) units, Resource Plan Areas, Planning Units in New South Wales, and catchments defined by the Commonwealth Environmental Water Holder. These have all been prepared from relevant shapefiles from each agency. In addition, a riverlines sf object is provided for visualisation of the river network itself.

A causal network for the EWR Tool is provided as well, extracted from various sources including the EWR tool itself, New South Wales water managers, and Long-Term Watering Plans. This network includes levels for sub-ewr codes, ewr codes, environmental objective code, target groups, species or other specific goals, management objectives, and 5, 10, and 20 year management targets (see glossary @sec-glossary). Different levels are defined at different spatial scales; for example, the mapping from ewr code to particular fish species typically should happen within a planning unit or SDL unit, as that ewr code might map to a different species in another location.

#### Spatial aggregation

Maps allow large-scale visualization of ecological objectives under various scenarios. These visualisations can be quite important for communications and quickly grasping how outcomes aggregate spatially and spatial patterns in the data (SI @sec-map-versions). Management targets are often defined spatially, and in the case of EWRs, they are defined in local Planning Units (which are constituents of the SDL units defined above), where outcomes may depend on hydrographs at one or more gauges. Representing the outcomes as maps can provide intuitive assessment of the condition of values across space and whether different spatial scales or spatial locations are responding differently to scenarios. Moreover, the ecology (in this example) or other processes might themselves be large-scale, and so capturing the condition over a large area is a better descriptor of the true outcome than assessing each specific location separately. For example, objective EF3 is "Provide movement and dispersal opportunities for water dependent biota to complete lifecycles and disperse into new habitats within catchments", and so necessarily incorporates a spatial dimension. Particularly in these situations, the aggregation method should be considered carefully -- for movement opportunities to succeed, perhaps the success of the SDL unit should be determined by the lowest value at a gauge if it represents a loss of connectivity. In contrast, for WB4: Increase opportunities for colonial waterbird breeding, it might be sufficient if a single site within the SDL unit provides those opportunities.

```{r}
#| label: build-map-figs
#| include: false
#| 
# a single sdl map for comparison
nf_maps_single <- obj_sdl_to_plot |>
    dplyr::filter(env_obj == 'NF1' & scenario == 'climatebaseadapt0') |>
  mutate(scenario = ifelse(scenario == 'MAX', 'MAX', 
                           paste0(climate_code, adapt_code)), 
         SWSDLName = stringr::str_replace(SWSDLName, '–', '-\n')) |> 
  plot_outcomes(outcome_col = 'ewr_achieved',
                outcome_lab = 'Proportion\nEWR achieved',
                plot_type = 'map',
                colorset = 'ewr_achieved',
                pal_list = achieve_pal,
                underlay_list = list(underlay = basin,
                                     pal_list = 'azure'),
                setLimits = c(0,1))  +
  theme(axis.ticks = element_blank(), 
                         axis.text=element_blank())

# a smaller subset of sdls and scenarios
# a single sdl map for comparison
obj_maps_few <- obj_sdl_to_plot |>
    dplyr::filter(env_obj %in% c('NF1', 'EF3', 'WB4') & 
                    scenario %in% c('climatedown2adapt250', 
                                    'climatebaseadapt0', 
                                    'climateup2adapt6500')) |>
  mutate(scenario = ifelse(scenario == 'MAX', 'MAX', 
                           paste0(climate_code, adapt_code)), 
         SWSDLName = stringr::str_replace(SWSDLName, '–', '-\n')) |> 
  plot_outcomes(outcome_col = 'ewr_achieved',
                outcome_lab = 'Proportion\nEWR achieved',
                plot_type = 'map',
                colorset = 'ewr_achieved',
                pal_list = achieve_pal,
                facet_row = 'scenario',
                                facet_col = 'env_obj',

                #underlay_list = list(underlay = basin,
                #                     pal_list = 'azure'),
                setLimits = c(0,1))  +
  theme(axis.ticks = element_blank(), 
                         axis.text=element_blank())

```

#### EWRs

::: {#supptbl-ewrs}
```{r}
# 
# 
ewr_tab <- ewrs_in_pyewr |>
  filter(gauge %in% gauges_to_plot) |>
  # Why these? Same as Georgia had
  dplyr::select(Catchment = LTWPShortName, gauge, Code, StartMonth, EndMonth, TargetFrequency, TargetFrequencyMax, TargetFrequencyMin, EventsPerYear, Duration, MinSpell, FlowThresholdMin, FlowThresholdMax, `MaxInter-event`)

# Both huxtable and knitr are bad for word export. Probably will just have to save CSVs for submission
# if (knitr::is_html_output()) {
  knitr::kable(ewr_tab)
# } else {
#   huxtable::huxtable(ewr_tab) |> theme_article()
# }
```

Environmental water requirements (EWR) for two example gauges (`r gauges_to_plot[1]` and `r gauges_to_plot[2]`).
:::

#### Causal network

Causal networks are available linking the EWRs to other values. Here, we show a limited set for a single gauge, illustrating some of the value levels that can be linked. This network is derived from the New South Wales Long Term Watering plans [@nswdpiemacq2020].

![HydroBOT incorporates causal networks that describe the environmental objectives for a system. In the current example these causal networks are extracted from the Murray-Darling Basin Long Term Watering Plans (LTWPs), which sets environmental watering requirements (EWRs), objectives, and long-term targets for key water-dependent plants, waterbirds, fish and ecosystem functions. From left to right, the columns here represent EWR codes, proximate environmental Objectives typically capturing portions of the life cycle or changes in abundance, species goals (which also include ecosystem components such as 'Refugia'), target ecological groupings, and 5-year management targets. The network shown here is for a single gauge (`r gauges_to_plot[1]`) and Planning Unit, which is the scale at which EWR codes and proximate Environmental Objectives are defined. The other levels are defined at larger spatial scales, but only those that apply to the EWRs present at this gauge are shown here.](images/all_causal.png){#suppfig-causal-example}

```{r}
#| eval: false
#| label: suppfig-causal-example-old
#| fig-cap: !expr glue::glue("HydroBOT incorporates causal networks that describe the environmental objectives for a system. In the current example these causal networks are extracted from the Murray-Darling Basin Long Term Watering Plans (LTWPs), which sets environmental watering requirements (EWRs), objectives, and long-term targets for key water-dependent plants, waterbirds, fish and ecosystem functions. From left to right, the columns here represent EWR codes, proximate environmental Objectives typically capturing portions of the life cycle or changes in abundance, species goals (which also include ecosystem components such as 'Refugia'), target ecological groupings, and 5-year management targets. The network shown here is for a single gauge ({gauges_to_plot[1]}) and Planning Unit, which is the scale at which EWR codes and proximate Environmental Objectives are defined. The other levels are defined at larger spatial scales, but only those that apply to the EWRs present at this gauge are shown here.")   

# edges <- make_edges(dflist = causal_ewr, 
#                fromtos = list(c('ewr_code', 'env_obj'), 
#                               c('env_obj', 'Specific_goal'), 
#                               c('Specific_goal', 'Target'), 
#                               c('env_obj', 'target_5_year_2024')),
#                gaugefilter = gauges_to_plot[1]) 
# 
# nodes <- make_nodes(edges)
# 
# 
# # To work with both html and word, save out and read back in.
# causal_example <- make_causal_plot(nodes,
#                  edges,
#                  focalnodes = filter(nodes, NodeType == "ewr_code")$Name,
#                  edge_pal = 'black',
#                  node_pal = net_pal,
#                  render = FALSE,
#                  save = TRUE,
#                  savedir = 'images',
#                  savename = 'causal_structure') 
# 
# # if (knitr::is_html_output()) {
#   # causal_example |> 
#   # DiagrammeR::render_graph()
# # } else {
# #   knitr::include_graphics("images/causal_structure.png")
# # }
# 
# causal_structure <- png::readPNG('images/causal_structure.png')
# causal_structure_grob <- grid::rasterGrob(causal_structure, interpolate = TRUE)
# patchwork::wrap_plots(causal_structure_grob)

```

## Scenarios {#sec-scenarios}

::: {#supptbl-scenarios}
```{r}

#| layout-ncol: 2
#| tbl-subcap: 
#|  - "Climate"
#|  - "Adaptation"


adapt_scenes <- scenarios |> 
  filter(scenario != 'MAX') |> 
  mutate(flow_addition = as.integer(flow_addition)) |> 
  select(`Adaptation code` = adapt_code,
         `Flow addition (ML/d)` = flow_addition) |>
  distinct()
climate_scenes <- scenarios |> 
  filter(scenario != 'MAX') |> 
  select(`Climate code` = climate_code,
         `Flow multiplier` = flow_multiplier) |>
  distinct()

# Huxtables look better, but won't go side-by-side. and despite saying they work better in word, they're much worse. Ugh. Why are tables so hard?

# huxtable::huxtable(climate_scenes) |> theme_article()
# huxtable::huxtable(adapt_scenes) |> theme_article()

knitr::kable(climate_scenes |> 
               mutate(`Flow multiplier` = signif(`Flow multiplier`, 2))) 
knitr::kable(adapt_scenes)

```

Demonstration scenarios are a factorial combination of 'climate' (scaled flow) and 'adaptation' (pulsed additions). Climate scenarios included in this demonstration were produced by applying a flow multiplier to historical flows. Adaptation options were applied to each climate scenario with additional flows added throughout the period of September to December. For ease of display in some figures, we provide alpha codes for the 'climate' changes and numeric codes for the 'adaptations'. Mostly frequently, we present the ‘A’ (0.5 x historical flow), ‘E’ (1.0 x historical flow and ‘I’ (2.0 x historical flow) scenarios, with adaptions 1 (no flow addition), 2 (addition of 250 ML/d) and 3 (addition of 6500 ML/d) in most plots, with scenario 4 only appearing in heatmaps and smoothed fits.
:::

::: {#suppfig-hydrographs}
```{r}
#| message: false

hydro_plot <- scenehydros |>
    dplyr::filter(scenario %in% scenarios_to_plot & gauge %in% gauges_to_plot) |>
  dplyr::mutate(flow = flow/1000) |> 
  plot_outcomes(outcome_col = 'flow',
                outcome_lab = 'Flow (GL/day)',
                x_col = 'Date',
                colorset = 'gauge',
                color_lab = 'Gauge ID:',
                pal_list = gauge_pal,
                facet_row = 'climate_code',
                facet_col = 'adapt_code',
                ) +
    ggplot2::scale_y_continuous(sec.axis = sec_axis(~ . ,
                                                    name = "Climate scenario",
                                                    breaks = NULL, labels = NULL)) +
    ggplot2::scale_x_date(sec.axis = sec_axis(~ . , 
                                              name = "Adaptation option", 
                                              breaks = NULL, labels = NULL)) +
    theme_werp_toolkit(legend.position = "bottom")

hydro_plot
```

Hydrographs for two example gauges (represented by colour) with 'climate' scenarios on rows and 'adaptation' scenarios as columns. Scenario codes as in @supptbl-scenarios.
:::

## Baselined hydrographs {#sec-baselining}

::: {#suppfig-baseline-hydro-clim}
```{r}

# Relative is how we should look at this for climate scenarios, but when the addition in the adaptation options happens when the baseline is at 0 or close to it, it goes to inf. So make two plots, I think.

# The relative one is supremely uninteresting, but maybe we need it to make a point?
base_hydro_clim <- scenehydros |>
    dplyr::filter(scenario %in% scenarios_to_plot & 
                    gauge %in% gauges_to_plot & 
                    flow_addition == 0) |>
    plot_outcomes(outcome_col = 'flow',
                  outcome_lab = 'Relative flow',
                  x_col = 'Date',
                  colorset = 'gauge',
                  color_lab = 'Gauge ID:',
                  pal_list = gauge_pal,
                  base_list = list(base_lev = "climatebaseadapt0",
                     values_col = 'flow',
                     comp_fun = "relative",
                     group_cols = c('Date', 'gauge')),
                  facet_col = 'climate_code')

 base_hydro_clim <- base_hydro_clim +
   ggplot2::scale_x_date(sec.axis = sec_axis(~ . ,
                                              name = "Climate scenarios",
                                              breaks = NULL, labels = NULL)) +
    theme_werp_toolkit(legend.position = "bottom")+
      guides(colour=guide_legend(nrow=2,byrow=TRUE))+
   ylab("Relative flow to baseline")

base_hydro_clim
```

Change in flow relative to the baseline scenario. These are flat lines because the relativisation occurs at each timepoint.The baseline scenario is represented by the observed historical data with no climate change or adaptation options applied (scenario E1)
:::

::: {#suppfig-baseline-hydro-adapt}
```{r}

# Look at difference just at the the base multiplier
base_hydro_adapt <- scenehydros |>
    dplyr::filter(scenario %in% scenarios_to_plot & 
                    gauge %in% gauges_to_plot & 
                    flow_multiplier == 1) |>
      plot_outcomes(outcome_col = 'flow',
                  outcome_lab = 'Difference flow',
                  x_col = 'Date',
                  colorset = 'gauge',
                  color_lab = 'Gauge ID:',
                  pal_list = gauge_pal,
                  base_list = list(base_lev = "climatebaseadapt0",
                     values_col = 'flow',
                     comp_fun = "difference",
                     group_cols = c('Date', 'gauge')),
                  facet_col = 'adapt_code') +
    ggplot2::scale_x_date(sec.axis = sec_axis(~ . ,
                                              name = "Adaptation options",
                                              breaks = NULL, labels = NULL)) +
    theme_werp_toolkit(legend.position = "bottom")+
      guides(colour=guide_legend(nrow=2,byrow=TRUE))+
   ylab("Flow difference from baseline")

base_hydro_adapt
```

Change in flow volume compared to the baseline scenario. This comparison is done using the difference, and so represents the flow additions. The baseline scenario is represented by the observed historical data with no climate change or adaptation options applied (scenario E1)
:::

## Additional comparison plots

### Map aggregation {#sec-map-versions}

Here, we show results at the gauge, SDL and basin scales, and also to show how the outcomes aggregate along the thematic dimension. To start @suppfig-gauge-to-sdl-map-all-0 illustrates a subset of EWRs that contribute to priority ecosystem function at the gauge scale. Our aggregations sequence then proceeds to aggregate these EWR to the environmental objectives at each gauge. Here, @suppfig-gauge-to-sdl-map-all-1 shows the outcomes for gauges for all ecological objectives contributing the priority ecosystem function (left panels) in addition to a gauge level aggregation to the Ecological value scale of the thematic dimension. @suppfig-gauge-to-sdl-map-all-2 then shows these outcomes at the SDL scale; and @suppfig-gauge-to-sdl-map-all-3 shows these outcomes at the basin scale.

::: {#suppfig-gauge-to-sdl-map-all-0}
```{r}

#| message: false

agged_EWRs_gauges <- agged_data$ewr_code |>
  left_join(causal_ewr$ewr2obj, relationship = 'many-to-many')|>
  dplyr::mutate(env_group = stringr::str_extract(env_obj, '^[A-Z]+')) |>
  dplyr::filter(env_group == 'EF' & !(env_obj %in% c('EF3a', 'EF3b'))) |>
  dplyr::filter(ewr_code %in% c('BF1' ,'CF' ,'LF1' ,'OB-WL' ,'SF1' ,'BK1' ,'VF' ,'AC1', 'OB1'))|>
  distinct(ewr_code, gauge, scenario, .keep_all = TRUE)

ef_EWR_gauges <- agged_EWRs_gauges |>
       dplyr::filter(scenario %in% scenarios_to_plot) |>
  # clean names
    mutate(scenario = paste0(climate_code, adapt_code)) |> 
  plot_outcomes(outcome_col = 'ewr_achieved',
                outcome_lab = 'Proportion\nEWR achieved',
                plot_type = 'map',
                colorset = 'ewr_achieved',
                pal_list = achieve_pal,
                facet_row = 'scenario',
                facet_col = 'ewr_code',
                underlay_list = list(list(underlay = sdl_units |> 
                                            filter(SWSDLName %in%
                                                     unique(obj_sdl_to_plot$SWSDLName)),
                                         pal_list = 'gray')),
                setLimits = c(0,1)) 

ef_EWR_gauges <- ef_EWR_gauges + 
  scale_y_continuous(sec.axis = sec_axis(~ . ,
                                         name = "Climate & Adaptation Option Scenario", 
                                         breaks = NULL, labels = NULL)) +
    scale_x_continuous(sec.axis = sec_axis(~ . , 
                                           name = "EWR",
                                           breaks = NULL, labels = NULL)) +
  theme(axis.ticks = element_blank(), 
                         axis.text=element_blank())

suppressMessages(print(ef_EWR_gauges)) #+ 
  #+ plot_layout(guides = "collect", heights = c(1,1), widths = c(10,2), nrow = 1)
```

Outcomes for gauges for a subset of EWRs that contribute to priority ecosystem function.
:::

::: {#suppfig-gauge-to-sdl-map-all-1}
```{r}
#| message: false

agged_gauges <- agged_data$ewr_code |> 
  theme_aggregate(from_theme = 'ewr_code', to_theme = 'env_obj',
                  groupers = c('scenario', 'gauge', 'climate_code', 'adapt_code'),
                  aggCols = 'ewr_achieved',
                  funlist = ArithmeticMean,
                  causal_edges = causal_ewr,
                  auto_ewr_PU = FALSE) |> 
  agg_names_to_cols(aggsequence = 'env_obj', 
                    funsequence = 'ArithmeticMean', 
                    aggCols = 'ewr_achieved')

agged_gauges <- agged_gauges |>
  dplyr::mutate(env_group = stringr::str_extract(env_obj, '^[A-Z]+')) |>
  dplyr::filter(env_group == 'EF' & !(env_obj %in% c('EF3a', 'EF3b')))

 ef_gauges <- agged_gauges |>
       dplyr::filter(scenario %in% scenarios_to_plot) |>
  # clean names
    mutate(scenario = paste0(climate_code, adapt_code)) |> 
  plot_outcomes(outcome_col = 'ewr_achieved',
                outcome_lab = 'Proportion\nEWR achieved',
                plot_type = 'map',
                colorset = 'ewr_achieved',
                pal_list = achieve_pal,
                facet_row = 'scenario',
                facet_col = 'env_obj',
                underlay_list = list(list(underlay = sdl_units |> 
                                            filter(SWSDLName %in%
                                                     unique(obj_sdl_to_plot$SWSDLName)),
                                         pal_list = 'gray')),
                setLimits = c(0,1)) 

ef_gauges <- ef_gauges + 
  scale_y_continuous(sec.axis = sec_axis(~ . ,
                                         name = "Climate & Adaptation Option Scenario", 
                                         breaks = NULL, labels = NULL)) +
    scale_x_continuous(sec.axis = sec_axis(~ . , 
                                           name = "Environmental objective",
                                           breaks = NULL, labels = NULL)) +
  theme(axis.ticks = element_blank(), 
                         axis.text=element_blank())

 ef_gauges_target <- agged_gauges |>
  dplyr::group_by(scenario,env_group, climate_code, adapt_code, gauge, geometry)|>
  dplyr::summarise(ewr_achieved = mean(ewr_achieved)) |>
  dplyr::filter(scenario %in% scenarios_to_plot) |>
  dplyr::filter(env_group == 'EF') |> 
  # clean names
    mutate(scenario = paste0(climate_code, adapt_code)) |> 
  plot_outcomes(outcome_col = 'ewr_achieved',
                outcome_lab = 'Proportion\nEWR achieved',
                plot_type = 'map',
                colorset = 'ewr_achieved',
                pal_list = achieve_pal,
                facet_row = 'scenario',
                facet_col = 'env_group',
                underlay_list = list(list(underlay = sdl_units |> 
                                            filter(SWSDLName %in%
                                                     unique(obj_sdl_to_plot$SWSDLName)),
                                         pal_list = 'gray')),
                setLimits = c(0,1)) 

ef_gauges_target <- ef_gauges_target + 
  scale_y_continuous(sec.axis = sec_axis(~ . ,
                                         name = "Climate & Adaptation Option Scenario", 
                                         breaks = NULL, labels = NULL)) +
    scale_x_continuous(sec.axis = sec_axis(~ . , 
                                           name = "Ecological value",
                                           breaks = NULL, labels = NULL)) +
  theme(axis.ticks = element_blank(), 
                         axis.text=element_blank())

ef_gauges + ef_gauges_target + plot_layout(guides = "collect", heights = c(1,1), widths = c(10,2), nrow = 1)
```

Outcomes for gauges for all ecological objectives contributing the priority ecosystem function.
:::

::: {#suppfig-gauge-to-sdl-map-all-2}
```{r}
#| message: false

ef_maps <- obj_sdl_to_plot |>
    dplyr::filter(scenario %in% scenarios_to_plot) |>
  # Need to reduce dimensionality
    dplyr::filter(env_group == 'EF' & !(env_obj %in% c('EF3a', 'EF3b'))) |> 
  # clean names
  mutate(scenario = paste0(climate_code, adapt_code), 
         SWSDLName = stringr::str_replace(SWSDLName, '–', '-\n')) |> 
  plot_outcomes(outcome_col = 'ewr_achieved',
                outcome_lab = 'Proportion\nEWR achieved',
                plot_type = 'map',
                colorset = 'ewr_achieved',
                pal_list = achieve_pal,
                facet_row = 'scenario',
                facet_col = 'env_obj',
                # underlay_list = list(underlay = basin,
                #                      pal_list = 'azure'),
                setLimits = c(0,1)) 

ef_maps <- ef_maps + 
  scale_y_continuous(sec.axis = sec_axis(~ . ,
                                         name = "Climate & Adaptation Option Scenario", 
                                         breaks = NULL, labels = NULL)) +
    scale_x_continuous(sec.axis = sec_axis(~ . , 
                                           name = "Environmental objective",
                                           breaks = NULL, labels = NULL)) +
  theme(axis.ticks = element_blank(), 
                         axis.text=element_blank())

ef_maps_target <- obj_sdl_to_plot |>
  dplyr::group_by(scenario,env_group, climate_code, adapt_code, SWSDLName, geometry)|>
  dplyr::summarise(ewr_achieved = mean(ewr_achieved)) |>
  dplyr::filter(scenario %in% scenarios_to_plot) |>
  dplyr::filter(env_group == 'EF') |> 
  # clean names
    mutate(scenario = paste0(climate_code, adapt_code)) |> 
  plot_outcomes(outcome_col = 'ewr_achieved',
                outcome_lab = 'Proportion\nEWR achieved',
                plot_type = 'map',
                colorset = 'ewr_achieved',
                pal_list = achieve_pal,
                facet_row = 'scenario',
                facet_col = 'env_group',
                underlay_list = list(list(underlay = sdl_units |> 
                                            filter(SWSDLName %in%
                                                     unique(obj_sdl_to_plot$SWSDLName)),
                                         pal_list = 'gray')),
                setLimits = c(0,1)) 

ef_maps_target <- ef_maps_target + 
  scale_y_continuous(sec.axis = sec_axis(~ . ,
                                         name = "Climate & Adaptation Option Scenario", 
                                         breaks = NULL, labels = NULL)) +
    scale_x_continuous(sec.axis = sec_axis(~ . , 
                                           name = "Ecological value",
                                           breaks = NULL, labels = NULL)) +
  theme(axis.ticks = element_blank(), 
                         axis.text=element_blank())

ef_maps + ef_maps_target + plot_layout(guides = "collect", heights = c(1,1), widths = c(10,2), nrow = 1)

```

Outcomes for SDL units for all ecological objectives contributing the priority ecosystem function. Environmental water requirements (EWRs) are defined by hydrographs at gauges and apply to Planning Units. The outcomes at these scales of definition can then be aggregated to larger spatial areas, such as SDL units, which we do here with an area-weighted mean.
:::

::: {#suppfig-gauge-to-sdl-map-all-3}
```{r}
#| message: false

 ef_basin_data <- obj_sdl_to_plot |>
   dplyr::group_by(scenario, env_obj, climate_code, adapt_code)|>
   dplyr::reframe(ewr_achieved = mean(ewr_achieved)) |>
   dplyr::filter(scenario %in% scenarios_to_plot) |>
   dplyr::mutate(OBJECTID = as.double(1))|>
   dplyr::right_join(basin, by = join_by(OBJECTID))|>
   st_sf()|>
   dplyr::mutate(env_group = stringr::str_extract(env_obj, '^[A-Z]+')) |>
   dplyr::filter(env_group == 'EF' & !(env_obj %in% c('EF3a', 'EF3b'))) 
 
ef_basin <- ef_basin_data |> 
  # clean names
  mutate(scenario = paste0(climate_code, adapt_code)) |> 
  plot_outcomes(outcome_col = 'ewr_achieved',
                outcome_lab = 'Proportion\nEWR achieved',
                plot_type = 'map',
                colorset = 'ewr_achieved',
                pal_list = achieve_pal,
                facet_row = 'scenario',
                facet_col = 'env_obj',
                setLimits = c(0,1)) 

ef_basin <- ef_basin + 
  scale_y_continuous(sec.axis = sec_axis(~ . ,
                                         name = "Climate & Adaptation Option Scenario", 
                                         breaks = NULL, labels = NULL)) +
    scale_x_continuous(sec.axis = sec_axis(~ . , 
                                           name = "Environmental objective",
                                           breaks = NULL, labels = NULL)) +
  theme(axis.ticks = element_blank(), 
                         axis.text=element_blank())

ef_basin_target <- ef_basin_data |>
  dplyr::group_by(scenario, env_group, climate_code, adapt_code, geometry)|>
  dplyr::summarise(ewr_achieved = mean(ewr_achieved)) |>
  dplyr::filter(scenario %in% scenarios_to_plot) |>
  dplyr::filter(env_group == 'EF') |> 
  # clean names
    mutate(scenario = paste0(climate_code, adapt_code)) |> 
  plot_outcomes(outcome_col = 'ewr_achieved',
                outcome_lab = 'Proportion\nEWR achieved',
                plot_type = 'map',
                colorset = 'ewr_achieved',
                pal_list = achieve_pal,
                facet_row = 'scenario',
                facet_col = 'env_group',
                setLimits = c(0,1)) 

ef_basin_target <- ef_basin_target + 
  scale_y_continuous(sec.axis = sec_axis(~ . ,
                                         name = "Climate & Adaptation Option Scenario", 
                                         breaks = NULL, labels = NULL)) +
    scale_x_continuous(sec.axis = sec_axis(~ . , 
                                           name = "Ecological value",
                                           breaks = NULL, labels = NULL)) +
  theme(axis.ticks = element_blank(), 
                         axis.text=element_blank())

ef_basin + ef_basin_target + plot_layout(guides = "collect", heights = c(1,1), widths = c(10,2), nrow = 1)
```

Outcomes for the basin for all ecological objectives contributing the priority ecosystem function.
:::

Here, we show the full set of SDL units and ecological values that are shown in part in @fig-smooth-climate-adapt panel b.

::: {#suppfig-smooth-all}
```{r}
#| message: false
#| warning: false

# sdl_smooth_groups / sdl_smooth_clim +
#   plot_layout(guides = 'collect', heights = c(3,1))
# Lots of loess warnings, we don't really care here.
suppressMessages(suppressWarnings(print(sdl_smooth_groups))) 
# + coord_cartesian(ylim = c(0.5, 2)) # + geom_abline(slope = 1, intercept = 1)
```

Smoothed fits to assess change in performance across the 'climate' scenarios. Points are individual ecological objectives, fitted lines are loess smooths. Separate fits are done for each adaptation option, and so differences between lines of different colours represent the impact of those adaptations. Rows are ecological values groupings, columns are SDL units. Note the different scales of the y-axis.
:::

### Heatmaps

::: {#suppfig-heatmap}
```{r}

qual_heatmap
```

Condition results visualised as a heatmap with the two scenario definitions on the axes. This approach allows visualising changes in outcome as the result of multiple axes on which scenarios might differ. These axes might be different aspects of scenario creation (as here), or they might be different axes describing the outcome of scenarios (e.g. two different hydrometrics such as mean flow and flow variance).
:::
