---
title: "An integrated toolkit for assessment of hydrology-dependent outcomes in the Murray-Darling Basin: CLEVERACRONYM"
author: 
 - name: Galen Holt
   orcid: 0000-0002-7455-9275
   corresponding: true
   email: galen@deakin.edu.au
   affiliation:
    - ref: du
 - name: Georgia Dwyer
   orcid: 
   corresponding: false
   affiliations:
     - ref: du
 - name: David Robertson
   orcid: 
   corresponding: false
   affiliations:
     - CSIRO
 - name: Martin Job
   orcid: 
   corresponding: false
   affiliations:
     - MDBA
 - name: Lara Palmer
   orcid: 
   corresponding: false
   affiliations:
     - MDBA
 - name: Rebecca E Lester
   orcid: 
   corresponding: false
   affiliations:
     - ref: du

affiliations:
  - id: du
    name: Deakin University
    city: Waurn Ponds
    state: Victoria
        
keywords: 
 - Murray-Darling Basin
 - Holistic modeling
 - Management modeling
 - Climate change
 - Climate adaptation
 
date: last-modified

bibliography: references.bib

number-sections: true

echo: false
---

*Author list not set- anyone else? Anyone to drop? Strong feelings about order?*

*There are too many figures, though I can at least panel a few more than I currently do*.

*Target journal: [Environmental Modelling and Software](https://www-sciencedirect-com.ezproxy-b.deakin.edu.au/journal/environmental-modelling-and-software)*

*How about 'flowre' for CLEVERACRONYM? HydroVista (Hydrological Assessment and Valuation Toolkit for Integrated Sustainability and Adaptation); HD BOT (Hydrology-dependent Basin Outcomes Toolkit); BOA (Basin Outcomes Assessor)*

```{r}
#| eval: false

# This should not be run, except to make a simple quarto
make_simpleyml <- function(renderfile = 'auto') {
  
  if (renderfile == 'auto') {
    projpath <- rstudioapi::getActiveProject()
    docpath <- rstudioapi::documentPath()
    projdir <- sub(".*/([^/]+)$", "\\1", projpath)
    reldocpath <- sub(paste0(".*", projdir, "/"), "", docpath)
    renderfile <- reldocpath
  }
    
  
  simple_yaml <- list()
  simple_yaml$project <- list()
  simple_yaml$project$render <- list(renderfile)
  yaml::write_yaml(simple_yaml, '_quarto-singlefile.yml')
}

make_simpleyml(rstudioapi::documentPath())
```

```{r}
#| label: packages
#| include: false
library(werptoolkitr) 

library(dplyr)
library(sf)
library(huxtable)
library(ggplot2)
library(patchwork)
```

```{r}
#| label: directories
#| include: false

# This depends on the same scenarios as the demo website, so give it the path to that. This will likely be user-specific. Everything else is relative.

demo_webdir <- file.path('../WERP_toolkit_demo')

# Why is the execute-dir not working?
# Outer directory 
project_dir = file.path(demo_webdir, 'more_scenarios')  # '..', 

# Hydrographs
hydro_dir = file.path(project_dir, 'hydrographs')  

# EWR outputs
ewr_results <- file.path(project_dir, 'module_output', 'EWR')  

# outputs of aggregator
agg_results <- file.path(project_dir, 'aggregator_output', 'sdl_target') 

# outputs of aggregator
agg_results_pooled_ewrs <- file.path(project_dir, 'aggregator_output', 'pooled_ewr') 

```

```{r}
#| label: data-subsets
#| include: false

gauges_to_plot <- c('412002', '419001')#, '422028', '421001')

scenarios_to_plot <- c("climatedown2adapt0", 
                       "climatedown2adapt250",
                      "climatedown2adapt6500",
                      "climatebaseadapt0",
                      "climatebaseadapt250", 
                      "climatebaseadapt6500",
                      "climateup2adapt0",
                      "climateup2adapt250",
                      "climateup2adapt6500")
```

```{r}
#| label: scenario-info
#| include: false
print(file.path(hydro_dir,'scenario_metadata.yml'))

scenarios <- yaml::read_yaml(file.path(hydro_dir,                                     
                                       'scenario_metadata.yml'))


```

```{r}
#| label: scenario-info2
#| include: false
scenarios <- scenarios |>  
  tibble::as_tibble() |> 
  dplyr::rename('scenario' = "scenario_name")

# Add Georgia's scenario codes
scenarios <- scenarios |> 
  arrange(flow_addition, flow_multiplier) |> 
  group_by(flow_addition) |>
  mutate(climate_code = LETTERS[1:n()]) |>
  ungroup() |> 
  group_by(flow_multiplier) |> 
  mutate(adapt_code = 1:n()) |> 
  ungroup()

# set a sceneorder
sceneorder <- forcats::fct_reorder(scenarios$scenario,
                                   (scenarios$flow_multiplier +
                                      scenarios$flow_addition/100000))

# But we usually use the codes, so we need to order them too.
rename_sceneorder <- scenarios  |> 
  mutate(scenario = ifelse(scenario == 'MAX', 'MAX', 
                           paste0(climate_code, adapt_code))) |> 
  pull(scenario) |> 
  forcats::fct_reorder((scenarios$flow_multiplier +
                          scenarios$flow_addition/100000))
```

```{r}
#| label: data-import
#| include: false

# Now that the data is in, deal with the extra junk associated with unique scenario names, hence the str_remove_all

#Hydrographs- just read in the ones we use
scenehydros <- read_hydro(hydro_dir, 
                          scenariofilter = stringr::str_c(scenarios_to_plot, '_', scenarios_to_plot), 
                          long = TRUE, format = 'csv') |> 
  mutate(scenario = stringr::str_remove_all(scenario, '.*0_')) |> 
  left_join(scenarios, by = 'scenario')

#Agg data (1.2 GB)
agged_data <- readRDS(file.path(agg_results, 'achievement_aggregated.rds')) |>
  purrr::map(\(x) mutate(x, 
                         scenario = stringr::str_remove_all(scenario, '.*0_'))) |> 
  purrr::map(\(x) left_join(x, scenarios, by = 'scenario'))

#Agg data (1.2 GB)
agged_data_pooled_ewrs <- readRDS(file.path(agg_results_pooled_ewrs, 'achievement_aggregated.rds')) |>
  purrr::map(\(x) mutate(x, 
                         scenario = stringr::str_remove_all(scenario, '.*0_'))) |>
  purrr::map(\(x) left_join(x, scenarios, by = 'scenario'))

```

```{r}
#| label: flow-differences


# To get a single dimension for the scenarios, we can use the overall difference in flow volumes. It's crude, but likely the only thing that works when we have an addition over part of the year and a multiplicative change. Those are fundamentally different, so we'll do our best

dif_flow <- baseline_compare(scenehydros, compare_col = 'scenario',                                             base_lev = "climatebaseadapt0",
                             values_col = 'flow',                               
                             comp_fun = c("difference"),
                             group_cols = c('Date', 'gauge')) |> 
  group_by(scenario) |> 
  summarise(scenario_difference = mean(difference_flow)*0.001)

scenarios <- left_join(scenarios, dif_flow, by = 'scenario')

```

```{r}
#| label: palettes
#| include: false

# I'm adding these from Georgia as needed
# Trying to organise by the sort of palette we need for each

# Qualitative
SDL_pal <- make_pal(unique(agged_data$sdl_units$SWSDLName), 
                    palette = "impressionist.colors::la_recolte_des_foins_eragny")

gauge_pal <- make_pal(unique(gauges_to_plot),                       
                      palette = 'ggsci::nrc_npg')

adapt_pal <- make_pal(as.character(unique(scenarios$adapt_code)),
                      palette = 'nationalparkcolors::Redwoods')

# descriptive networks
net_pal <- list(NodeType = 'nationalparkcolors::MtRainier')

# these have to use quantitative even though they're not, or we run out of colors.
env_pals = list(EB = 'grDevices::Grays',
  EF = 'grDevices::Purp',
                NF = 'grDevices::Mint',
                NV = 'grDevices::Burg',
                OS = 'grDevices::Blues 2',
                WB = 'grDevices::Peach')

# use the first level of each of those to make a named pal. I wish there were an easier way
envgroup_pal <- purrr::imap_chr(env_pals,
                                \(x,y) make_pal(levels = y, palette = x)) |> 
  werptoolkitr:::as_colors()

# Quantitative- sequential achievement
achieve_pal <- 'grDevices::Blue-Yellow'

# quantitative- diverging achievement (e.g. relative to baseline)
compare_pal <- 'scico::bam'

# We don't end up using scene_pal, I don't think. 
# But I also think we should
# Since there are two dimensions, maybe use faded colors? Should be able to bring that function over.
# But do that later
scene_pal <- make_pal(unique(scenehydros$scenario),                       
                      palette = "viridis::mako", #'ggsci::nrc_npg', 
                      refvals = 'base', refcols = 'black')
```

# Abstract

NEED TO DO - GEORGIA

# Introduction

*I know MDBA is moving away from quad-bottom-line, so this first para will be reframed to just say there are a lot of values being managed for, rather than necessarily put them in those buckets.*

Water management in large river systems typically targets a wide range of desired values. For example, in the Murray-Darling Basin, Australia, the objective of water management is to maintain a healthy working river that supports productive and resilient water-dependent industries, healthy and resilient ecosystems, and communities with access to sufficient and reliable water supplies [@murray-darlingbasinauthority2011]. These values are not unique to Australia; water is managed to protect the social, economic, environmental and cultural values of communities worldwide [e.g. @stern2019; @kaye-blake2014] *neither of these are actually papers, and we need something from Europe/Asia; GEORGIA check Rebeccas Basiwide paper*. That these values are the targets of water management implies that each value depends on water in some way but, in many cases, these dependencies are not well-defined and management proceeds under the relatively simple assumption that, if water is provided, these targets will improve.

Water managers typically have a limited range of levers at their disposal which primarily affect hydrology, e.g. flow releases from dams or inundation of wetlands. When non-hydrologic levers are available, such as water trading rules in the Murray-Darling Basin, their impact is still often assessed on how they alter hydrologic conditions-- their impact on the spatio-temporal patterns of flow in the system. Further, hydrologic modelling is often better-integrated with management workflows than models of other values. In part, this is due to the availability of large-scale physical models that provide robust ability to model flows as they arise from natural drivers such as rainfall and capture infrastructure such as dams and diversions. While complex, these models have relatively high precision and relatively few outcomes compared to models of ecological or economic responses, for example. The impact of particular management actions (e.g. dam releases) on hydrology is well-understood and captured by the hydrograph, allowing accurate targeting of particular aspects of the flow regime by management actions. While these proximate models of system state and impact of management actions are invaluable, they do not provide the necessary information to assess the status of the range of flow-dependent values and targets.

Assessing values as they respond to flow and management actions requires models of these relationships. Such models exist, though their quality and extent vary widely, ranging from unstated mental models to highly-detailed population dynamics or economic models [@lester2019]. When these models are quantitative or computational, they are written in various languages by subject-matter experts, often focus on one or a limited suite of target values and return disparate outputs depending on their particular goals and approaches. These models are often designed to study the value(s) (e.g. fish populations) that they model, not to produce the most useful analysis for management questions or to capture the breadth of target values. Moreover, these models cannot individually provide information about larger-scale values; single-species models are insufficient to assess the condition of all fish or the whole ecosystem, for example. Integrating these models into a holistic modelling approach is necessary to assess management-relevant outcomes of disparate, typically broad-scale, values under different hydrologic conditions and management actions. Integrating diverse response models gives each response model utility beyond its original purpose and identifies where new work is needed (e.g. where response models are limited or non-existent). The creation of an integrated toolkit provides the opportunity for robust decision-making [@harrison2023] and the ability to prioritize water planning across a range of values and identify conditions that achieve disproportionately large (or small) impacts, as well as the explicit consideration of synergies and trade-offs among different values or value types.*These first few paras probably need more general cites in them GEORGIA*

Exemplifying these issues, the Murray-Darling Basin Authority (MDBA) is the federal body charged with water management in the Murray-Darling Basin (MDB), Australia. The Murray-Darling Basin is centrally important to the economic, cultural, social and environmental wellbeing of Australia. Within the MDB, 70% of water is ustilised for agricultural purposes. The MDB contributes nearly 2% to gross domestic product from agriculture and tourism, is home to 2.2 million people, including 40 Aboriginal nations, and contains approximately 400,000 water-dependent ecosystems [@hart2021]. While balancing this range of values is difficult in any highly-utilised basin, the Murray-Darling is unusually dry and variable compared to other systems of similar importance [@hart2021]. Modern management of the MDB arises from the Commonwealth *Water Act 2007*, which established the Murray-Darling Basin Authority with obligations to develop and implement a Basin Plan governing water resource management [@hart2021] *I'm citing Hart a lot because it's a big overview, but are there better cites? Something internal?*.

The MDBA has statutory obligations to manage water to maintain a healthy working river that supports productive and resilient water-dependent industries, healthy and resilient ecosystems, and communities with access to sufficient and reliable water supplies *You have these words up front in the first para, so probably just paraphrase here. GEORGIA* ([@murray-darlingbasinauthority2011]). Moreover, the state of the Basin is required to be assessed annually, with a major review of and updates to the Basin Plan made at legislated intervals [e.g. 15 years between development and first review, @hart2021]. Beyond these requirements, the MDBA has an increasing focus on assessing system response to climate change and possible adaptation actions that may be taken by the MDBA itself or other stakeholders in the Basin ( *MDBA ref? GEORGIA*). In addition to the MDBA, Basin states and other stakeholders (e.g. the Commonwealth Environmental Water Holder) have additional responsibilities for water management in the MDB [@hart2021] *Is there a better cite for who has control over what?*. Taken together, these management goals require a holistic modeling approach that integrates across values and is adaptable to these various management needs while also simplifying repeated, ongoing use. *This is all MDBA-focused. The toolkit is just as usable by the states, should we discuss them as well?* *RL: I don’t think so. I would focus on similar basins elsewhere that have similar complex and competing needs that might also benefit from such an approach.*

The MDBA has access to robust hydrologic models describing flows in the system and responses to current management practices, and these models are under continual use, development, and improvement ( *What's the best cite? David, Martin?*). Despite the need for ongoing assessment and forward planning across a range of values, models of the responses to those hydrologic conditions are patchy, only represent some values, and have been developed and used in a more ad-hoc approach rather than integrated with each other or the hydrologic models. In this paper, we describe an integrated modelling 'toolkit' to address these water management needs in the Murray-Darling Basin, Australia, hereafter referred to as *CLEVERACRONYM*.

The toolkit described here greatly improves the capacity of the relevant manager (here, the MDBA) to assess outcomes across a range of values, provides the structure to adapt and include additional values as additional component models become available, and addresses a number of issues with current assessment practices and modelling approaches. By providing a single, consistent interface to a range of response models, we avoid the need to manually run models separately and we abstract their different interfaces, languages, and idiosyncrasies. Moreover, the toolkit design is highly modular, built to allow the integration of new response models with limited additional updates to the toolkit itself. Continuing with this consistency, the toolkit provides a standard set of synthesis approaches and functions that target management-relevant analysis and interpretation of outcomes from these disparate models with a common approach and design language. Because the need for assessing outcomes is nearly universal in water management, and not limited to a particular scenario or project, the toolkit is designed with strong scenario-comparison capabilities but is agnostic to what those scenarios represent. For a similar reason, the standardised synthesis and outputs are highly flexible, allowing the user to choose the most relevant outputs for different management needs.

One common issue with modelling in general, and particularly integrated models spanning several tools, is that such tools can become a black box where the relationships modelled are opaque. This can yield mistrust by the public and other stakeholders influenced by the model, but also mistrust and misunderstanding by users and developers of the model. To avoid these issues, the toolkit has been continuously co-designed with the relevant management agency, the MDBA, and an emphasis is put on public code, production of outputs that describe the model actions, (e.g. causal relationships), and reproducibility and self-documentation.

To demonstrate the toolkit, we develop a set of example scenarios capturing some qualitative aspects of one intended use: the assessment and comparison of outcomes under different climate scenarios and different adaptations to those changes. These axes represent changes to the system due to processes over which managers have no control (i.e. a changing climate), and management actions which would typically be targeted interventions. We use this demonstration to illustrate the problem space and show how the toolkit can aid in assessing potential system change and prioritising management actions to mitigate impacts.

# Methods

The purpose of the toolkit is to assess how hydrographs representing various climate and adaptation scenarios affect multiple sets of values, which may span many scales and disciplines. We seek to make these assessments in a consistent and repeatable way despite differences in the response models. The toolkit then has the capability to synthesize a wide range of outputs from the response models into results that compare scenarios and are digestible and useful for management decision making (@fig-tktomgmt). A co-design process including scientists, software developers, and managers was developed to ensure the toolkit achieved its goal of producing scientifically robust results that are also management-relevant.

![Conceptualisation of toolkit benefits to management. Scenarios represented by hydrographs are fed in a consistent way to various response models, while the outputs are synthesized into management-relevant outputs that aid decision-making.](../images/tktomgmt.png){#fig-tktomgmt}

*FYI GEORGIA if you edit the conceptual figs: I'm trying to keep current versions of conceptual figs in QAEL - WERP in house - WERP\Toolkit\0_CURRENT_CONCEPTUAL_FIGS.pptx so we have them in one place and don’t have to go dig through a million old ppts from various presentations. Then, to get them into quarto, save the slide as a png, and put it in the  /images directory.*

*RL: Picky comment, but can we move the orange arrow between water policy and planning and adaption options so it doesn’t cross over the rest of the diagram?*
*RL: Also, it might be worth using the caption to point to the various parts of the ms that outline each of the major components in the diagram. For example, by the time people get here, they’ll have no idea about the causal networks and that might make the conceptual model less useful. Perhaps we can spell them out and cross reference the various sections in the ms*
*RL: Finally, it might be worth trying to combine with the next fig to reduce the number of figs.*
*GH: I debated that, curious if Georgia can think of a good way to do it. I wanted to drop one of them entirely, but they're different enough I couldn't quite manage- this is broad conceptual goals, and that is about architecture. But maybe it could be done- I kind of think it's more likely to figure out a way to just drop one than to try to keep both as a two-panel or something.*


## Co-design and scoping for management relevance

To ensure the toolkit met management needs and is trusted by management users, a toolkit development team was created consisting of primary toolkit developers, hydrologic modelers, and MDBA staff. Frequent collaboration among this team allowed issues to be addressed while still small or emerging and ensure decisions about toolkit construction reflected the needs of the end-user. This approach encouraged an iterative process, where broad goals were established as a group, and implementation discussed. As implementation proceeded, the close collaboration provided a mechanism by which goals could be adjusted or the implications of decisions discussed and understood. By having this window into the toolkit development, the managers obtained a much more granular view of how it operates than they would have otherwise, including its capabilities and limitations. Making the toolkit less of a black box builds trust in its output and greatly aids in knowing how to interpret and use that output.

Key to the collaborative development was identification of the response models to include. These models need to provide information about values relevant to water management decisions as those values respond to hydrology. Early in the development process, a wide scan was taken to identify candidate response models. This scan considered models being used or developed within the MDBA itself, other government agencies (both federal and state), and externally. This scan found that there were a number of responses models available, but many were outdated or highly manual, and their use was patchy both within and across management agencies *GEORGIA We can probably cite our original report where we outline the results of that scan.*. Ultimately, only one was suitably modern and well-developed to include in the toolkit, the Environmental Water Response (EWR) Tool. Other in-development modules were identified as candidates to include during the life of the toolkit, including economic and social models. Further, this scan identified values that are mandated management targets for which there were no available or in-development response models, highlighting areas needing future work.

## Causal networks {#sec-causal_networks}

*RL: I think I want the toolkit overview before the causal networks. As yet, I don’t know why I’m interested in the casual networks.*
*GH: Yeah, I agree. Not quite sure where in the overview- We need both a general 'what is a causal network', and then a description of the specific one we use for EWR. Maybe it's as simple as moving this general stuff after the controller and before the response models, since the specific EWR network is already in the EWR section of the Response models*

Causal networks are models that describe the topology of dependence among many drivers and outcomes of different type (adapted from @peeters2022) *need more causal refs, Peeters didn't invent them*. The use of a causal network framing both at a high level for visualisation and communication with the MDBA and embedded in the toolkit illustrate both the goals and the functioning of the toolkit, avoiding it becoming a black box. *RL: What isn’t clear to me in the few sentences that follow are which parts are inherent in the conceptualisation of a causal model (i.e. stuff we didn’t invent) versus what we have developed ourselves. It might worth making that clearer.* *GH: My thinking was, this was 'what is a causal network and why is it a useful thing' here (and so almost none of this is what we did), while the specific causal networks we built go below. And so if we move this into the architecture section, this could probably be cut way back to really target the conceptualisation of a causal network and why they're useful, with what we did going in the relevant response model sections (currently just EWR), since that's where we actually built them and can discuss that provess and what they look like.* This approach greatly aided the collaborative process and provides an ongoing communication tool. The relevant causal network for water management in the Murray-Darling Basin captures relationships between management, flow, and outcomes for a wide range of values and assets, from ecological response to economic performance and human wellbeing. Thus, they include climatic and management drivers, but also include the causal relationships which form the basis of the response models (e.g. flow timeseries to hydrologic indicators, or potentially to the life history inherent in a population dynamics model). They incorporate any links connecting those outcomes to larger-scale outcomes (e.g. from hydrologic indicators to ecological response). Thus, causal networks define an overarching model from initial inputs (e.g. rainfall or flows or adaptations) through to all values of interest, with each link defining a response model or component of a response model. The specifications of the models underlying each link are highly variable. These models range from detailed physical models linking runoff to flow, to simpler ecological models of environmental water requirements, to simple averages, to leaving the model unspecified where information about the relationships is unavailable. Assessing the quality of knowledge around each link provides a powerful assessment of knowledge deficiencies and uncertainty in responses.

Causal networks themselves, i.e. the structure of the links (relationships) and nodes (state variables) can be derived from many sources, including empirical studies defining the existence of causal relationships and expert opinion. The toolkit provides a causal network for included modules, where available, to describe how their outputs arise from hydrology and how they relate to various levels of management-relevant outcomes. *GH: I think if this is just above the Response models section, this bit could just get cut (next words).* For example, the causal network provided for the EWR tool (@sec-ewr) is developed primarily from expert opinion in the Long Term Watering Plans (LTWPs). It gives the hypothesised causal relationships between the hydrologic indicators assessed by that module to ecological outcomes ranging from particular components of life cycles for individual species up to broad groupings of environmental priorities or 20-year management targets (see @sec-modules for a description of EWRs and the LTWPs they are derived from). Thus, the causal network defines not only the causal relationships among values, but also defines a 'values' dimension of responses to water, from proximate responses to the condition of species groups or even all ecological outcomes.

The causal networks enable: 1) visual representation of the complex inter-relationships between scenario inputs and outcomes across a range of objectives and 2) assessment of outcomes aggregated along the value dimension (see @sec-aggregator). The former aids transparency, elucidating the intentions and causal relationships behind the response models and is a useful device for communication alongside other final outputs. The latter allows outcomes to be quantified for individual (or sets of) values, (e.g. environmental objectives, target groups, long-term targets), or at the overarching levels of environmental, cultural, social, or economic values. This quantification provides a powerful assessment tool and the ability to identify synergies and trade-offs across interrelated values.

## Toolkit overview

The key goals of the toolkit are to provide a flexible platform for comparing outcomes between different possible scenarios. Scenario comparison is essential for use in both evaluating past actions or conditions and planning for the future, whether to better understand potential shifts in the system from external forces (e.g. climate change) or to assess potential management actions.*RL: This feels a bit abrupt. I think another sentence is needed to create the flow into the architecture sub section.*

### Architecture

Taken holistically, the architecture of the toolkit comprises five primary components and the links between them (@fig-architecture). The data flow through the toolkit is represented by the bold arrows. Input data (hydrographs) is ingested by the Controller, which packages and runs Response Models. Results from the Response Models are then processed by the Aggregator, and the analysis and final outputs are prepared by the Comparer. The two components outside this data flow are the Causal networks and Spatial units, which are used within the Aggregator and Comparer to define groupings for aggregation and for visual representation of space and the complex inter-relationships defined in the response models. Each of these components is described in more detail below.

![Architecture of toolkit. Hydrographs representing are inputs, typically reflecting modeled scenarios or historic flows. The flow of data during a modeling run follows the bold arrows, with the additional components of the Causal network and Spatial units providing necessary grouping information for the Aggregator. Dashed lines indicate that hydrographs and direct Response model output can utilise the Comparer functionality directly. Causal networks are linked closely to each Response model, and while both are defined externally to the toolkit they require significant work to integrate into a compatible, modular toolkit component. Spatial units are typically more general, typically polygons of management interest, and require only light changes to make compatible. Each set of boxes represents a distinct component of the toolkit, allowing changes to be made at any step in a modular way without impacting the functioning of other stages.](../images/architecture.png){#fig-architecture}

*RL: It might be worth leaving this one as the boxes and data flow and deleting the output figures for the purpose of the paper. GEORGIA*

The architecture of the toolkit emphasizes modularity. Each of the components can save its outputs, allowing users to run either the whole toolkit or re-run needed components only to update analysis. For example, if a user wished to change how they aggregate the results of the modules, they could re-run the aggregation step and the subsequent comparison step to match. This ability to adjust intermediate steps allows rapid iteration of results to address a given management question, or adaptation of preexisting results to new questions. This modularity also allows rapid, iterative development of the toolkit itself. Any of the components of the toolkit can be updated without affecting others, and so obtaining new results from updated components (e.g. new aggregation capability) simply requires re-running the toolkit from that point forward.

As each stage of the toolkit runs, it produces yaml and json metadata files including the run settings and other attached information relating to the scenarios to enhance repeatability, ensure correctness and increase comprehension. These metadata include all parameters for the run, allowing exactly repeatable analyses to be conducted by using the metadata files as parameter files for subsequent runs. Even if a run is started in the middle, such as to re-run aggregation in a different way, the metadata for that run will capture the metadata for the previous steps, ensuring that outputs at every stage are tagged with full provenance information about the run that created them.

### Implementation

The toolkit is available as an R package, which provides a suite of functions representing the steps in the architecture. These functions are designed to be general, allowing users much flexibility in how they run the toolkit for a particular set of analyses while retaining a consistent structure and outputs. Because translating from hydrologic scenarios to various responses is a general problem in water management, we expect the ways in which the toolkit is used will be highly variable. Thus, by providing a general structure in the toolkit, users can target the particular questions and particular analyses needed for a given question. For example, in some cases we might want to look at the responses of different components of fish life cycles for a small subset of locations in the Basin. In another situation, we might want a big-picture view of how climate might shift long-term goals for the environment as a whole. Although the initial impetus for creating the toolkit was to assess climate scenarios, its use in practice can be far more general. Any hydrograph can be assessed, and any set of scenarios represented by hydrographs can be compared, provided a response model exists.

The toolkit is designed for analysis of management questions in the Murray-Darling Basin, and so along with the functions to perform the analyses, it also provides a standard set of spatial data comprising the MDB itself, gauges within the Basin (at which hydrographs may be available), and various management units (Sustainable Diversion Limit units, Resource Plan Areas, and catchment boundaries for major subcatchments). Some example hydrograph data are also included for testing and demonstration. The toolkit provides a clean causal network for included modules, described in more detail in @sec-causal_networks. Analogous elements can be constructed for other spatial units or responses to extend functionality within or outside the Murray-Darling Basin.

*GEORGIA: Go though and replace 'the basin' with 'the MDB'; and Python is capitalised*

As a result of the scan of available response models, toolkit development proceeded with the EWR tool as a single response model, but with an architecture designed to allow modular integration of additional response models as they become available. The scan accentuated a critical feature of this modularity; the toolkit must be able to incorporate and standardise models written in various languages and with a wide range of input needs and outputs. The toolkit achieves this by wrapping those other tools so as to make their differences as hidden from the user as possible. In the case of Python modules, the toolkit uses the {reticulate} R package [@ushey2023] in combination with small amounts of internal Python code to call python modules directly. The python code internal to the toolkit performs limited cleaning and translation to prevent passing large objects between languages and ensure that any idiosyncrasies in module inputs and outputs are handled consistently. Python dependencies (and python itself) are automatically installed on first use of Controller functions that call Python modules unless they already exist on the user's system. This approach provides essentially invisible python for most users, while providing flexibility for the user to provide their own Python environment if desired. Modules in other languages are not yet available, but the key requirement is that they be available in a format that is scriptable. In that case, the toolkit will provide small setup and cleanup functions as with the Python modules and wrapper functions to call these modules.

The modularity of the toolkit means it can be run stepwise, with the user calling the relevant functions at each step ([@fig-architecture]). The outputs of each step can be saved or returned directly to an interactive session or both. Typically sufficient selected outputs would be saved for reproducibility and speed unless the project is small enough to retain a comprehensive set in memory or re-run quickly in a notebook. There are also wrapper functions provided that allow running the entire toolkit from Controller through Aggregator, which are extremely useful for large runs or remote runs on batching services. One particularly useful wrapper provides the ability to run from a yaml config file providing function arguments. This function allows the use of a default file and 'tweaked' file *GEORGIA RL: Can we think of a better way to represent this. A default file and a scenario definition file or something? Tweaked sounds a bit informal and doesn’t quite capture that this is where you specify the differences between runs, I don’t think.* *GH: I was spending too much time using futures when I wrote that. We do have a default file, and I haven't decided on the name for the other. Modifications? Run specification? I think 'scenario definition' is likely to lead to confusion since it won't have anything to do with the 'scenarios' we're discussing throughout. Analysis definition?*, making it ideal for holding many parameters constant at a default for a particular set of analyses and only changing some on a per-run basis in a smaller file. It also takes command-line or R list arguments, making it a flexible solution to run the toolkit from the command line, in scripting contexts, or Quarto notebooks. The metadata saved at each step in the process is a yaml file with parameters that are a superset of those needed to run the toolkit. Thus, an exactly identical run can be produced by running the toolkit using an output metadata file as an input parameter file. These metadata files also include the git hash, further allowing reproducibility in the face of code changes.

In practice, the toolkit functions are primarily run in one of two ways. Interactive investigation of relatively small sets of hydrographs can be done in notebooks (typically Quarto; @allaire2022) or simple R scripts. Larger investigations typically would be run on remote computers as part of batching systems, whether HPC, Azure, AWS, or other, with the outputs at the end of the aggregation (and potentially each step) returned. The Comparer step would usually not be run as part of this larger batching, but considered interactively for two reasons. First, through the aggregation step, all operations can proceed in parallel over scenarios, and in some cases parallelizing over gauges is possible. The Comparer necessarily looks across scenarios, and so breaks this parallelisation. Conducting comparisons interactively is typically not excessively CPU- or memory-intensive, provided the Aggregator step has been well thought through. If there are enough data to require high processing or memory, it is unlikely to be simplified enough to make interpretable figures. Second, the primary goal of the Comparer is to produce usable, interpretable outputs. Arriving at a set of meaningful outputs is an iterative process that rarely will be known *a priori*, and so working through this step interactively is necessary. If, however, the toolkit is being used for ongoing monitoring of the same analyses (e.g. a 'dashboard'), then the first iteration may be done interactively, with subsequent uses incorporating those settings written into a script to auto-generate the same figures.

## Toolkit components

Here we describe the specific implementation of each component of the toolkit illustrated in @fig-architecture. An overview of this specific implementation is given in [Appendix @tbl-components], with descriptions given here.

### Controller

The 'Controller' component of the toolkit is the interface between the externally generated input data (scenarios), the chosen response model, and other internal components of the toolkit (@fig-architecture). This component initiates the downstream processing steps according to user-defined settings for a particular run. It includes arguments for locating the input data and the response model(s) to use along with any necessary parameters for those models. The Controller can also control later components of the toolkit, allowing the full toolkit to be run at once. These include defining aggregation steps as discussed in @sec-aggregator and analysis of the results with the Comparer ( @sec-comparer ). The Controller determines whether and where outputs are returned at each step. Having control over the full toolkit process enables large batched runs using parameter files to specify the control arguments in `yaml` files. This core functionality of the Controller is delivered via simple functions that apply to the input data for each scenario and can be looped over scenarios in parallel. The controller can be accessed by the user by using Quarto notebooks to work interactively, R scripts, or via the command line, depending on the use case.

### Response models {#sec-modules}

The impacts of climate and adaptation options on social, cultural, environmental, or economic values are estimated based on causal relationships between drivers (e.g. hydrology) and responses (e.g. the state of assets and values). The response models may exist in many different forms, ranging from binary achievement of hydrologic indicators to fully quantitative responses. These tools are expected to be sourced from existing or in-development models developed by subject-matter experts and, as such, will be written in different languages and will target different outcomes. The toolkit then provides a unified interface and ongoing analysis and modelling of their results.

#### EWR (Environmental Water Requirements) {#sec-ewr}

The EWR tool which forms the core of this demonstration is one such response model, written in Python and in use by the MDBA internally as well as the state of New South Wales for water planning. It models the response of environmental values of the Murray-Darling Basin founded on hydrologic indicators paired with causal relationships to environmental values. It holds databases of the environmental water requirements (EWRs; the indicators) and the volume, frequency, timing and duration of flows or inundation required to meet those indicators (@sec-ewr-table). These indicators were developed based on hypothesized relationships to the environmental objectives of the Basin, which protect or enhance environmental assets that are valued based on ecological significance *GEORGIA NEED REF*. The EWR tool itself only provides an assessment of the hydrologic indicators. The EWR tool assesses whether spatially explicit flow timeseries data meets each EWR (hydrologic indicator) at each gauge (illustrated in @fig-ewr-example). The precise definitions for each EWR differ at each gauge, due to the unique hydrology and channel morphology. For example, a small fresh for 10 days is required every year, ideally between October and April to meet indicator EWR = SF1 (small fresh 1), but the flow volume defined as a 'small fresh' differs between gauges. For the toolkit to model environmental outcomes, we connect it to a specific causal network defining these links.

```{r}
#| label: fig-ewr-example
#| fig-cap: !expr glue::glue("EWR are illustrated at two example gauges ({paste0(gauges_to_plot, collapse = ' and ')}) on the historical base level (scenario E1) hydrographs. See @sec-ewr-table for a table. *Need a table of their English definitions, the full EWR table isn't helpful*")

# This relies on the NSW ewr definitions. We could keep passing them around, but better to pull from py-ewr directly (now a handy toolkit function)
ewrs_in_pyewr <- get_ewr_table()

NSWEWR_gauge <- filter(ewrs_in_pyewr, Gauge %in% gauges_to_plot) |>
  tidyr::separate_wider_delim(cols = Code, delim = '_', 
                              names = c("Code", "Timing"),
                              too_few = 'align_start',
                              too_many = 'merge') |>
  rename(gauge = Gauge) |>
  group_by(gauge) %>%
  distinct(Code, .keep_all = TRUE) |>
  mutate(FlowThresholdMin = as.numeric(FlowThresholdMin)) |>
  arrange(FlowThresholdMin) %>%
  mutate(Date = seq(from = max(scenehydros$Date), 
                    to = min(scenehydros$Date), 
                    length.out = n())) %>%
  ungroup()

hydro_plot_EWRs <- scenehydros |>
    dplyr::filter(scenario == 'climatebaseadapt0' & gauge %in% gauges_to_plot) |>
    ggplot2::ggplot(ggplot2::aes(x = Date, y = (flow/1000) + 1)) +
    ggplot2::geom_hline(data = NSWEWR_gauge, 
                        mapping = aes(yintercept = (FlowThresholdMin/1000) + 1),
                        colour = "red")+ #
    ggplot2::geom_line() +
    ggplot2::facet_grid(gauge ~ . , scales = 'free') +
    ggplot2::labs(y = paste0("Flow (GL/day +1)")) +
    theme_werp_toolkit(legend.position = "bottom") +
      guides(colour=guide_legend(nrow=2,byrow=TRUE)) +
    ggplot2::geom_label(data = NSWEWR_gauge, 
                        mapping = aes(x = Date, y = (FlowThresholdMin/1000)+1,
                                      label = Code), size = 3, colour = "black") +
  # tempted to use 'pseudo_log' and not add 1, but the ticks aren't as nice
  ggplot2::scale_y_continuous(trans = 'log10',
                              sec.axis = sec_axis(~ . , name = "Gauge ID", 
                                                  breaks = NULL, labels = NULL))

hydro_plot_EWRs
```

The EWR tool outcomes are binary responses of hydrologic indicators and so, to link these to expected ecological responses, we developed causal networks from the relationships implied in the Long-Term Watering Plans in setting the EWRs *NEED A REF HERE GEORGIA*. These plans describe how the hydrologic indicators are expected to influence both proximate and larger-scale ecological outcomes. We extracted these causal relationships from the Murray-Darling Basin Long Term Watering Plans (LTWPs), which were developed based on the best available information from water managers, ecologists, scientific publications, and analysis of gauged and modelled flows (e.g. @nswdepartmentofplanningandenvironment2020, @lobegeiger2022). This provided a dense network of links across a range of ecological outcomes at various scales, from components of the life cycle of single species to whole-community outcomes at 10- or 20-year target dates. For example, for the small fresh (SF1) indicator described above might contribute to environmental objectives pertaining to native fish (environmental objectives NF1-9; e.g. NF1 = No loss of native fish species), native vegetation (NV1), and ecosystem functions (EF1-5). These environmental objectives are defined as values supporting the completion of all elements of a life cycle of an organism or group of organisms (taxonomic or spatial), with these links defining another level of causal relationships. Outcomes for species or other objectives are then linked in the causal network to five target groups (native fish, native vegetation, waterbirds, other species, and ecosystem functions) and are associated with long-term targets (5, 10, and 20 year) of the LTWP's management strategies. The chain of dependencies from EWRs to environmental objectives to long-term targets are captured in the causal networks as links, with nodes defining the objectives or targets (@fig-causal-example). This structure not only provides a visual definition of the links in the LTWP, it also enables assessment of outcomes in direct equivalence to the LTWP's management strategies.

```{r}
#| label: fig-causal-example
#| fig-cap: !expr glue::glue("The toolkit incorporates causal networks that describe the environmental objectives for a system. In the current example these causal networks are extracted from the Murray-Darling Basin Long Term Watering Plans (LTWPs), which sets environmental watering requirements (EWRs), objectives, and long-term targets for key water-dependent plants, waterbirds, fish and ecosystem functions. From left to right, the columns here represent EWR codes, proximate Environmental Objectives, Specific Goals, Target Groups, and 5-year Management Targets. The network shown here is for a single gauge ({gauges_to_plot[1]}) and Planning Unit, which is the scale at which EWR codes and proximate Environmental Objectives are defined. The other levels are defined at larger spatial scales, but only those that apply to the EWRs present at this gauge are shown here.")   

edges <- make_edges(dflist = causal_ewr, 
               fromtos = list(c('ewr_code', 'env_obj'), 
                              c('env_obj', 'Specific_goal'), 
                              c('Specific_goal', 'Target'), 
                              c('env_obj', 'target_5_year_2024')),
               gaugefilter = gauges_to_plot[1]) 

nodes <- make_nodes(edges)


# To work with both html and word, save out and read back in.
causal_example <- make_causal_plot(nodes,
                 edges,
                 focalnodes = filter(nodes, NodeType == "ewr_code")$Name,
                 edge_pal = 'black',
                 node_pal = net_pal,
                 render = FALSE,
                 save = TRUE,
                 savedir = 'images',
                 savename = 'causal_structure') 

# if (knitr::is_html_output()) {
  # causal_example |> 
  # DiagrammeR::render_graph()
# } else {
#   knitr::include_graphics("images/causal_structure.png")
# }

causal_structure <- png::readPNG('images/causal_structure.png')
causal_structure_grob <- grid::rasterGrob(causal_structure, interpolate = TRUE)
patchwork::wrap_plots(causal_structure_grob)

```

*RL: And can you make this the causal network that you then present in the results/discussion so that you only need one and not two separate figs?* *GH: We can try. I'll just write the reasons I didn't here, and see what we can figure out. Getting a better plotting function might fix both the unreadability and use in two places issues. Certainly the unreadability. ; Mainly, the issue is that causal networks as used here do two things. One is as a model, where they specify the structure of the relationships. The second is as a way to visualise the outputs of that model at each step. Ie, the model itself, and the results of that model. Maybe I'm being too precious about the distinction. ; This was intended to address the first- show what the causal networks for EWRs capture, through both the environmental groups (e.g. Native Fish, second set from right), but also the long term goals (on the right). ; The ones in the results were intended to do the second- show actual results mapped onto the causal networks, which get (even more) unreadable with that long-term goal set.  ; It also would require a bit of manual gluing of different aggregation sequences, since the long-term targets don't come from the environmental groups. That's totally doable, it just seemed overly complex for a paper about 'here's a thing we built'. I don't think we want to put results up here, since this section is about the model structure, but maybe the way to go is send people to an appendix for this one, and just say there's an example in use in the results/discussion?*

#### Module standardization

Each response model will have a distinct set of outputs, reflecting the captured responses and the structure of the model. When run within the toolkit, these outputs are cleaned and processed into standard, expected formats for further toolkit processing, and metadata is saved. This enables the toolkit to provide a consistent, unified home for disparate response models. The outputs can be saved to disk or retained in-memory for interactive use, depending on the user's needs. The outcomes of the response models are then processed by the Aggregator to enable outputs to be viewed at relevant scales (in time, space or value dimensions). *RL: I may just be muddling up all the things that I’ve been reading but I thought we called this something else up above. Happy to go with value (given that it gets us around the confusion regarding themes) but let’s double check we’re using that consistently.* *GH: I'm not set on 'value', just picked it because of the theme issue, and I think it does capture better the idea of managing for multiple values, which might include a range of scales. But could be 'objectives' or 'targets' (both of which conflict with specific names of causal network levels though). Whatever we go with, consistency is the main thing.*

### Aggregator {#sec-aggregator}

Results from the response models are typically very granular in many dimensions because the best response models operate near the scale of the processes being modelled. In many cases, those processes (e.g. fish breeding, crop planting) individually occur at small spatial and temporal scales. Note that this is the scale of the process itself, but that may be replicated over much larger scales. For example, fish may breed across the Basin but each female breeds in only one location at a given time. Moreover, outcomes from response models are typically at small value scales as well, e.g. capturing portions of the life cycle of fish species, rather than an overall outcome for all fish, or representing planting of particular crops, rather than overall agricultural output. The consequence is that there are potentially thousands of different modeled outcomes across time, locations and values.This plethora of outcomes must then be aggregated to extract meaning at larger scales and condense the information for digestibility in management decision making.

Aggregation condenses that information to scales that are useful for interpretation and planning. Depending on the use, the desired scale(s) may range from local, short-term responses of fine-grained outcomes to large spatial scales over longer time periods for high-level outcomes such as environmental condition (@fig-aggregation-dims). Thus, the toolkit must achieve a robust, consistent aggregation approach along three dimensions (time, space, and value), while maintaining the ability to define those aggregation steps flexibly to meet the needs of the specific analysis. For example, the EWR tool assesses EWRs at individual gauges, but outcomes may be desired within SDL units *RL: Have we defined this? GEORGIA not in order It might be worth just calling them management-relevant units above. The definition makes sense here.* or at the basin scale. Likewise, multiple EWRs are required to meet environmental objectives, of which many are required for each Target group or long-term target *will include a glossary* *RL: Good because it isn’t immediately obvious to me how a target maps onto a value.* *GH: The EWR names for the levels are a mess. But my basic conception is that everything in them is a 'value', with each of the levels in the network being a particular scale/type of value. Just like 'location' might be a gauge, a catchment, or the basin, a 'value' might be an EWR, fish breeding, Native Fish or Ecological condition.*. The Aggregator component of the toolkit enables scaling from the hydrology at each gauge to results at any of these scales. The toolkit provides a standard set of spatial units for aggregation but can accept any user-supplied polygons as the spatial aggregation units ([@fig-aggregation-dims]). Aggregation along the value dimension follows the causal network, which is supplied by the toolkit for included tools, though the user can specify other causal relationships if required.

![Aggregation along multiple dimensions. The toolkit provides flexible capability to aggregate along spatial, temporal and value scales. Users can control the sequence of steps along these axes, with the capability to switch between axes at different steps.](../images/aggregation.png){#fig-aggregation-dims}

A flexible approach to aggregation is needed as specific dimensions (time, space and value) and units within those are best combined in different ways, depending on the meaning of the data and the use of the final outputs. The choices made in these aggregation steps are critical to ensure the final values are scientifically justified and capture the intended meaning. The Aggregator defines a sequence of aggregation steps to take with the data, specifying the dimensions along which to aggregate and the aggregation functions to apply at each step. Each step can be along any dimension and multiple functions can be assigned at each step. The sequence of aggregation steps can interleave the dimensions, e.g. aggregate along the value dimension to an intermediate level, then aggregate in space, then value again. For example, following @fig-aggregation-dims, the user might want to aggregate from hydrologic indicator (EWR) to Objective to Specific Goal (species) at each gauge, then aggregate those gauges into a SDL unit to assess performance of each species over a larger area, followed by aggregating to Target (broad group, e.g. Native Fish, Waterbirds, Native Vegetation, Ecosystem Function).

The Aggregator allows the user to choose any aggregation function at each aggregation step, reflecting the need to account for both the processes being aggregated and the outputs needed for management decisionmaking. These aggregation functions should be considered carefully, as they have different meaning both for the processes being modeled and the interpretation of the outcomes ([Illustration of different aggregations and their meaning given in Appendix @fig-aggregation_types]). For example, in some situations the user might want to know the rate at which EWRs pass across some area, or perhaps the average value of an abundance measure. In this case, a mean would be appropriate. In other situations, however, a single failure may be disproportionately important (e.g. 'no loss' requirements), or perhaps a single passing value is sufficient (e.g. bird breeding can occur anywhere in a catchment). These might be captured with a minimum and maximum, respectively. To address this need for flexible aggregation, the toolkit provides a standard set of functions (e.g. mean, max, min, and spatially-weighted mean), but the user can also specify any other aggregation function, including custom-written functions.

The complexity of the potential aggregation sequences and functions highlights the importance of tracking the provenance of the final values to understand their meaning. Thus, the Aggregator saves the sequences and functions applied at each stage to a metadata file that also can serve as the aggregation parameters for repeatable runs. Moreover, the output dataset retains the full sequence and functions alongside each value, ensuring that values are always paired with their provenance and meaning.

### Comparer {#sec-comparer}

The Comparer is designed primarily to make comparisons between scenarios (typically hydrographs reflecting climate or climate adaptation in the examples that follow), allowing assessment and visualization of their differences. This component of the toolkit also provides generalized capacity to produce plots and other outputs such as tables using a consistent approach, even when not directly comparing scenarios. Comparisons are essential to assess the outcomes of various scenarios, e.g. the behaviour of the system under different climate regimes or with different adaptation options. The functions within the Comparer can be divided into two main categories, those for analysis and those for plotting. Although in some instances presenting the absolute outcome values can be useful across scenarios, explicitly calculating comparisons (e.g. the absolute or relative difference between scenarios) provides distinct advantages. Difficulty in accurately simulating a complex system means that comparisons between scenario outcomes can be more useful and accurate because any bias in the baseline assumptions applies to all outcomes and the focus moves from the total level to the change between scenarios *RL: Can use the same ref you cite in MER once you find one. GALEN*. The best method for comparing will vary depending on the quantities being compared and the intended use of the comparison, so several common default options (differences, relative change) have been developed along with the flexibility for the user to define alternatives.

The comparison functions provide the ability to choose a baseline level for comparison, which may be one of the scenarios, but also may be a reference dataset or a scalar value. For example, we might want to compare a set of outcomes for climate scenarios to a 'no change' climate scenario, to historical observations, or to a mean value. Output values are calculated relative to the defined baseline using either default functions for the absolute or relative difference, or any other user-supplied function. These functions can be applied to any dataframe, but a major advantage of the toolkit is including them within the plotting functions. This allows the generation of comparison plots from raw Aggregator outputs without the need for subsequent data calculations by the user and avoids potential errors that arise from repeated or forgotten data transformations in an analysis workflow.

The plotting functions in the Comparer provide capability to present and visualize comparisons using standardized procedures for all outputs within a project. Different purposes require different sets of outputs; for instance, maps are particularly useful for visualizing geographic patterns, tables and graphs typically provide more precise ability to assess impacts on values, and timeseries plots are useful for visualizing climate trajectories. While potential visualizations and comparisons vary widely depending on the intended use, the Comparer standardizes data cleaning and processing for each plot, as well as aesthetics and plotting approaches. This standardization ensures consistency across plot types and through the project, ensuring values plotted are robust and interpretable. Key to this standardization is the internal data cleaning, which allows the raw outputs of the Aggregator and arguments for the comparisons to be provided to the plotting functions. By standardizing data cleaning within the Comparer, we avoid losing information or performing unsupported data manipulations and so ensure the quality and meaning of the outputs.

## Demonstration scenarios

We demonstrate toolkit functionality for environmental values by using the existing EWR (Environmental Water Requirements) tool for the response model (see @sec-modules for a description of the EWR module and its associated causal network). Our input data consists of hypothetical flow timeseries generated from historical hydrographs at 46 gauges. These gauges fall within the Lachlan, Macquarie--Castlereagh, and Namoi Sustainable Diversion Limit (SDL) units (areas defined for management purposes) of the Murray-Darling Basin, Australia ([@fig-gauges]). These SDL units have detailed LTWPs, and so well-specified EWRs and causal networks.

```{r}
#| label: fig-gauges
#| fig-cap: Map of the Murray-Darling basin, in eastern Australia, illustrating gauge locations within three SDL units (Macquarie–Castlereagh, Lachlan, and Namoi). *The river lines are the 'major' rivers in the geofabric, but there are still too many. Is there a better dataset with the 'even-more-major' rivers?* *RL: Maybe try that thing that Simon Linke did that I sent you the link for when I was chatting to Emily re global RLE assessments.* *GH: I think his is built on this, from when I talked to him at AFSS, but it might do a better job filtering. I'll check. We could also just drop the rivers. If it's a sub-panel on another plot, we'll need to if we want it to be readable. GALEN*

relevant_gauges <- filter(bom_basin_gauges,
                          gauge %in% unique(scenehydros$gauge))

gauge_plot <- agged_data$sdl_units |>
  group_by(SWSDLName) |>
  summarise(across(everything(), first)) |>
  ungroup() |>
           plot_outcomes(outcome_col = 'SWSDLName',
              plot_type = 'map',
              colorset = 'SWSDLName',
              pal_list = SDL_pal,
              underlay_list = list(list(underlay = basin,
                                   pal_list = 'azure')),
              overlay_list = list(
                list(overlay = basin_rivers,
                                        pal_list = 'lightblue1'),
                list(overlay = relevant_gauges,
                                   pal_list = 'firebrick')
                                   )) +
  theme_werp_toolkit(axis.ticks = element_blank(), 
                         axis.text=element_blank())

inset_map <- ggplot(ozmaps::ozmap_country) +
  geom_sf(fill = 'grey20') +              
  geom_sf(data = basin, fill = 'azure') +
  theme_werp_toolkit(axis.ticks = element_blank(), 
                         axis.text=element_blank())

# Why on earth does this print a dataframe of the corners?
overview_map <- gauge_plot +
  patchwork::inset_element(inset_map, left = 0.01, bottom = 0.7,
                           right = 0.4, top = 1)

overview_map
```
*RL: Can we just add the little ref map to the first outputs that have a map and ditch this one? Seems like a good option to reduce the number of figures. GEORGIA*


We develop a set of simple scenarios that capture two sorts of changes that may be commonly represented in management analyses. First, we consider scaled flow throughout the period of the hydrograph, representing overall increases or decreases in flow as might occur from large-scale climate patterns. Second, we consider short-duration additions to flow, representing periodic pulses of change as might happen from targeted interventions. Each scenario characterizes all water in the system including natural inflows, extraction, and release of environmental water, yielding a complete hydrograph (@fig-hydrographs shows a selected subset). These do not reflect realistic future scenarios but provide an avenue to test and illustrate the capabilities of the toolkit.

To scaled flow, we apply ten flow multipliers, ranging from 0.5 to 2.0, to the historical hydrographs (@tbl-scenarios). We refer to these as 'climate' scenarios, reflecting a common representation where entire hydrographs might shift to represent climate change, though these scenarios are not derived from climate models and do not represent hypothesized climate change. To achieve pulsed change for each of the 'climate' scenarios, four flow additions were applied including 1) no addition (baseline), 2) addition of 250 ML/d, 3) addition of 6500 ML/d, and 4) addition of 12000 ML/d (@tbl-scenarios). These additional flows were added throughout the period of September to December. We refer to these scenarios as 'climate adaptations' because management options are often available in the form of altering water availability for short time periods through mechanisms like water releases, though the options here do not represent proposed actions.

```{r}
#| label: tbl-scenarios
#| tbl-cap: Demonstration scenarios are a factorial combination of 'climate' (scaled flow) and 'adaptation' (pulsed additions). Climate scenarios included in this demonstration were produced by applying a flow multiplier to historical flows. Adaptation options were applied to each climate scenario with additional flows added throughout the period of September to December. For ease of display in some figures, we provide alpha codes for the 'climate' changes and numeric codes for the 'adaptations'. Mostly frequently, we present the ‘A’ (0.5 x historical flow), ‘E’ (1.0 x historical flow and ‘I’ (2.0 x historical flow) scenarios, with adaptions 1 (no flow addition), 2 (addition of 250 ML/d) and 3 (addition of 6500 ML/d).
#| layout-ncol: 2
#| tbl-subcap: 
#|  - "Climate"
#|  - "Adaptation"


adapt_scenes <- scenarios |> 
  filter(scenario != 'MAX') |> 
  mutate(flow_addition = as.integer(flow_addition)) |> 
  select(`Adaptation code` = adapt_code,
         `Flow addition (ML/d)` = flow_addition) |>
  distinct()
climate_scenes <- scenarios |> 
  filter(scenario != 'MAX') |> 
  select(`Climate code` = climate_code,
         `Flow multiplier` = flow_multiplier) |>
  distinct()

# Huxtables look better, but won't go side-by-side. and despite saying they work better in word, they're much worse.

# huxtable::huxtable(climate_scenes) |> theme_article()
# huxtable::huxtable(adapt_scenes) |> theme_article()

knitr::kable(climate_scenes |> 
               mutate(`Flow multiplier` = signif(`Flow multiplier`, 2)))
knitr::kable(adapt_scenes)

```

```{r}
#| label: fig-hydrographs
#| fig-cap: Hydrographs for two example gauges (represented by colour) with 'climate' scenarios on rows and 'adaptation' scenarios as columns. Scenario codes as in @tbl-scenarios.

hydro_plot <- scenehydros |>
    dplyr::filter(scenario %in% scenarios_to_plot & gauge %in% gauges_to_plot) |>
  dplyr::mutate(flow = flow/1000) |> 
  plot_outcomes(outcome_col = 'flow',
                outcome_lab = 'Flow (GL/day)',
                x_col = 'Date',
                colorset = 'gauge',
                color_lab = 'Gauge ID:',
                pal_list = gauge_pal,
                facet_row = 'climate_code',
                facet_col = 'adapt_code',
                ) +
    ggplot2::scale_y_continuous(sec.axis = sec_axis(~ . ,
                                                    name = "Climate scenario",
                                                    breaks = NULL, labels = NULL)) +
    ggplot2::scale_x_date(sec.axis = sec_axis(~ . , 
                                              name = "Adaptation option", 
                                              breaks = NULL, labels = NULL)) +
    theme_werp_toolkit(legend.position = "bottom")

hydro_plot
```

*GEORGIA shift ABOVE Figure to appendix.*

For simplicity for this demonstration, we use arithmetic means for all aggregations except the very first, though we typically present results only after this first step. The first step gives achievement of EWR indicators from timing-dependent sub-indicators. In that case, we consider that, if an EWR is achieved at any time, it is achieved and so use a maximum for that aggregation. Though we use means throughout, their meaning changes depending on the level of aggregation. For simplicity, we assume the value of each outcome represents some 'condition', and the 'condition' at a particular level can be assessed as the mean of the conditions contributing to it. For example, the condition of proximate environmental objectives might simply be the proportion of EWRs that contribute to each objective that are achieved. Then, the condition of Target groups, e.g. Native Fish, might be the mean condition over all the NF1..n objectives, despite those objectives depending on different numbers and sets of EWRs. This captures the idea that Native Fish condition improves when the life-cycle components captured by those objectives are met, whether it takes 1 or 10 EWRs to meet an objective.

# Results and discussion

Here, we present example results from the toolkit using the demonstration scenarios described above and the EWR tool as the response model. These results demonstrate the flexibility and robustness of the toolkit, which give it the capability to produce rigorous but interpretable and management-relevant results in a reproducible way (all code is available at https://github.com/MDBAuth/toolkit-demo-paper).

```{r}
#| label: simplfy-for-plots
#| include: false

# Create a grouping variable
obj_sdl_to_plot <- agged_data$sdl_units |>
  dplyr::mutate(env_group = stringr::str_extract(env_obj, '^[A-Z]+')) |>
  dplyr::filter(!is.na(env_group)) |>
  dplyr::arrange(env_group, env_obj)

# We can use spatial_aggregate directly to go straight to sdl from EWR without first averaging over env_obj or gauges. This gives a pure measure of the proportion ewr met in each sdl without issues of uneven contributions.
agg_ewr_sdl <- agged_data$ewr_code |> 
  spatial_aggregate(to_geo = sdl_units, 
                    groupers = c('scenario', 'climate_code', 'adapt_code'),
                    aggCols = ewr_achieved,
                    funlist = 'ArithmeticMean') |> 
  rename(ewr_achieved = spatial_ArithmeticMean_ewr_achieved)

```

Comparison of the direct outputs from the response model (in this example, pass/fail of EWRs) without any aggregation along the value dimension gives an overview of hydrologic responses at different locations (e.g. gauges) or areas (e.g. SDL units) to different scenarios. Such an assessment can identify areas that may be particularly vulnerable or which potential 'adaptation options' might be most impactful across many outcomes. In @fig-sdl-comparison, we present the EWR outcomes for three climate scenarios (A, E, and I) and three adaptation options (1, 2, and 3) (see @tbl-scenarios for definitions). 

This example aggregates the EWR outputs directly to the SDL unit, and shows that they are likely to be affected by the changes in flow resulting from these changes in 'climate' and application of these 'adaptation options'. However, the scenarios affect each SDL unit differently. The Lachlan has the highest proportion of EWRs achieved under all scenarios and has relatively consistent increases in EWR success with the adaptation options (though the options themselves are not even; 0 to 250 to 6500 ML/d). The Macquarie--Castlereagh is most sensitive to small increases in additional water, with large jumps between 'adaptation' options 1 and 2. In all situations, the 'climate' scenarios have less of an impact than the 'adaptation' scenarios, though neither is reflective of expected change in these dimensions. These outcomes are not yet directly linked to environmental assets or values and so each hydrologic indicator (EWR) at each gauge is represented with equal importance, whether it is required for all environmental objectives or just one.

```{r}
#| label: fig-sdl-comparison
#| fig-cap: Scenario comparison for different Sustainable Diversion Limit areas. This example shows the mean proportion of environmental watering requirements (EWRs) that are achieved under each scenario for each SDL unit. This approach illuminates broad-brush differences between scenarios and geographic locations, but does not address which EWRs may be more important to environmental assets or which assets are more sensitive to particular scenarios. Climate scenarios and adaptation options as in @tbl-scenarios. Panels a and b illustrate the same data with a emphasizing quantititive differences and b emphasizing spatial patterns.
#| message: false

# The bars
sdl_achieve_bars <- agg_ewr_sdl |> 
  filter(scenario %in% scenarios_to_plot) |> 
  mutate(scenario = paste0(climate_code, adapt_code), # This makes the names clean
         SWSDLName = stringr::str_replace(SWSDLName, '–', '-\n')) |> 
  plot_outcomes(outcome_col = 'ewr_achieved',
                outcome_lab = 'Proportion\nEWR achieved',
                x_col = 'scenario',
                x_lab = 'Climate and adaptation scenario',
                colorset = 'SWSDLName',
                color_lab = '',
                pal_list = SDL_pal |> 
                  setNames(stringr::str_replace(names(SDL_pal), '–', '-\n')),
                position = 'dodge',
                setLimits = c(0,1)) +
  # guides(fill = guide_legend(nrow=2, label.position = 'top')) +
  theme(legend.position = 'bottom')

  # if we really want facetted, this will do it, but I don't think it's needed:  
# facet_col = 'scenario',
# scales = 'free_x',

# The map
sdl_achieve_map <- agg_ewr_sdl |> 
  filter(scenario %in% scenarios_to_plot) |> 
  plot_outcomes(outcome_col = 'ewr_achieved',
                outcome_lab = 'Proportion\nEWR achieved',
                plot_type = 'map',
                facet_row = 'climate_code',
                facet_col = 'adapt_code',
                colorset = 'ewr_achieved',
                pal_list = achieve_pal,
                underlay_list = list(underlay = basin, underlay_pal = 'azure'),
                setLimits = c(0,1))

sdl_achieve_map <- sdl_achieve_map +
  theme(legend.position = 'bottom', 
        axis.ticks = element_blank(), 
        axis.text = element_blank()) +
  scale_y_continuous(sec.axis = sec_axis(~ . , name = "Climate scenario", 
                                         breaks = NULL, labels = NULL)) +
    scale_x_continuous(sec.axis = sec_axis(~ . , name = "Adaptation option",
                                           breaks = NULL, labels = NULL))

sdl_achieve_bars + sdl_achieve_map + 
  patchwork::plot_annotation(tag_levels = 'a')
```
*GH: Could we squeeze a 'where are we and where are the gauges' plot on here? Probably? Would be crowded. It'd be easy to just put the gauges on b, but they'll clutter it up. GEORGIA*


Response models may not themselves provide responses to all values of interest, and so we use the causal networks to link these outputs to additional objectives. In the EWR example, this linking is essential to address ecological outcomes and investigate how changes in flow affect values of interest. Thus, we can compare how native fish, native vegetation, waterbirds, other species, and ecosystem function targets are likely to respond to our hypothetical set of climates and adaptation scenarios. We are also able to compare the planning unit areas and the scenarios themselves. While there are many ways to display this information, @fig-obj_in_groups consolidates a large amount of information across scenarios, planning units, and multiple scales of objective. Each set of colours (and row of panels) represents outcomes at the larger ecological group level. Within those, the different shades represent single Environmental Objectives (e.g. WB1; Maintain the number and type of waterbird species), with the heights of these shades being the proportion of the constituent hydrologic requirements that are met (EWRs). Because the overall bar heights are then a sum of these proportions, we provide a dashed line as reference that shows the situation where all EWRs are met for each environmental objective. This reference is necessary because the number of EWRs contributing to each Environmental Objective, and the number of Environmental Objectives vary within each larger ecological group and spatial unit.

This view provides a useful overview of the impact of different scenarios on the environmental groups across space, while also retaining the ability to assess individual environmental objectives. For example, WB1 (Maintain the number and type of waterbird species) and WB2 (Increase total waterbird abundance across all functional groups) are unlikely to be achieved in the Macquarie--Castlereagh under any scenarios, while they are met in the baseline and 2x climate scenarios (2 and 3) in both the Lachlan and Namoi. At the larger group scale, we can see that the effect of halving water (moving from the baseline (2) scenario to the 1 scenario) has a disproportionately greater impact on Native Fish than doubling water (the 3 scenario) in the Lachlan, while these shifts are more proportional in the Namoi.

```{r}
#| label: fig-obj_in_groups
#| fig-cap: "Proportion of EWRs achieved for each proximate environmental objective (shades), grouped into broader environmental groups (Colors, rows. EF = Priority Ecosystem Function, NF = Native Fish, NV = Native Vegetation, OS = Other Species, WB = Waterbirds). Thus, each shade has a maximum height of 1 if all constituent EWRs are met. This view provides an assessment of the performance of individual environmental objectives, as well as how those contribute to the overall sensitivity of the broader groups across space. Not all EWR are applicable in all locations and there are not equal number of EWR in each category. The dashed horizonal lines show the total number of EWRs for reference. If each EWR contributing to the environmental objective were met, the bars would be at those lines. There are no Other Species objectives in the Namoi. This illustration includes three climate scenarios: A (0.5x), E (historical base level/no change), and I (2x) and three adaptation options 1 (no adaptation), 2 (+250 ML/d), and 3 (+6500 ML/d)" 
#| message: false
#| warning: false


obj_in_groups <- obj_sdl_to_plot |>
  filter(env_group != 'EB') |> # There's only one, this is just distracting.
  filter(scenario %in% scenarios_to_plot) |> 
  # clean the names
  mutate(scenario = paste0(climate_code, adapt_code), 
         SWSDLName = stringr::str_replace(SWSDLName, '–', '-\n')) |> 
  plot_outcomes(outcome_col = 'ewr_achieved',
                outcome_lab = "EWR achievement\nassessed for individual EWRs (shades)",
                x_col = 'scenario',
                x_lab = "Climate & Adaptation Option Scenario",
                colorgroups = 'env_group',
                colorset = 'env_obj',
                pal_list = env_pals,
                color_lab = "Environmental objectives",
                facet_col = 'SWSDLName',
                facet_row = 'env_group',
                sceneorder = rename_sceneorder
                )

# ADD IN MAX: new way?
maxdata <- obj_sdl_to_plot |> 
  st_drop_geometry() |> 
  filter(env_group != 'EB') |> # There's only one, this is just distracting.
  filter(scenario %in% "MAX") |> 
  # clean the names
  mutate(SWSDLName = stringr::str_replace(SWSDLName, '–', '-\n')) |> 
  summarise(ewr_achieved = sum(ewr_achieved), 
            .by = c(SWSDLName, env_group))

obj_in_groups <- obj_in_groups +
  geom_hline(data = maxdata, 
             mapping = aes(yintercept = ewr_achieved),
             linetype = 'dashed')

obj_in_groups

```
*RL: This confuses me. How do I know if each shade has a height of 1? ; I think that they’re then added to get to the total, but perhaps we need to make that next step explicit. Otherwise people will be looking at the y axis wondering why it goes to 10 if there is a max height of 1.* *GH:Yes, each shade has a max of 1, and they're stacked. The more I mess with this plot, the less I like it. I think it's really cool to be able to do the sub-colors, but the structure of this plot is fundamentally confusing since it's internally doing two different sorts of aggregation and so the y-axis for the overall bar heights is a really strange metric. An obvious thing to do is to scale the whole bar 0-1, but then the individual shades can't be 0-1, they'd be some proportion of a proportion, and that's weird too. But maybe better. At least then the overall bar height would be interpretable as the proportion of the EWRs contributing to each environmental group that pass, and the shades would just show the contribution of each env_obj in a weird unit, but they're hard to interpret individually anyway, so that might be fine- they'd give the idea, and the main axis would be easier to read. GEORGIA*

*There   are no Other Species objectives in the Namoi!!! RL: Then why is there a panel for them? What is shown there?* *GH: That is a very good question. My guess is that an EWR update meant they showed up and I didn't change the caption, but need to double check, obviously. SOMEONE*


```{r}
#| label: build-map-figs
#| include: false
ef_maps <- obj_sdl_to_plot |>
    dplyr::filter(scenario %in% scenarios_to_plot) |>
  # Need to reduce dimensionality
    dplyr::filter(env_group == 'EF' & !(env_obj %in% c('EF3a', 'EF3b'))) |> 
  # clean names
  mutate(scenario = paste0(climate_code, adapt_code), 
         SWSDLName = stringr::str_replace(SWSDLName, '–', '-\n')) |> 
  plot_outcomes(outcome_col = 'ewr_achieved',
                outcome_lab = 'Proportion\nEWR achieved',
                plot_type = 'map',
                colorset = 'ewr_achieved',
                pal_list = achieve_pal,
                facet_row = 'scenario',
                facet_col = 'env_obj',
                underlay_list = list(underlay = basin,
                                     pal_list = 'azure'),
                setLimits = c(0,1)) 

ef_maps <- ef_maps + 
  scale_y_continuous(sec.axis = sec_axis(~ . ,
                                         name = "Climate & Adaptation Option Scenario", 
                                         breaks = NULL, labels = NULL)) +
    scale_x_continuous(sec.axis = sec_axis(~ . , 
                                           name = "Environmental objective",
                                           breaks = NULL, labels = NULL)) +
  theme(axis.ticks = element_blank(), 
                         axis.text=element_blank())

# gauges with blank sdl units
  # because gauges contribute to multiple planning units, reporting them is not a good indicator of condition. However, to show how the aggregation works, we can do something here to get single values for them by using theme aggregate directly and allowing it to average over the multiple rows due to multiple planning units.
agged_gauges <- agged_data$ewr_code |> 
  theme_aggregate(from_theme = 'ewr_code', to_theme = 'env_obj',
                  groupers = c('scenario', 'gauge', 'climate_code', 'adapt_code'),
                  aggCols = 'ewr_achieved',
                  funlist = ArithmeticMean,
                  causal_edges = causal_ewr,
                  auto_ewr_PU = FALSE) |> 
  agg_names_to_cols(aggsequence = 'env_obj', 
                    funsequence = 'ArithmeticMean', 
                    aggCols = 'ewr_achieved')

nf_gauges <- agged_gauges |>
    dplyr::filter(env_obj == 'NF1' & scenario == 'climatebaseadapt0') |> # Need to reduce dimensionality
  # clean names
  mutate(scenario = paste0(climate_code, adapt_code)) |> 
  plot_outcomes(outcome_col = 'ewr_achieved',
                outcome_lab = 'Proportion\nEWR achieved',
                plot_type = 'map',
                colorset = 'ewr_achieved',
                pal_list = achieve_pal,
                underlay_list = list(list(underlay = basin,
                                     pal_list = 'azure'),
                                     list(underlay = sdl_units |> 
                                            filter(SWSDLName %in%
                                                     unique(obj_sdl_to_plot$SWSDLName)),
                                         pal_list = 'gray')),
                setLimits = c(0,1)) +
  theme(axis.ticks = element_blank(), 
                         axis.text=element_blank())

# The 'env_ob' dataset is at the planning unit scale before agg to sdl
nf_PU <- agged_data$env_obj |>
    dplyr::filter(env_obj == 'NF1' & scenario == 'climatebaseadapt0') |> # Need to reduce dimensionality
  # clean names
  mutate(scenario = paste0(climate_code, adapt_code)) |> 
  plot_outcomes(outcome_col = 'ewr_achieved',
                outcome_lab = 'Proportion\nEWR achieved',
                plot_type = 'map',
                colorset = 'ewr_achieved',
                pal_list = achieve_pal,
                map_outlinecolor = NA,
                underlay_list = list(list(underlay = basin,
                                     pal_list = 'azure'),
                                     list(underlay = sdl_units |> 
                                            filter(SWSDLName %in%
                                                     unique(obj_sdl_to_plot$SWSDLName)),
                                         pal_list = 'gray')),
                setLimits = c(0,1)) +
  theme(axis.ticks = element_blank(), 
                         axis.text=element_blank())

# are there better ways to show this?

# a single sdl map for comparison
nf_maps_single <- obj_sdl_to_plot |>
    dplyr::filter(env_obj == 'NF1' & scenario == 'climatebaseadapt0') |>
  mutate(scenario = ifelse(scenario == 'MAX', 'MAX', 
                           paste0(climate_code, adapt_code)), 
         SWSDLName = stringr::str_replace(SWSDLName, '–', '-\n')) |> 
  plot_outcomes(outcome_col = 'ewr_achieved',
                outcome_lab = 'Proportion\nEWR achieved',
                plot_type = 'map',
                colorset = 'ewr_achieved',
                pal_list = achieve_pal,
                underlay_list = list(underlay = basin,
                                     pal_list = 'azure'),
                setLimits = c(0,1))  +
  theme(axis.ticks = element_blank(), 
                         axis.text=element_blank())

# a smaller subset of sdls and scenarios
# a single sdl map for comparison
obj_maps_few <- obj_sdl_to_plot |>
    dplyr::filter(env_obj %in% c('NF1', 'EF3', 'WB4') & 
                    scenario %in% c('climatedown2adapt250', 
                                    'climatebaseadapt0', 
                                    'climateup2adapt6500')) |>
  mutate(scenario = ifelse(scenario == 'MAX', 'MAX', 
                           paste0(climate_code, adapt_code)), 
         SWSDLName = stringr::str_replace(SWSDLName, '–', '-\n')) |> 
  plot_outcomes(outcome_col = 'ewr_achieved',
                outcome_lab = 'Proportion\nEWR achieved',
                plot_type = 'map',
                colorset = 'ewr_achieved',
                pal_list = achieve_pal,
                facet_row = 'scenario',
                                facet_col = 'env_obj',

                underlay_list = list(underlay = basin,
                                     pal_list = 'azure'),
                setLimits = c(0,1))  +
  theme(axis.ticks = element_blank(), 
                         axis.text=element_blank())

# trying to make the singles cleaner


# # if we keep these, they should go to appendix
# 
# # gauges with different color on colored sdls
# ef_gauges_undercolor <- agged_data$env_obj |>
#     dplyr::filter(env_obj == 'EF1' & scenario == 'climatebaseadapt0') |> # Need to reduce dimensionality
#   # clean names
#   mutate(scenario = ifelse(scenario == 'MAX', 'MAX', 
#                            paste0(climate_code, adapt_code))) |> 
#   plot_outcomes(outcome_col = 'ewr_achieved',
#                 outcome_lab = 'Proportion\nEWR achieved',
#                 plot_type = 'map',
#                 colorset = 'ewr_achieved',
#                 pal_list = 'grDevices::Red-Purple',
#                 facet_row = 'scenario',
#                 facet_col = 'env_obj',
#                 underlay_list = list(list(underlay = basin,
#                                      pal_list = 'azure'),
#                                      list(underlay = obj_sdl_to_plot |> 
#                                             filter(env_obj == 'EF1' & 
#                                                      scenario == 'climatebaseadapt0') |> 
#                                             mutate(scenario = ifelse(scenario == 'MAX', 'MAX', 
#                            paste0(climate_code, adapt_code))),
#                                           y_col = 'ewr_achieved',
#                                           pal_list = achieve_pal)),
#                 setLimits = c(0,1)) +
#   theme(axis.ticks = element_blank(), 
#                          axis.text=element_blank())
# 
# # same, but just let the colors be the same ramp and see if it's visible
# ef_gauges_undercolor_same <- agged_data$env_obj |>
#     dplyr::filter(env_obj == 'EF1' & scenario == 'climatebaseadapt0') |> # Need to reduce dimensionality
#   # clean names
#   mutate(scenario = ifelse(scenario == 'MAX', 'MAX', 
#                            paste0(climate_code, adapt_code))) |> 
#   plot_outcomes(outcome_col = 'ewr_achieved',
#                 outcome_lab = 'Proportion\nEWR achieved',
#                 plot_type = 'map',
#                 colorset = 'ewr_achieved',
#                 pal_list = achieve_pal,
#                 facet_row = 'scenario',
#                 facet_col = 'env_obj',
#                 underlay_list = list(list(underlay = basin,
#                                      pal_list = 'azure'),
#                                      list(underlay = obj_sdl_to_plot |> 
#                                             filter(env_obj == 'EF1' & 
#                                                      scenario == 'climatebaseadapt0') |> 
#                                             mutate(scenario = ifelse(scenario == 'MAX', 'MAX', 
#                            paste0(climate_code, adapt_code))),
#                                           y_col = 'ewr_achieved',
#                                           pal_list = achieve_pal)),
#                 setLimits = c(0,1)) +
#   theme(axis.ticks = element_blank(), 
#                          axis.text=element_blank())

```
*RL: Could be a spot to condense. You’ve mentioned some of this explanation about what maps are useful for earlier.*
Maps allow large-scale visualization of environmental objectives under various scenarios. These visualisations can be quite important for communications and quickly grasping how outcomes aggregate spatially ([@fig-spatial-scaling]) and spatial patterns in the data ([@fig-gauge-to-sdl-map]). Management targets are often defined spatially, and in the case of EWRs, they are defined in local Planning Units (which are constituents of the SDL units defined above), where outcomes may depend on hydrographs at one or more gauges. Representing the outcomes as maps can provide intuitive assessment of the condition of values across space and whether different spatial scales or spatial locations are responding differently to scenarios. Moreover, the ecology (in this example) or other processes might themselves be large-scale, and so capturing the condition over a large area is a better descriptor of the true outcome than assessing each specific location separately. For example, objective EF3 is "Provide movement and dispersal opportunities for water dependent biota to complete lifecycles and disperse into new habitats within catchments", and so necessarily incorporates a spatial dimension. Particularly in these situations, the aggregation method should be considered carefully – for movement opportunities to succeed, perhaps the success of the SDL unit should be determined by the lowest value at a gauge if it represents a loss of connectivity. In contrast, for WB4: Increase opportunities for colonial waterbird breeding, it might be sufficient if a single site within the SDL unit provides those opportunities.

*GH: I sure wish the planning units weren't so ugly, but that's what they are, so not sure there's much we can do about it. GEORGIA GD: maybe we could get rid of the basin outline to zoom in on the catchements for this figure?*

```{r}
#| label: fig-spatial-scaling
#| fig-cap: Environmental water requirements (EWRs) are defined by hydrographs at gauges (a), and apply to Planning Units (b). The outcomes at these scales of definition can then be aggregated to larger spatial areas, such as SDL units (c), which we do here with an area-weighted mean for the example EWR NF1 in the baseline climate and adaptation scenario (E1, simple historical hydrograph with no climate or adaptation changes).


nf_gauges + nf_PU + nf_maps_single +
  plot_layout(guides = 'collect') &
  theme(legend.position = 'bottom')
```

```{r}
#| label: fig-gauge-to-sdl-map
#| fig-cap: "Environmental objectives aggregated to SDL unit spatial scale, illustrated here for three examples (Priority Ecosystem Function 3, Native Fish 1, and Waterbirds 4). Polygon colors indicate the proportion of EWR passed for each objective in each SDL unit. Aggregation as in @fig-spatial-scaling. Includes three climate scenarios: A (0.5x), E (historical base level/no change), and I (2x) and three adaptation options 1 (no adaptation), 2 (+250 ML/d), and 3 (+6500 ML/d), though not all combinations [see Appendix @sec-map-versions]."

obj_maps_few

```

While we can see which scenarios are better or worse than others with bar graphs ([@fig-obj_in_groups]) or maps ([@fig-gauge-to-sdl-map]), they can make it difficult to accurately assess relative differences that may illuminate disproportionate impacts and thresholds for when adaption options could be most effectively adopted. In general, this requires quantitative x-axes which would typically be referenced to some baseline. Here, we can represent both our 'climate' and 'adaptation' scenarios on a single axis by quantifying the difference in mean flow from the baseline condition (historical hydrograph, E1) using the baselining functionality provided by the toolkit (see @sec-baselining). Plotting the proportion of EWRs achieved for each of the Native Fish environmental objectives shows how that EWR achievement is related to changes in the overall levels of flow. One striking feature of @fig-difference-baseline is that the lines do not smoothly increase; EWR achievement is not simply a direct relationship to flow volumes. Instead, the timing matters. There are particularly steep slopes between the '1' (baseline) and '2' (+250 ML/d) adaptations. The application of water at those particular times is thus disproportionately impactful, yielding greater outcomes even when they have less water than the baseline adaptations (‘1s’)  for climate scenarios 'A' and 'E'. Such analyses can identify highly efficacious points to add water to the system.

```{r}
#| label: fig-difference-baseline
#| fig-cap: "Quantitative scenario comparison for Native Fish objectives for three SDL units. Scenarios defined here as the difference in mean flow (GL) from the baseline historical scenario (E1). A key message here is that the lines are not smooth – EWR achievement is not simply a function of the amount of water. Instead, the 'adaptation' options, particularly the '2' scenarios of adding 250 ML/d of water, have disproportionately large impact (steep slopes). Shading indicates different environmental objectives within the native fish target group. This illustration includes three climate scenarios: A (0.5x), E (historical base level/no change), and I (2x) and three adaptation options: 1 (no adaptation), 2 (+250 ML/d), and 3 (+6500 ML/d)."
#| message: false


gl_difference <- obj_sdl_to_plot |>
  dplyr::filter(scenario %in% scenarios_to_plot) |>
  dplyr::filter(env_group == 'NF') |> 
  left_join(dif_flow, by = 'scenario') |> 
  # clean names
  mutate(SWSDLName = stringr::str_replace(SWSDLName, '–', '-\n')) |> 
  
  plot_outcomes(outcome_col = 'ewr_achieved',
                outcome_lab = "Proportion EWR achieved",
                x_col = "scenario_difference",
                x_lab = "Mean flow difference (GL)",
                colorgroups = 'env_group',
                colorset = 'env_obj',
                pal_list = env_pals,
                # base_lev = 'E1',
                # comp_fun = 'difference',
                # group_cols = c('env_obj', 'polyID'),
                color_lab = "Envionmental objectives",
                facet_row = 'SWSDLName',
                facet_col = '.') 

gl_difference <- gl_difference + 
  geom_vline(data = filter(scenarios, scenario  %in% scenarios_to_plot),
             mapping = aes(xintercept = scenario_difference))

# This gets pretty close without needing the weird extra facet
# gl_difference <- gl_difference + 
#   geom_text(gl_difference$data |> filter(SWSDLName == "Lachlan"),
#             mapping = aes(label = scenario, y = Inf),
#             vjust = 1.5, size = 3)

header_difference <-  scenarios |> 
  filter(scenario  %in% scenarios_to_plot) |> 
  mutate(scenario = ifelse(scenario == 'MAX', 'MAX', 
                           paste0(climate_code, adapt_code))) |> 
  ggplot(aes(x = scenario_difference,
             y = 1)) +
  # geom_vline(mapping = aes(xintercept = scenario_difference)) +
  # ggrepel::geom_text_repel(mapping = aes(label = scenario),
  #                          # size = 3,
  #                          angle = 90,
  #                          direction='x') +
  # This kind of works better if we get rid of vline. The repel just isnt' working very well
  geom_text(mapping = aes(label = scenario), size = 3) +
  theme_werp_toolkit(legend.position = "none", axis.title=element_blank(),
                     axis.text=element_blank(), axis.ticks=element_blank())

# put those together
header_difference + gl_difference + 
  plot_layout(ncol = 1, heights = c(1,15)) + theme(legend.position = "right")
```

```{r}
#| label: build-smooth-figs
#| include: false
sdl_smooth_groups <- obj_sdl_to_plot |>
  dplyr::filter(adapt_code %in% c(1,2,3) &
                  scenario != 'MAX') |> # max isn't really relevant here
  dplyr::filter(env_group != 'EB') |> 
  # mutate(ewr_achieved = ewr_achieved + 1) |> 
  # clean names
  mutate(scenario = paste0(climate_code, adapt_code), 
         SWSDLName = stringr::str_replace(SWSDLName, '–', '-\n'),
         adapt_code = as.character(adapt_code)) |>
  plot_outcomes(outcome_col = 'ewr_achieved',
                x_col = 'flow_multiplier',
                outcome_lab = 'Condition',
                x_lab = 'Flow relative to baseline',
                transx = 'log10',
                transy = 'log10',
                scales = 'free_y',
                
                color_lab = 'Adaptation',
                colorgroups = NULL,
                colorset = 'adapt_code',
                # point_group = 'env_obj',
                pal_list = adapt_pal,
                facet_row = 'env_group',
                facet_col = 'SWSDLName',
                position = 'jitter',                
                zero_adjust = 0.01, # needed here to make the trans work.

                base_list = list(base_lev = 'E1',
                                 comp_fun = 'relative',
                                 group_cols = c('env_obj', 'polyID')),
                smooth_arglist = list())

# This is better in some ways and worse in others, flippig the colors and facets
sdl_smooth_groups_flipped <- obj_sdl_to_plot |>
  dplyr::filter(adapt_code %in% c(1,2,3) &
                  scenario != 'MAX') |> # max isn't really relevant here
  dplyr::filter(env_group != 'EB') |> 
  # mutate(ewr_achieved = ewr_achieved + 1) |> 
  # clean names
  mutate(scenario = paste0(climate_code, adapt_code), 
         SWSDLName = stringr::str_replace(SWSDLName, '–', '-\n')) |>
  plot_outcomes(outcome_col = 'ewr_achieved',
                x_col = 'flow_multiplier',
                outcome_lab = 'Environmental objectives\nrelative to baseline',
                x_lab = 'Flow relative to baseline',
                transx = 'log10',
                transy = 'log10',
                scales = 'free_y',
                
                color_lab = 'Environmental group',
                colorgroups = NULL,
                colorset = 'env_group',
                # point_group = 'env_obj',
                pal_list = list('scico::berlin'),
                facet_row = 'adapt_code',
                facet_col = 'SWSDLName',
                position = 'jitter',
                zero_adjust = 0.01, # needed here to make the trans work.

                base_list = list(base_lev = 'E1',
                                 comp_fun = 'relative',
                                 group_cols = c('env_obj', 'polyID')),
                smooth_arglist = list())

# just native fish in the Namoi
# This is better in some ways and worse in others, flippig the colors and facets
sdl_smooth_groups_NFNamoi <- obj_sdl_to_plot |>
  dplyr::filter(adapt_code %in% c(1,2,3) &
                  scenario != 'MAX') |> # max isn't really relevant here
  dplyr::filter(env_group == 'NF' & SWSDLName == 'Namoi') |> 
  # mutate(ewr_achieved = ewr_achieved + 1) |> 
  # clean names
  mutate(scenario = paste0(climate_code, adapt_code), 
         SWSDLName = stringr::str_replace(SWSDLName, '–', '-\n'),
         adapt_code = as.character(adapt_code)) |>
  plot_outcomes(outcome_col = 'ewr_achieved',
                x_col = 'flow_multiplier',
                outcome_lab = 'Condition',
                x_lab = 'Flow relative to baseline',
                transx = 'log10',
                transy = 'log10',
                scales = 'free_y',
                
                color_lab = 'Adaptation',
                colorgroups = NULL,
                colorset = 'adapt_code',
                # point_group = 'env_obj',
                pal_list = adapt_pal,
                facet_row = 'env_group',
                facet_col = 'SWSDLName',
                position = 'jitter',                
                zero_adjust = 0.01, # needed here to make the trans work.

                base_list = list(base_lev = 'E1',
                                 comp_fun = 'relative',
                                 group_cols = c('env_obj', 'polyID')),
                smooth_arglist = list())


# What if we really try to smash down what we're showing? The adaptations are blowing it out. Which is a good message, but confusing. Maybe it's a two-parter?

# First, the climate response at no adaptation
sdl_smooth_clim <- obj_sdl_to_plot |>
  dplyr::filter(adapt_code %in% c(1) &
                  scenario != 'MAX') |> # max isn't really relevant here
  dplyr::filter(env_group != 'EB') |> 
  # mutate(ewr_achieved = ewr_achieved + 1) |> 
  # clean names
  mutate(scenario = paste0(climate_code, adapt_code), 
         SWSDLName = stringr::str_replace(SWSDLName, '–', '-\n')) |>
  plot_outcomes(outcome_col = 'ewr_achieved',
                x_col = 'flow_multiplier',
                outcome_lab = 'Condition',
                x_lab = 'Flow relative to baseline',
                transx = 'log10',
                transy = 'log10',
                scales = 'free_y',
                color_lab = 'Environmental group',
                colorgroups = NULL,
                colorset = 'env_group',
                # point_group = 'env_obj',
                pal_list = envgroup_pal,
                facet_row = '.',
                facet_col = 'SWSDLName',
                position = 'jitter',
                zero_adjust = 0.01, # needed here to make the trans work.

                base_list = list(base_lev = 'E1',
                                 comp_fun = 'relative',
                                 group_cols = c('env_obj', 'polyID')),
                smooth_arglist = list())

# Next, the adaptation response at no climate
sdl_smooth_adapt <- obj_sdl_to_plot |>
  dplyr::filter(climate_code %in% c('E') &
                  scenario != 'MAX' & 
                  flow_addition < 10000 ) |> # max isn't really relevant here, and 12,500 is a LOT
  dplyr::filter(env_group != 'EB') |> 
  # get the log to work, saying we added 1 is fine here
  mutate(flow_addition = flow_addition + 1) |>
  # clean names
  mutate(scenario = paste0(climate_code, adapt_code), 
         SWSDLName = stringr::str_replace(SWSDLName, '–', '-\n')) |>
  plot_outcomes(outcome_col = 'ewr_achieved',
                x_col = 'flow_addition',
                outcome_lab = 'Condition',
                x_lab = 'Flow addition (ML/d)',
                transx = 'log10',
                transy = 'log10',
                scales = 'free_y',
                color_lab = 'Environmental group',
                colorgroups = NULL,
                colorset = 'env_group',
                # point_group = 'env_obj',
                pal_list = envgroup_pal,
                facet_row = '.',
                facet_col = 'SWSDLName',
                position = 'jitter',
                zero_adjust = 0.01, # needed here to make the trans work.
                base_list = list(base_lev = 'E1',
                                 comp_fun = 'relative',
                                 group_cols = c('env_obj', 'polyID')),
                smooth_arglist = list())
```

With a large number of scenarios, we can better characterise the way values respond along different axes of change. Here, we use smoothed fits to show trends in the performance of environmental objectives (and groups thereof) in response to multiplicative flow changes ('climate' scenarios) and pulsed flow additions ('adaptations') (@fig-smooth-climate-adapt, @fig-smooth-all). We use baselining (see @sec-baselining) to show the relative change on both the x (flow) and y (response) axes. Thus, any slope other than 1:1 represents a disproportionate shift in condition. Moreover, because we use smoothed fits, we can identify thresholds or areas of flow change that are disproportionately more important (small changes in flow can yield large shifts in condition). We set the limits of @fig-smooth-climate-adapt equal for x and y to better visualise this proportionality or lack thereof. For example, Other Species and Native Vegetation show steeper increases with increasing flow relative to baseline than decreasing flow, while Native Fish respond disproportionately to flow change across the range considered here.

*RL: This is confusing without any discussion of what Fig 20 is. Do we need it here or can this para move to the supplement too?* *GH: Hmm. I seem to have made major changes to these figs but not the text. Fig 20 used to be here, and fig 13 used to be different. The idea was that panel C could be used to accentuate the main point of Fig 20, that the adaptations here have a way bigger impact than the climate. So, yes, we should move most of this to the appendix. If we keep C, we should keep a sentence about it. And maybe we should decide we don't need C at all and cut it back off the figure.* In @fig-smooth-all the y-axis scales are much larger than the x, and so proportionality is difficult to assess. However, this figure makes clear the nonlinear nature of the response to flow shift, particularly for the no adaptation scenario (1), as well as changes in sensitivity between adaptation options. The response to adapatation options (differences between the lines in @fig-smooth-all, slope of lines in @fig-smooth-climate-adapt panel b) tends to be much stronger than the response to climate (slopes of the lines in @fig-smooth-all and @fig-smooth-climate-adapt panel a), even though the shift in total water might be lower. Moreover, the adaptation options are not as sensitive to the climate scenarios; adaptation options other than '1' (no adaptation) show less change with climate in [@fig-smooth-all]. Thus, these 'adaptations' are increasing resilience to those holistic flow changes. Although these scenarios do not represent true adaptation options or climate scenarios, this shows that such changes to resilience are possible with targeted interventions, and the toolkit provides the capacity to investigate them.

The responses seen in @fig-smooth-all and @fig-smooth-climate-adapt vary between SDL unit (columns) and environmental group, indicating different sensitivity to both 'climate' and 'adaptation' flow conditions across space and among ecological groupings. For example, although both the Lachlan and Macquarie-Castlereagh have no successful Waterbird outcomes under baseline conditions, targeted flow conditions have a greater ability to increase Waterbird success in the Lachlan.


```{r}
#| label: fig-smooth-climate-adapt
#| fig-cap: Smoothed fits of shifts in environmental objectives to changes in flow, both multiplicatively over the whole hydrograph (panel a, 'climate' scenarios) and with pulsed flow additions (panel b, 'adaptation' scenarios. Panel a includes no flow additions, and panel b has those additions to the baseline 'climate' scenario (historical hydrograph). The full combination of scenarios are shown for the example of Native Fish in the Namoi in panel c, which accentuates the larger impact of the 'adaptation' options used here than the 'climate' shifts. Points are individual environmental objectives, fitted lines are loess smooths. Separate fits are done for each environmental group. Columns are SDL units. Y-axes set to match x-axes to better visualise proportionality. Thus, a small amount of data is not plotted, but is accounted for in the fits. The full set of SDL units and groups as in c shown in Appendix @fig-smooth-all.
#| message: false
#| warning: false

# layout <- "
# AAAA
# BBBB
# ##CC
# "

grp_smooths <- patchwork::wrap_plots(sdl_smooth_clim  + 
                                       coord_cartesian(ylim = c(0.5, 2)),
                      sdl_smooth_adapt) +
  plot_annotation(tag_levels = 'a') +
  plot_layout(guides = 'collect', nrow = 2)

namoi_plot <- guide_area() + sdl_smooth_groups_NFNamoi + plot_layout(guides = 'collect')

patchwork::wrap_plots(grp_smooths,
                      namoi_plot) +
  plot_layout(nrow = 2, heights = c(5,1)) +
  plot_annotation(tag_levels = 'a')

# patchwork::wrap_plots(sdl_smooth_clim  + coord_cartesian(ylim = c(0.5, 2)),
#                       sdl_smooth_adapt,
#                       sdl_smooth_groups_NFNamoi,
#                       design = layout, byrow = FALSE) +
#   plot_annotation(tag_levels = 'a')
# 
# ((sdl_smooth_clim  + coord_cartesian(ylim = c(0.5, 2)) )/
#   (sdl_smooth_adapt) +
#   plot_layout(guides = 'collect')) +
#   (sdl_smooth_groups_NFNamoi + theme(legend.position = 'left')) +
#   plot_annotation( tag_levels = 'a')
```

Scenarios will often be defined along more than one axis. In the demonstration here, we define both a flow multiplication axis as a proxy for 'climate' shifts, and a flow addition as a proxy for 'adaptations'. Moreover, it will often be the case that values will respond to several different aspects of the flow regime, for example the mean flow and the flow variance or the return interval of floods or low-flow periods. Heatmaps or contour surfaces provide a powerful tool for visualising these interacting responses ([@fig-contour], [@fig-heatmap]). By examining multiple driver axes, such plots can highlight important interactions and identify where thresholds occur and where change along one axis (e.g. adaptations) can mitigate change along the other (e.g. climate shifts). This ability to identify the axes that provide resilience or sensitivity to changes in others will be critically important for management uses of this toolkit targeting climate change adaptation. These assessments must also take spatial and value differences into account; the different environmental groupings and SDL units show very different patterns in how they respond to the interaction between the 'climate' and 'adaptation' scenarios ([@fig-contour]).

Perhaps most usefully, if scenarios are carefully developed to explore the range of potential change in the system, then the heatmap represents the response surface of values over this range. Developing the response surface can be iterative, with subsequent scenarios developed to increase resolution near areas of rapid change in outcome. This approach differs from the usual approach of assessing only a small set of scenarios targeting specific proposed actions or environmental conditions. Instead, by covering the range to generate a response surface, it can provide hypotheses about how proposed scenarios might perform and assess how sensitive the outcomes are to uncertainty in single scenarios. Specific proposed scenarios could of course be assessed as well and mapped onto the surface. For example, we might think of the flow multipliers here as defining the entire range of plausible climate shifts, and the addition scenarios as the entire potential range of additions. Then, specific proposed adaptations or climate sequences could be mapped onto these heatmaps at particular points. The reverse is also possible; identification of areas of high sensitivity in the heatmaps could be used to choose a set of potential adaptations designed to increase climate resilience. This idea extends to additional dimensions, which can then be collapsed in various ways (e.g. via principal component analysis, or by identifying dominant hydrometrics) to visualise with 2d heatmaps even when the response surface itself is best defined and studied in more dimensions. 

```{r}
#| label: build-heatmaps
# Use the Target here to get to the big groups

# qualitative axes
qual_heatmap <- agged_data_pooled_ewrs$Target |>
  dplyr::filter(adapt_code %in% c(1,2,3, 4) &
                  scenario != 'MAX') |> # max isn't really relevant here
  dplyr::filter(!is.na(Target)) |> 
  # clean names
  mutate(scenario = paste0(climate_code, adapt_code), 
         SWSDLName = stringr::str_replace(SWSDLName, '–', '-\n'),
         Target = stringr::str_replace(Target, 'Priority e', 'E'),
         adapt_code = as.character(adapt_code)) |>
  plot_outcomes(outcome_col = 'ewr_achieved',
                outcome_lab = 'Condition',
                y_col = 'adapt_code', 
                y_lab = 'Adaptation option',
                x_col = 'climate_code', 
                x_lab = 'Climate scenario',
                plot_type = 'heatmap',
                colorset = 'ewr_achieved',
                pal_list = 'grDevices::Viridis',
                facet_row = 'Target',
                facet_col = 'SWSDLName')

# Quantitative axes- it's more informative, but uglier
quant_heatmap <- agged_data_pooled_ewrs$Target |>
  dplyr::filter(adapt_code %in% c(1,2,3) &
                  scenario != 'MAX') |> # max isn't really relevant here
  dplyr::filter(!is.na(Target)) |> 
  # clean names
  mutate(scenario = paste0(climate_code, adapt_code), 
         SWSDLName = stringr::str_replace(SWSDLName, '–', '-\n'),
         Target = stringr::str_replace(Target, 'Priority e', 'E'),
         adapt_code = as.character(adapt_code)) |>
  mutate(flow_addition = flow_addition + 1) |> 
  plot_outcomes(outcome_col = 'ewr_achieved',
                outcome_lab = 'Condition',
                y_col = 'flow_addition', 
                y_lab = 'Flow addition',
                x_col = 'flow_multiplier', 
                x_lab = "Flow multiplier",
                plot_type = 'heatmap',
                transy = 'log10',
                transx = 'log10',
                colorset = 'ewr_achieved',
                pal_list = 'grDevices::Viridis',
                facet_row = 'Target',
                facet_col = 'SWSDLName',
                setLimits = c(0,1))

# interpolated raster- just one argument different
  # THe spacing is too uneven though
quant_interp_heatmap <- agged_data_pooled_ewrs$Target |>
  dplyr::filter(adapt_code %in% c(1,2,3) &
                  scenario != 'MAX') |> # max isn't really relevant here
  dplyr::filter(!is.na(Target)) |> 
  # clean names
  mutate(scenario = paste0(climate_code, adapt_code), 
         SWSDLName = stringr::str_replace(SWSDLName, '–', '-\n'),
         Target = stringr::str_replace(Target, 'Priority e', 'E'),
         adapt_code = as.character(adapt_code)) |>
  mutate(flow_addition = flow_addition + 1) |> 
  plot_outcomes(outcome_col = 'ewr_achieved',
                outcome_lab = 'Condition',
                y_col = 'flow_addition', 
                y_lab = 'Flow addition',
                x_col = 'flow_multiplier', 
                x_lab = "Flow multiplier",
                plot_type = 'heatmap',
                transy = 'log10',
                transx = 'log10',
                colorset = 'ewr_achieved',
                pal_list = 'grDevices::Viridis',
                facet_row = 'Target',
                facet_col = 'SWSDLName',
                setLimits = c(0,1),
                contour_arglist = list(interpolate = TRUE))

# This would be better if we had a more even and tighter set of scenarios
  contour_heatmap <- agged_data_pooled_ewrs$Target |>
  dplyr::filter(adapt_code %in% c(1,2,3) &
                  scenario != 'MAX') |> # max isn't really relevant here
  dplyr::filter(!is.na(Target)) |> 
  # clean names
  mutate(scenario = paste0(climate_code, adapt_code), 
         SWSDLName = stringr::str_replace(SWSDLName, '–', '-\n'),
         Target = stringr::str_replace(Target, 'Priority e', 'E'),
         adapt_code = as.character(adapt_code)) |>
  mutate(flow_addition = flow_addition + 1) |> 
  plot_outcomes(outcome_col = 'ewr_achieved',
                outcome_lab = 'Condition',
                y_col = 'flow_addition', 
                y_lab = 'Flow addition',
                x_col = 'flow_multiplier', 
                x_lab = "Flow multiplier",
                plot_type = 'heatmap',
                transy = 'log10',
                transx = 'log10',
                colorset = 'ewr_achieved',
                pal_list = 'grDevices::Viridis',
                facet_row = 'Target',
                facet_col = 'SWSDLName',
                setLimits = c(0,1),
                contour_arglist = list()
  )

```


```{r}
#| label: fig-contour
#| fig-cap: Condition results visualised as a surface with the two scenario definitions on the axes. This approach allows visualising changes in outcome as the result of multiple axes on which scenarios might differ. These axes might be different aspects of scenario creation (as here), or they might be different axes describing the outcome of scenarios (e.g. two different hydrometrics such as mean flow and flow variance)

contour_heatmap
```

Causal networks can be used to show outcomes in addition to the causal relationships themselves. This sort of visualisation allows identification of the holistic consequences of the different scenarios across the complex and interrelated sets of values, as well as identifying nodes that are unusually resilient or sensitive to change ([@fig-network-subset]). For example, NF7 is little changed across the range of climate scenarios considered, while EF5 shows greater sensitivity. The network structure can also identify critical nodes that have outsize consequences for other nodes in the network. Such nodes are critically important for outcomes, and so should be investigated to determine whether they capture key aspects of the system or are instead an artifact of model structure (possibly resulting from the way the network was developed) that may bias results. If their sensitivity does in fact capture the system, these nodes may be ideal targets for management intervention. The edges also identify the dependence between values, where we can see that different environmental outcomes depend on not only different hydrologic indicators (EWRs), but also different numbers of those indicators.

```{r}
#| label: network-setup
#| message: false

## NOTE TO SELF: THIS ALL NEEDS TO BE A FUNCTION IN THE TOOLKIT
# just get the theme-scale values
# First we need the sequence lists

aggparams <- yaml::read_yaml(file.path(agg_results,
                                      'agg_metadata.yml'))

themeseq <- aggparams$aggregation_sequence[
  !names(aggparams$aggregation_sequence) %in%
    c('planning_unit', 'sdl_units', 'mdb')
]

themefuns <- aggparams$aggregation_funsequence[
  !names(aggparams$aggregation_sequence) %in%
    c('planning_unit', 'sdl_units', 'mdb')
]

# skip the _timing
ewr_edges <- make_edges(dflist = causal_ewr, 
                        fromtos = themeseq[2:length(themeseq)],
                        gaugefilter = gauges_to_plot[2])

# get the nodes
nodes <- make_nodes(ewr_edges)

aggvals <- extract_vals_causal(agged_data,
                               whichaggs = themefuns, 
                               valcol = 'ewr_achieved', 
                               targetlevels = names(themeseq))

# filter to a single gauge. Multiple gauges should have separate networks or otherwise split the gauge-specific nodes. And include the larger scales pertaining to that gauge.
gaugematch <-  st_intersects(bom_basin_gauges[bom_basin_gauges$gauge ==
                                                gauges_to_plot[2],], 
                             aggvals, sparse = FALSE)

aggvals <- aggvals[as.vector(gaugematch),] |>
  st_drop_geometry()

# join to the nodes
nodes_with_vals <- nodes |> 
  dplyr::filter(NodeType != 'ewr_code_timing') |> 
  dplyr::left_join(aggvals) |>
  dplyr::filter(!is.na(scenario)) |> 
  # Scenario metadata fell off, return it
  dplyr::left_join(scenarios, by = 'scenario') |> 
  # clean up names
    dplyr::mutate(scenario = ifelse(scenario == 'MAX', 'MAX', 
                           paste0(climate_code, adapt_code)), 
         adapt_code = as.character(adapt_code))

# a subset of nodes so plots are readable
set.seed(17)
sampleenvobj <- nodes_with_vals |> 
  filter(NodeType == 'env_obj') |> 
  reframe(names = unique(Name)) |> 
  pull() |> 
  sample(10)

# pre-filter to make plotting simpler
basenodes <- nodes_with_vals |> 
  dplyr::filter(flow_multiplier %in% c(0.5, 1, 2) & flow_addition == 0) |> 
  baseline_compare(compare_col = 'scenario', base_lev = 'E1',
                   values_col = 'ewr_achieved',
                   group_cols = c('Name', 'NodeType', 'nodeorder'),
                   comp_fun = 'relative',
                   add_eps = 0.01) |> 
  mutate(logrel_ewr_achieved = log(relative_ewr_achieved))
```

```{r}
#| label: make-networks
#| include: false
#| warning: false
# use a subset again
aggNetworkdown_sub_rel <- basenodes |> 
  dplyr::filter(flow_multiplier == 0.5 & flow_addition == 0) |> 
  make_causal_plot(edges = ewr_edges,
                   focalnodes = sampleenvobj,
                 edge_pal = 'black',
                 node_pal = list(value = compare_pal),
                 node_colorset = 'logrel_ewr_achieved',
                 render = FALSE,
                 setLimits = c(min(basenodes$logrel_ewr_achieved),
                               0,
                               max(basenodes$logrel_ewr_achieved)),
                 save = TRUE,
                 savedir = 'images',
                 savename = 'aggNetworkdown_sub_rel')

aggNetworkup_sub_rel <- basenodes |> 
  dplyr::filter(flow_multiplier == 2 & flow_addition == 0) |> 
  make_causal_plot(edges = ewr_edges,
                   focalnodes = sampleenvobj,
                 edge_pal = 'black',
                 node_pal = list(value = compare_pal),
                 node_colorset = 'logrel_ewr_achieved',
                 render = FALSE,
                 setLimits = c(min(basenodes$logrel_ewr_achieved),
                               0,
                               max(basenodes$logrel_ewr_achieved)),
                 save = TRUE,
                 savedir = 'images',
                 savename = 'aggNetworkup_sub_rel')

# GET LEGEND: THIS NEEDS TO BE INTEGRATED IN FUNCTION 
lims <- c(min(basenodes$logrel_ewr_achieved),
                               0,
                               max(basenodes$logrel_ewr_achieved))

limtib <- tibble(x = seq(from = lims[1], to = lims[2], length.out = 10), y = 1) |> 
  bind_rows(tibble(x = seq(from = lims[2], to = lims[3], length.out = 10), y = 1)) |> 
  # make sure we have pretty options
  bind_rows(tibble(x = labeling::extended(lims[1], lims[3], 5), y = 1)) |> 
  distinct()

limtib <- tibble(x = labeling::extended(lims[1], lims[3], 5), y = 1)

allcols <- limtib |>
  grouped_colors(pal_list = list(compare_pal), colorset = 'x')

# Can I just make the legend and then steal it? using pretty breaks

pal_gg <- ggplot(allcols, aes(x = x, y = y, fill = color)) + 
  geom_tile() +
  scale_fill_identity(guide = 'legend', breaks = allcols$color, labels = as.character(allcols$x))

# I guess I could also do a line and steal that, but if we've monkeyed with a dividing point, that won't work

limtc <- tibble(condition = seq(from = lims[1], to = lims[3], by = 0.1), y = 1)

pal_ggc <- ggplot(limtc, aes(x = condition, y = y, color = condition)) + geom_point() +
  paletteer::scale_color_paletteer_c(compare_pal)

net_legend <- ggpubr::get_legend(pal_ggc) |> 
  ggpubr::as_ggplot()

# ggsave('images/aggNetworkup_sub_legend.png', width = 1, height = 2, units = 'cm')
```

*I'm working on better network plotting. Diagrammer is good for html but not for static output.*

```{r}
#| label: fig-network-subset
#| fig-cap: !expr glue::glue("Subset of the causal network for gauge {gauges_to_plot[2]} relevant to a selection of {length(sampleenvobj)} environmental objectives. A version with all environmental objectives is given in the supplemental information. The data are at the gauge scale for the first and second columns (EWRs and environmental objectives) and at the SDL unit scale for the third (Target groups). Thus, the final set of nodes contain information from other gauges that are not shown here for clarity. Colors represent the log of the relative change in condition from the baseline for the halving (panel a, scenario A) and doubling (panel b, scenario I) 'climate' scenarios. Large reductions in condition are dark purple, large improvements are dark green, and no change is white.") 

# if (knitr::is_html_output()) {
  # DiagrammeR::render_graph(aggNetworkdown_sub_rel)
  # DiagrammeR::render_graph(aggNetworkup_sub_rel)
  # net_legend
# } else {
#   knitr::include_graphics("images/aggNetworkdown_sub_rel.png")
#   knitr::include_graphics("images/aggNetworkup_sub_rel.png")
#   knitr::include_graphics("images/aggNetworkup_sub_legend.png")
# }
  
aggNetworkdown_sub_rel_grob <- png::readPNG('images/aggNetworkdown_sub_rel.png') |>
  grid::rasterGrob(interpolate = TRUE)
aggNetworkup_sub_rel_grob <- png::readPNG('images/aggNetworkup_sub_rel.png') |>
  grid::rasterGrob(interpolate = TRUE)

patchwork::wrap_plots(aggNetworkdown_sub_rel_grob, 
                      aggNetworkup_sub_rel_grob, 
                      net_legend,
                      ncol = 2, widths = c(9, 1), byrow = FALSE) +
  plot_annotation(tag_levels = list(c('a', 'b', '')))

```

# Implications and conclusions

*This needs more work, but I want to make sure you agree we're on the right track with the intro and this outline before spending too much time on it*

### Outline

What we achieved:

-   a toolkit that provides a consistent, scientifically robust and repeatable capacity to model responses to flow, with management-relevant outputs

-   co-design and development between scientists and managers

What this provides:

-   new ability to assess the wide suite of values the MDBA is mandated to manage for.

    -   moving beyond hydrology

-   Clear (or at least open) modelling to build trust

-   ability to assess a range of scenarios, including climate and climate adaptation

Advantages:

-   Identification of areas of resilience and sensitivity.

-   Uncertainty, understanding parameter space.

-   Modularity

-   adapt best models for responses into unified model and target management relevance

-   agnostic to scenario

-   causal networks

What cool software things do we do?

-   Modularity in architecture

-   ability to wrap models in multiple languages

-   flexibility- e.g. ability to aggregate differently

-   consistent comparison, with data provenance

-   metadata and use as parameters for repeatability

### From elsewhere- incorporate

*lots of this can be the backbone of the big-picture points above*

Large-scale natural resource management requires the capacity to make decisions relating to multiple spatial, temporal, and value dimensions, and is most successful when multiple scales within those dimensions are considered [@moore2021]. The toolkit is a framework to navigate those dimensions for water-dependent social, economic, environmental, and cultural values. Combining such disparate information in a standard and comparable manner can illuminate synergies and trade-offs, which could be critical for final judgement. Our example concerns the environmental values of the Murray-Darling Basin; however, the framework is equally applicable to social, economic, and cultural values and the toolkit itself has a modular design to incorporate such response models. Our framework drives a consistent approach to processing, scaling, analyses, and visualising outcomes, with the flexibility built-in for most end uses. Thus, the toolkit provides a good avenue for informed decision-making for water management in the Murray Darling Basin.

We expand upon the utility of an existing diver-indicator model by linking its indicators to objectives. This increases the transparency in the causal relationships that underpin the model and builds understanding and trust in the outcomes.

concerning which adaptation options should be implemented under changing climate by explicitly modelling effects on both target and other values.

The development of the toolkit is necessary to better understand the impacts of climate change and the different adaptation options in response to climate change, on water-dependent social, economic, environmental and cultural values. It incorporates new and existing information, knowledge and models to enable transparent, repeatable assessments of impacts and adaptation to future climates. In summary, the toolkit ingests scenarios (for example, climate or flow timeseries), feeds them to a response model (such as the EWR tool), reports outcomes and enables comparisons among scenarios. It uses the links in the response models for visualisation of the complex inter-relationships between water-dependent outcomes. This aids transparency and improves communication of the outputs.

# References

::: {#refs}
:::

# Appendices

In flux

### Component overview

A table of the toolkit components

```{r}
#| label: tbl-components
#| tbl-cap: Components of the toolkit architecture

comp_tab <- readr::read_csv('presentation_paper/component_table.csv', show_col_types = FALSE)

knitr::kable(comp_tab)
# huxtable::huxtable(comp_tab) |> theme_article()
```

### Aggregation

![Aggregation functions determine outcomes and reflect processes or values. Aggregating a set of outcomes (top row) yields a different outcome depending on the function used. Thus, function choice should be considered carefully and reflect the processes involved or management goals. The toolkit provides default functions for the mean, compensating (e.g. max), limiting (min), and spatially-weighted versions of the same. It also provides the ability for the user to define any desired function, allowing for more complex situtations.](../images/agg_concept.png){#fig-aggregation_types}

*RL: I’m not really getting this figure. What are the top row and why do only two of them have outcomes?* *GH: Noted. Top row is four things to be aggregated, outcome is color, with the unlabeled ones somewhere between 0-1. They yield 1 aggregated outcome, but it's value (color) depends on the function (bottom row). Does this work if we just say that and put numbers in all the boxes? Is it needed at all?* *GEORGIA*

## EWRs {#sec-ewr-table}

*We had a EWR table here for a couple gauges, but I think we should just link to the EWR tool here, or provide this as online data or something; it doesn't really provide much info, and is huge* *RL: I suspect we’ll still need to define the EWRs somewhere so a table for one gauge and then the links may be the way to go.*
```{r}
#| eval: false
#| label: tbl-ewrs
#| tbl-cap: !expr glue::glue("Environmental water requirements (EWR) for two example gauges ({gauges_to_plot[1]} and {gauges_to_plot[2]}).")


ewrs_in_pyewr |> 
  filter(Gauge %in% gauges_to_plot) |> 
  # Why these? Same as Georgia had
  select(Catchment = LTWPShortName, Gauge, Code, StartMonth, EndMonth, TargetFrequency, TargetFrequencyMax, TargetFrequencyMin, EventsPerYear, Duration, MinSpell, FlowThresholdMin, FlowThresholdMax, `MaxInter-event`) |>  
  # huxtable::huxtable() |>
  # theme_article()
  knitr::kable()
```

## Baselined hydrographs {#sec-baselining}

Relative is how we should look at this for climate scenarios, but when the addition in the adaptation options happens when the baseline is at 0 or close to it, it goes to inf. So make two plots: one to look at the relative shift and the other the additions. There's not a ton of reason to have two gauges here. Or three panels, for that matter.

*DELET FIGURE GEORGIA*

```{r}
#| label: fig-baseline-hydro-clim
#| fig-cap: Change in flow relative to the baseline scenario. These are flat lines because the relativisation occurs at each timepoint.


# Relative is how we should look at this for climate scenarios, but when the addition in the adaptation options happens when the baseline is at 0 or close to it, it goes to inf. So make two plots, I think.

# The relative one is supremely uninteresting, but maybe we need it to make a point?
base_hydro_clim <- scenehydros |>
    dplyr::filter(scenario %in% scenarios_to_plot & 
                    gauge %in% gauges_to_plot & 
                    flow_addition == 0) |>
    plot_outcomes(outcome_col = 'flow',
                  outcome_lab = 'Relative flow',
                  x_col = 'Date',
                  colorset = 'gauge',
                  color_lab = 'Gauge ID:',
                  pal_list = gauge_pal,
                  base_list = list(base_lev = "climatebaseadapt0",
                     values_col = 'flow',
                     comp_fun = "relative",
                     group_cols = c('Date', 'gauge')),
                  facet_col = 'climate_code')

 base_hydro_clim <- base_hydro_clim +
   ggplot2::scale_x_date(sec.axis = sec_axis(~ . ,
                                              name = "Climate scenarios",
                                              breaks = NULL, labels = NULL)) +
    theme_werp_toolkit(legend.position = "bottom")+
      guides(colour=guide_legend(nrow=2,byrow=TRUE))

base_hydro_clim
```

```{r}
#| label: fig-baseline-hydro-adapt
#| fig-cap: Change in flow volume compared to the baseline scenario. This comparison is done using the difference, and so represents the flow additions.
#| 
# Look at difference just at the the base multiplier
base_hydro_adapt <- scenehydros |>
    dplyr::filter(scenario %in% scenarios_to_plot & 
                    gauge %in% gauges_to_plot & 
                    flow_multiplier == 1) |>
      plot_outcomes(outcome_col = 'flow',
                  outcome_lab = 'Difference flow',
                  x_col = 'Date',
                  colorset = 'gauge',
                  color_lab = 'Gauge ID:',
                  pal_list = gauge_pal,
                  base_list = list(base_lev = "climatebaseadapt0",
                     values_col = 'flow',
                     comp_fun = "difference",
                     group_cols = c('Date', 'gauge')),
                  facet_col = 'adapt_code') +
    ggplot2::scale_x_date(sec.axis = sec_axis(~ . ,
                                              name = "Adaptation options",
                                              breaks = NULL, labels = NULL)) +
    theme_werp_toolkit(legend.position = "bottom")+
      guides(colour=guide_legend(nrow=2,byrow=TRUE))

base_hydro_adapt
```

## Extra plots

### Map aggregation {#sec-map-versions}

The goal here is to show the values at the sdl scale, but also to show how the gauges aggregate to that scale. In the text, @fig-gauge-to-sdl-map has a few examples of SDL-scaled outcomes, while @fig-spatial-scaling has the scaling for one. @fig-gauge-to-sdl-map-all shows the SDL outcomes for all Environmental objectives contributing the Priority Ecosystem Function, along with the constituent gauges.

```{r}
#| label: fig-gauge-to-sdl-map-all
#| fig-cap: "all panels version." 

# reduced set of objectives and scenarios- closer to the next option
(ef_maps + theme(legend.position = 'none') ) + 
  wrap_elements(nf_gauges + 
                  guides(color = guide_colourbar(title.position="top")) +
                  theme(legend.position = 'bottom')) + 
  plot_annotation( tag_levels = 'a') +
  plot_layout(widths = c(2,1))


```


The full set of SDL units and target groups 

```{r}
#| label: fig-smooth-all
#| fig-cap: Smoothed fits to assess change in performance across the 'climate' scenarios. Points are individual environmental objectives, fitted lines are loess smooths. Separate fits are done for each adaptation option, and so differences between lines of different colors represents the impact of those adaptations. Rows are environmental groupings, columns are SDL units. Note the very different scale of the y-axis. 
#| message: false  


# sdl_smooth_groups / sdl_smooth_clim +
#   plot_layout(guides = 'collect', heights = c(3,1))
sdl_smooth_groups # + coord_cartesian(ylim = c(0.5, 2)) # + geom_abline(slope = 1, intercept = 1)
```

### Heatmaps

```{r}
#| label: fig-heatmap
#| fig-cap: Condition results visualised as a heatmap with the two scenario definitions on the axes. This approach allows visualising changes in outcome as the result of multiple axes on which scenarios might differ. These axes might be different aspects of scenario creation (as here), or they might be different axes describing the outcome of scenarios (e.g. two different hydrometrics such as mean flow and flow variance)

qual_heatmap
```

### Causal networks

The causal networks shown in the text have been subset for readability, and baselined. Here, we have the ones they're based on. *I've turned these off for word because diagrammer hates word and I don't have the energy to do a workaround*.

```{r}
#| label: fig-full-networks
#| fig-cap: !expr glue::glue("Subset of the causal network for gauge {gauges_to_plot[2]} for all environmental objectives. The data is at the gauge scale for the first and second columns (EWRs and environmental objectives) and at the SDL unit scale for the third (Target groups). Thus, the final set of nodes contain information from other gauges that are not shown here for clarity. Colors represent the condition for the halving (a), baseline (b), and doubling (c) 'climate' scenario. Low condition is dark blue, high is light yellow.")
#| 
aggNetworkdown <- nodes_with_vals |> 
  dplyr::filter(flow_multiplier == 0.5 & flow_addition == 0) |> 
  make_causal_plot(edges = ewr_edges,
                 edge_pal = 'black',
                 node_pal = list(value = achieve_pal),
                 node_colorset = 'ewr_achieved',
                 setLimits = c(0,1),
                 render = FALSE,
                 save = TRUE,
                 savedir = 'images',
                 savename = 'aggNetworkdown')

aggNetworkbase <- nodes_with_vals |> 
  dplyr::filter(flow_multiplier == 1 & flow_addition == 0) |> 
  make_causal_plot(edges = ewr_edges,
                 edge_pal = 'black',
                 node_pal = list(value = achieve_pal),
                 node_colorset = 'ewr_achieved',
                 setLimits = c(0,1),
                 render = FALSE,
                 save = TRUE,
                 savedir = 'images',
                 savename = 'aggNetworkbase')

aggNetworkup <- nodes_with_vals |> 
  dplyr::filter(flow_multiplier == 2 & flow_addition == 0) |> 
  make_causal_plot(edges = ewr_edges,
                 edge_pal = 'black',
                 node_pal = list(value = achieve_pal),
                 node_colorset = 'ewr_achieved',
                 setLimits = c(0,1),
                 render = FALSE,
                 save = TRUE,
                 savedir = 'images',
                 savename = 'aggNetworkup')

# DiagrammeR::render_graph(aggNetworkdown)
# DiagrammeR::render_graph(aggNetworkbase)
# DiagrammeR::render_graph(aggNetworkup)

# make the legend
lim_full <- tibble(condition = seq(from = 0, to = 1, by = 0.1), y = 1)

pal_full <- ggplot(lim_full, aes(x = condition, y = y, color = condition)) + geom_point() +
  paletteer::scale_color_paletteer_c(achieve_pal)

fullnet_legend <- ggpubr::get_legend(pal_full) |> 
  ggpubr::as_ggplot()

aggNetworkdown_grob <- png::readPNG('images/aggNetworkdown.png') |>
  grid::rasterGrob(interpolate = TRUE)
aggNetworkbase_grob <- png::readPNG('images/aggNetworkbase.png') |>
  grid::rasterGrob(interpolate = TRUE)
aggNetworkup_grob <- png::readPNG('images/aggNetworkup.png') |>
  grid::rasterGrob(interpolate = TRUE)

layout <- "
AAAAABBBBB
CCCCC##D##
"
patchwork::wrap_plots(aggNetworkdown_grob, 
                      aggNetworkbase_grob, 
                      aggNetworkup_grob,
                      fullnet_legend,
                      design = layout, byrow = FALSE) +
  plot_annotation(tag_levels = list(c('a', 'b', 'c')))

```

The same set of nodes as in the text, but the actual condition values, rather than relativized.

```{r}
#| label: fig-network-notbaseline
#| fig-cap: "Causal networks as in @fig-network-subset, but with the raw condition values for the halved (a), baseline (b), and doubled (c) scenarios instead of relativized to the baseline."

aggNetworkdown_sub <- nodes_with_vals |> 
  dplyr::filter(flow_multiplier == 0.5 & flow_addition == 0) |> 
  make_causal_plot(edges = ewr_edges,
                   focalnodes = sampleenvobj,
                 edge_pal = 'black',
                 node_pal = list(value = achieve_pal),
                 node_colorset = 'ewr_achieved',
                 setLimits = c(0,1),
                 render = FALSE,
                 save = TRUE,
                 savedir = 'images',
                 savename = 'aggNetworkdown_sub')

aggNetworkbase_sub <- nodes_with_vals |> 
  dplyr::filter(flow_multiplier == 1 & flow_addition == 0) |> 
  make_causal_plot(edges = ewr_edges,
                   focalnodes = sampleenvobj,
                 edge_pal = 'black',
                 node_pal = list(value = achieve_pal),
                 node_colorset = 'ewr_achieved',
                 setLimits = c(0,1),
                 render = FALSE,
                 save = TRUE,
                 savedir = 'images',
                 savename = 'aggNetworkbase_sub')

aggNetworkup_sub <- nodes_with_vals |> 
  dplyr::filter(flow_multiplier == 2 & flow_addition == 0) |> 
  make_causal_plot(edges = ewr_edges,
                   focalnodes = sampleenvobj,
                 edge_pal = 'black',
                 node_pal = list(value = achieve_pal),
                 node_colorset = 'ewr_achieved',
                 setLimits = c(0,1),
                 render = FALSE,
                 save = TRUE,
                 savedir = 'images',
                 savename = 'aggNetworkup_sub')

# DiagrammeR::render_graph(aggNetworkdown_sub)
# DiagrammeR::render_graph(aggNetworkbase_sub)
# DiagrammeR::render_graph(aggNetworkup_sub)

aggNetworkdown_sub_grob <- png::readPNG('images/aggNetworkdown_sub.png') |>
  grid::rasterGrob(interpolate = TRUE)
aggNetworkbase_sub_grob <- png::readPNG('images/aggNetworkbase_sub.png') |>
  grid::rasterGrob(interpolate = TRUE)
aggNetworkup_sub_grob <- png::readPNG('images/aggNetworkup_sub.png') |>
  grid::rasterGrob(interpolate = TRUE)

layout2 <- "
AAAAAAAAAAA#
BBBBBBBBBBBD
CCCCCCCCCCC#
"
patchwork::wrap_plots(aggNetworkdown_sub_grob, 
                      aggNetworkbase_sub_grob, 
                      aggNetworkup_sub_grob,
                      fullnet_legend,
                      design = layout2) +
  plot_annotation(tag_levels = list(c('a', 'b', 'c')))
```

------------------------------------------------------------------------

# Journal info

## Environmental Modelling & Software

• Author names and affiliations. Where the family name may be ambiguous (e.g., a double name), please indicate this clearly. Present the authors' affiliation addresses (where the actual work was done) below the names. Indicate all affiliations with a lower-case superscript letter immediately after the author's name and in front of the appropriate address. Provide the full postal address of each affiliation, including the country name and, if available, the e-mail address of each author.

• Corresponding author. Clearly indicate who will handle correspondence at all stages of refereeing and publication, also post-publication. Ensure that telephone numbers (with country and area code) are provided in addition to the e-mail address and the complete postal address. Contact details must be kept up to date by the corresponding author.

• Present/permanent address. If an author has moved since the work described in the article was done, or was visiting at the time, a 'Present address' (or 'Permanent address') may be indicated as a footnote to that author's name. The address at which the author actually did the work must be retained as the main, affiliation address. Superscript Arabic numerals are used for such footnotes.

### Authorship

Authorship should be limited to those who have made a significant contribution to the conception, design, execution, or interpretation of the reported study. All those who have made significant contributions should be listed as co-authors. Where there are others who have participated in certain substantive aspects of the research project, they should be acknowledged or listed as contributors. Acknowledgement of the contributions of authors is encouraged (see Acknowledgements section below). The corresponding author should ensure that all appropriate co-authors and no inappropriate co-authors are included on the paper, and that all co-authors have seen and approved the final version of the paper and have agreed to its submission for publication.

Title, Authors, Affiliations and Contact details

### Abbreviations

Define abbreviations that are not standard in this field in a footnote to be placed on the first page of the article. Such abbreviations that are unavoidable in the abstract must be defined at their first mention there, as well as in the footnote. Ensure consistency of abbreviations throughout the article.

## Separate files

### Highlights

Highlights are optional yet highly encouraged for this journal, as they increase the discoverability of your article via search engines. They consist of a short collection of bullet points that capture the novel results of your research as well as new methods that were used during the study (if any). Please have a look at the examples here: example Highlights.

Highlights should be submitted in a separate editable file in the online submission system. Please use 'Highlights' in the file name and include 3 to 5 bullet points (maximum 85 characters, including spaces, per bullet point).

Highlights are mandatory for this journal. They consist of a short collection of bullet points that convey the core findings of the article and should be submitted in a separate file in the online submission system. Please use 'Highlights' in the file name and include 3 to 5 bullet points (maximum 85 characters, including spaces, per bullet point). See https://www.elsevier.com/highlights for examples.

### Graphical abstract

A Graphical abstract is optional and should summarize the contents of the article in a concise, pictorial form designed to capture the attention of a wide readership online. Authors must provide images that clearly represent the work described in the article. Graphical abstracts should be submitted as a separate file in the online submission system. Image size: Please provide an image with a minimum of 531 × 1328 pixels (h × w) or proportionally more. The image should be readable at a size of 5 × 13 cm using a regular screen resolution of 96 dpi. Preferred file types: TIFF, EPS, PDF or MS Office files. See https://www.elsevier.com/graphicalabstracts for examples.

### Abstract (not included in section numbering)

A concise and factual abstract is required, with a restriction of 150 words. The abstract should state briefly the purpose of the research, the principal results and major conclusions. An abstract is often presented separately from the article, so it must be able to stand alone. For this reason, References should be avoided, but if essential, then cite the author(s) and year(s). Also, non-standard or uncommon abbreviations should be avoided, but if essential they must be defined at their first mention in the abstract itself.

### Keywords

Immediately after the abstract, provide a maximum of 6 keywords, using American spelling and avoiding general and plural terms and multiple concepts (avoid, for example, 'and', 'of'). Be sparing with abbreviations: only abbreviations firmly established in the field may be eligible. These keywords will be used for indexing purposes.

### Software and/or data availability

Most EMS papers should include a software/data availability section containing as much of the following information as possible: name of software or dataset, developer and contact information, year first available, hardware required, software required, availability and cost. Also for software: program language, program size; for data: form of repository (database, files, spreadsheet), size of archive, access form. Note that "Contact the author" is not acceptable for software or data access. Please use online data and software storage and retrieval systems such as GitHub, BitBucket, FigShare, HydroShare or others to make your data and software readily available. Links to commercial software and data access web sites are also acceptable.

When a software component is an essential part of the paper, authors should be prepared to make it available to reviewers during the review process. To preserve the anonymity of reviewers, the authors should make the software available for a download, protecting it if needed by a password that is communicated to the editors.
